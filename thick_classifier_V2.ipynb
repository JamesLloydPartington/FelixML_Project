import os
import numpy as np
from generators import DataGenerator
from keras import layers
from keras import models
from keras import optimizers
rng = np.random.default_rng()

path = "F:\\training3000\\64bit_arrs"

sample_arr = np.array(os.listdir(path))
c = 0
for i in sample_arr:
    sample_arr[c] = i[:-4]
    c += 1

indices = np.arange(0, sample_arr.size)
rng.shuffle(indices)

frac = 0.2
partition = {"train": sample_arr[indices[int(indices.size*frac):]], "val": sample_arr[indices[:int(indices.size*frac)]]}
labels = {}
for i in sample_arr:
    labels[i] = int((int(i[-4:])-50)/200)

params = {'dim': (128,128),
          'batch_size': 64,
          'n_classes': 10,
          'n_channels': 1,
          'shuffle': True}

training_generator = DataGenerator(partition['train'], labels, **params)
validation_generator = DataGenerator(partition['val'], labels, **params)

model = models.Sequential()
model.add(layers.SeparableConv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.SeparableConv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.SeparableConv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.SeparableConv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dropout(0.5))
model.add(layers.Dense(512, activation='relu', kernel_regularizer='l2'))
model.add(layers.Dense(10, activation='softmax', kernel_regularizer='l2'))

model.compile(loss='categorical_crossentropy', optimizer="rmsprop", metrics=['acc'])

model.fit_generator(generator=training_generator,
                    validation_data=validation_generator,
                    use_multiprocessing=True,
                    workers=4)
