{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers, backend, Model, losses, datasets, models, metrics, optimizers, initializers\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadNewImages(TrainingPaths, ValidationPaths, TestPaths, NumberInSet):\n",
    "    NumberImagesPerCrystal = 1\n",
    "    #TrainingPaths = [[All training inputs], [All training outputs]]\n",
    "    \n",
    "    NewTrainingImages = np.zeros(NumberInSet[0] * NumberImagesPerCrystal * 128 * 128 * 2, dtype = np.float32).reshape(NumberInSet[0] * NumberImagesPerCrystal, 2, 128, 128)\n",
    "    NewValidationImages = np.zeros(NumberInSet[1] * NumberImagesPerCrystal * 128 * 128 * 2, dtype = np.float32).reshape(NumberInSet[1] * NumberImagesPerCrystal, 2, 128, 128)\n",
    "    NewTestImages = np.zeros(NumberInSet[2] * NumberImagesPerCrystal * 128 * 128 * 2, dtype = np.float32).reshape(NumberInSet[2] * NumberImagesPerCrystal, 2, 128, 128)\n",
    "    \n",
    "    \n",
    "    for i in range(0, NumberInSet[0] * NumberImagesPerCrystal):\n",
    "        NewTrainingImages[i][0] = np.load(TrainingPaths[0][i]).astype(np.float32)\n",
    "        NewTrainingImages[i][1] = np.load(TrainingPaths[1][i]).astype(np.float32)\n",
    "        \n",
    "    for i in range(0, NumberInSet[1] * NumberImagesPerCrystal):\n",
    "        NewValidationImages[i][0] = np.load(ValidationPaths[0][i]).astype(np.float32)\n",
    "        NewValidationImages[i][1] = np.load(ValidationPaths[1][i]).astype(np.float32)\n",
    "    \n",
    "    for i in range(0, NumberInSet[2] * NumberImagesPerCrystal):\n",
    "        NewTestImages[i][0] = np.load(TestPaths[0][i]).astype(np.float32)\n",
    "        NewTestImages[i][1] = np.load(TestPaths[1][i]).astype(np.float32)\n",
    "    \n",
    "    AllNewImages = [NewTrainingImages, NewValidationImages, NewTestImages]\n",
    "    return(AllNewImages)\n",
    "\n",
    "def PairInputImages(All_Images): #Comparison done by a root mean square\n",
    "    NumberImagesPerCrystal = 4\n",
    "    #with All_Images = [Train_Images, Validation_Images, Test_Images]\n",
    "    DataSetSize = [len(All_Images[0]), len(All_Images[1]), len(All_Images[2])] * NumberImagesPerCrystal\n",
    "    TrainValidationPairs = np.zeros(DataSetSize[0] * DataSetSize[1], dtype = np.float32).reshape(DataSetSize[0], DataSetSize[1])\n",
    "    TrainTestPairs = np.zeros(DataSetSize[0] * DataSetSize[2], dtype = np.float32).reshape(DataSetSize[0], DataSetSize[2])\n",
    "    \n",
    "    for i in range(0, DataSetSize[0]):\n",
    "        print(\"1: \", i)\n",
    "        for j in range(0, DataSetSize[1]):\n",
    "            TrainValidationPairs[i][j] = MeanSquare(All_Images[0][i][0], All_Images[1][j][0])\n",
    "            \n",
    "    for i in range(0, DataSetSize[0]):\n",
    "        print(\"2: \", i)\n",
    "        for j in range(0, DataSetSize[2]):\n",
    "            TrainTestPairs[i][j] = MeanSquare(All_Images[0][i][0], All_Images[2][j][0])\n",
    "    \n",
    "    BestPairTrainValidation = np.zeros(DataSetSize[1], dtype = np.int)\n",
    "    BestPairTrainTest = np.zeros(DataSetSize[2], dtype = np.int)\n",
    "    \n",
    "    for i in range(0, DataSetSize[1]):\n",
    "        print(\"3: \", i)\n",
    "        min_val = np.inf\n",
    "        for j in range(0, DataSetSize[0]):\n",
    "            if(TrainValidationPairs[j][i] < min_val):\n",
    "                BestPairTrainValidation[i] = j\n",
    "                min_val = TrainValidationPairs[j][i]\n",
    "                \n",
    "    for i in range(0, DataSetSize[2]):\n",
    "        print(\"4: \", i)\n",
    "        min_val = np.inf\n",
    "        for j in range(0, DataSetSize[0]):\n",
    "            if(TrainTestPairs[j][i] < min_val):\n",
    "                BestPairTrainTest[i] = j\n",
    "                min_val = TrainTestPairs[j][i]\n",
    "    return(BestPairTrainValidation, BestPairTrainTest)\n",
    "\n",
    "def BestPairLoss(All_Images, BestPairTrainValidation, BestPairTrainTest):\n",
    "    Val_Loss_Sum = 0\n",
    "    Test_Loss_Sum = 0\n",
    "    for i in range(0, len(BestPairTrainValidation)):\n",
    "        Val_Loss_Sum+=MeanSquareLogError(All_Images[1][i][1], All_Images[0][BestPairTrainValidation[i]][1])\n",
    "        print(\"1: \", i)\n",
    "    for i in range(0, len(BestPairTrainTest)):\n",
    "        Test_Loss_Sum+=MeanSquareLogError(All_Images[2][i][1], All_Images[0][BestPairTrainTest[i]][1])\n",
    "        print(\"2: \", i)\n",
    "    Val_Loss = Val_Loss_Sum / len(BestPairTrainValidation)\n",
    "    Test_Loss = Test_Loss_Sum / len(BestPairTrainTest)\n",
    "    return(Val_Loss, Test_Loss)\n",
    "\n",
    "def MeanSquare(Image_1, Image_2): #Shape N by N\n",
    "    ms = (np.sum(np.square(Image_1 - Image_2)))\n",
    "    return(ms)\n",
    "\n",
    "def MeanSquareLogError(Image_1, Image_2):\n",
    "    msle = 0\n",
    "    for i in range(0, len(Image_1)):\n",
    "        for j in range(0, len(Image_1[i])):\n",
    "            msle+=(math.log(1+Image_1[i][j]) - math.log(1+Image_2[i][j])) ** 2\n",
    "    return(msle)\n",
    "\n",
    "def JeremyFunc(NewTrainingPaths, NewValidationPaths, NewTestPaths):\n",
    "    NumberInSet = [len(NewTrainingPaths[0]), len(NewValidationPaths[0]), len(NewTestPaths[0])]\n",
    "    AllNewImages = LoadNewImages(NewTrainingPaths, NewValidationPaths, NewTestPaths, NumberInSet)\n",
    "    BestPairTrainValidation, BestPairTrainTest = PairInputImages(AllNewImages)\n",
    "    Val_Loss, Test_Loss = BestPairLoss(AllNewImages, BestPairTrainValidation, BestPairTrainTest)\n",
    "    return(Val_Loss, Test_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        \"\"\"Here self.x is a list of paths to .npy input files. self.y is a\n",
    "        corresponding list of paths to .npy output files.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        #print(np.array([np.load(file_name) for file_name in batch_x]).shape, np.array([np.load(file_name) for file_name in batch_y]).shape)\n",
    "        return np.array([np.reshape(np.load(file_name), (128, 128, 1)) for file_name in batch_x]), np.array([np.reshape(np.load(file_name), (128, 128, 1)) for file_name in batch_y])\n",
    "    \n",
    "\n",
    "def gen_paths_labels(base_path = \"D:\\\\Uni Work\\\\Masters Project\\\\electron_dists\\\\Data\\\\VAE_000_1\\\\Data\"):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        input_paths = []\n",
    "        output_paths = []\n",
    "        for crystal in sorted(os.listdir(segment_path)):\n",
    "            crystal_path = os.path.join(segment_path, crystal)\n",
    "            files = sorted(os.listdir(crystal_path))\n",
    "            input_paths.append(os.path.join(crystal_path, files[0]))\n",
    "            output_paths.append(os.path.join(crystal_path, files[1]))\n",
    "        yield [input_paths, output_paths]\n",
    "\n",
    "def gen_paths_fromfile(Path):\n",
    "    Paths = []\n",
    "    with open(Path) as textFile:\n",
    "        lines = [line.split() for line in textFile]\n",
    "    for i in lines:\n",
    "        Paths.append(i[0])\n",
    "        \n",
    "    Paths = np.array(Paths, dtype = \"object\")\n",
    "    return(Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "\n",
    "\"\"\"\n",
    "## Create a sampling layer\n",
    "\"\"\"\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def __init__(self, gamma = 1, **kwargs):\n",
    "        super(Sampling, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        #print(self.gamma)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon * self.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        16400     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 91)                1491035   \n",
      "_________________________________________________________________\n",
      "z_mean (Dense)               (None, 16)                1472      \n",
      "_________________________________________________________________\n",
      "z_log_var (Dense)            (None, 16)                1472      \n",
      "_________________________________________________________________\n",
      "sampling (Sampling)          (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,511,419\n",
      "Trainable params: 1,511,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the encoder\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "NoKernel2 = 1\n",
    "NoKernel4 = 1\n",
    "NoKernel8 = 8\n",
    "NoKernel16 = 1\n",
    "\n",
    "encoder_inputs = Input(shape=(128, 128, 1))\n",
    "Layer_Encode_1_K2 = layers.Conv2D(NoKernel2, kernel_size = (2, 2), activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "Layer_Encode_1_K4 = layers.Conv2D(NoKernel4, kernel_size = (4, 4), activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "Layer_Encode_1_K8 = layers.Conv2D(NoKernel8, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "Layer_Encode_1_K16 = layers.Conv2D(NoKernel16, kernel_size = (16, 16), activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "Layer_Encode_1 = layers.concatenate([Layer_Encode_1_K2, Layer_Encode_1_K4, Layer_Encode_1_K8, Layer_Encode_1_K16])\n",
    "\n",
    "Layer_Encode_2_K2 = layers.Conv2D(NoKernel2, kernel_size = (2, 2), activation=\"relu\", strides=2, padding=\"same\")(Layer_Encode_1)\n",
    "Layer_Encode_2_K4 = layers.Conv2D(NoKernel4, kernel_size = (4, 4), activation=\"relu\", strides=2, padding=\"same\")(Layer_Encode_1)\n",
    "Layer_Encode_2_K8 = layers.Conv2D(NoKernel8, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")(Layer_Encode_1)\n",
    "Layer_Encode_2_K16 = layers.Conv2D(NoKernel16, kernel_size = (16, 16), activation=\"relu\", strides=2, padding=\"same\")(Layer_Encode_1)\n",
    "Layer_Encode_2 = layers.concatenate([Layer_Encode_2_K2, Layer_Encode_2_K4, Layer_Encode_2_K8, Layer_Encode_2_K16])\n",
    "\n",
    "\n",
    "\n",
    "x = layers.Flatten()(Layer_Encode_2)\n",
    "\n",
    "\n",
    "DenseParam_Encode = 1500000\n",
    "DenseNeurons_Encode = int(DenseParam_Encode / (x.shape[1]))\n",
    "\n",
    "x = layers.Dense(DenseNeurons_Encode, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", kernel_initializer='zeros', bias_initializer='zeros')(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "Num_Kernals = 16\n",
    "Size_Kernals = 8\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, gamma = 0, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "        self.Conv1 = layers.Conv2D(Num_Kernals, kernel_size = (Size_Kernals, Size_Kernals), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        self.Conv2 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.Conv3 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.Conv4 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "\n",
    "        self.flat = layers.Flatten()\n",
    "\n",
    "        self.DenseParam_Encode = 1500000\n",
    "        self.DenseNeurons_Encode = int(self.DenseParam_Encode / 16400)\n",
    "\n",
    "        self.dense = layers.Dense(self.DenseNeurons_Encode, activation=\"relu\", kernel_regularizer = l2(0.1))\n",
    "        self.z_mean = layers.Dense(latent_dim, name=\"z_mean\")\n",
    "        self.z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", kernel_initializer='zeros', bias_initializer='zeros')\n",
    "        self.sampling = Sampling(gamma=gamma)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.Conv1(inputs)\n",
    "        x = self.Conv2(x)\n",
    "        #x = self.Conv3(x)\n",
    "        #x = self.Conv4(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense(x)\n",
    "        z_mean = self.z_mean(x)\n",
    "        z_log_var = self.z_log_var(x)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z\n",
    "    \n",
    "encoder = Encoder(gamma = 0, name=\"encoder\")\n",
    "encoder(Input(batch_shape=(None,128,128,1)))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 93184)             1584128   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 91)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 64, 64, 16)        93200     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 128, 128, 16)      16400     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 1)       65        \n",
      "=================================================================\n",
      "Total params: 1,693,793\n",
      "Trainable params: 1,693,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the decoder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Dense_Size = Layer_Encode_2.shape[1]\n",
    "DenseParam_Decode = 1500000\n",
    "Dense_Depth = int(DenseParam_Decode / (latent_dim * Dense_Size * Dense_Size))\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "x = layers.Dense(Dense_Size * Dense_Size * Dense_Depth, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((Dense_Size, Dense_Size, Dense_Depth))(x)\n",
    "\n",
    "Layer_Decode_1_K2 = layers.Conv2DTranspose(NoKernel2, kernel_size = (2, 2), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "Layer_Decode_1_K4 = layers.Conv2DTranspose(NoKernel4, kernel_size = (4, 4), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "Layer_Decode_1_K8 = layers.Conv2DTranspose(NoKernel8, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "Layer_Decode_1_K16 = layers.Conv2DTranspose(NoKernel16, kernel_size = (16, 16), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "Layer_Decode_1 = layers.concatenate([Layer_Decode_1_K2, Layer_Decode_1_K4, Layer_Decode_1_K8, Layer_Decode_1_K16])\n",
    "\n",
    "Layer_Decode_2_K2 = layers.Conv2DTranspose(NoKernel2, kernel_size = (2, 2), activation=\"relu\", strides=2, padding=\"same\")(Layer_Decode_1)\n",
    "Layer_Decode_2_K4 = layers.Conv2DTranspose(NoKernel4, kernel_size = (4, 4), activation=\"relu\", strides=2, padding=\"same\")(Layer_Decode_1)\n",
    "Layer_Decode_2_K8 = layers.Conv2DTranspose(NoKernel8, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")(Layer_Decode_1)\n",
    "Layer_Decode_2_K16 = layers.Conv2DTranspose(NoKernel16, kernel_size = (16, 16), activation=\"relu\", strides=2, padding=\"same\")(Layer_Decode_1)\n",
    "Layer_Decode_2 = layers.concatenate([Layer_Decode_2_K2, Layer_Decode_2_K4, Layer_Decode_2_K8, Layer_Decode_2_K16])\n",
    "\n",
    "\n",
    "\n",
    "decoder_outputs = layers.Conv2DTranspose(1, kernel_size = (2, 2), activation=\"relu\", padding= \"same\")(Layer_Decode_2)\n",
    "decoder = Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "decoder.summary()\n",
    "\"\"\"\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, encoder_layer, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        Dense_Size = encoder_layer[1]\n",
    "        \n",
    "        DenseParam_Decode = 1500000\n",
    "        Dense_Depth = int(DenseParam_Decode / (latent_dim * Dense_Size * Dense_Size))\n",
    "        \n",
    "        self.dense1 = layers.Dense(Dense_Size * Dense_Size * Dense_Depth, activation=\"relu\",  kernel_regularizer = l2(0.1))\n",
    "        self.dense2 = layers.Reshape((Dense_Size, Dense_Size, Dense_Depth))\n",
    "                \n",
    "        self.convT1 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (Size_Kernals, Size_Kernals), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        self.convT2 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.convT3 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.convT4 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "\n",
    "        self.outputs = layers.Conv2DTranspose(1, kernel_size = (2, 2), activation=\"relu\", padding= \"same\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "                \n",
    "        x = self.convT1(x)\n",
    "        x = self.convT2(x)\n",
    "        #x = self.convT3(x)\n",
    "        #x = self.convT4(x)\n",
    "        \n",
    "        output = self.outputs(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "decoder = Decoder(encoder.layers[1].output_shape, name=\"decoder\")\n",
    "decoder(Input(batch_shape=(None, latent_dim)))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            #print(z_mean, z_log_var, z)\n",
    "            beta = 1\n",
    "            kl_loss = (-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))) * beta\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.decoder(self.encoder(data)[2])\n",
    "\n",
    "#losses.MSE(y, reconstruction), axis=(1, 2)\n",
    "#losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ug-ml/felix-ML/VAE_000/Data/FilePaths/\"\n",
    "\n",
    "\n",
    "TrainingPathsInput = gen_paths_fromfile(data_path + \"TrainingInput_J1.txt\")\n",
    "TrainingPathsOutput = gen_paths_fromfile(data_path + \"TrainingOutput_J1.txt\")\n",
    "\n",
    "ValidationPathsInput = gen_paths_fromfile(data_path + \"ValidationInput_J1.txt\")\n",
    "ValidationPathsOutput = gen_paths_fromfile(data_path + \"ValidationOutput_J1.txt\")\n",
    "\n",
    "TestPathsInput = gen_paths_fromfile(data_path + \"TestInput_J1.txt\")\n",
    "TestPathsOutput = gen_paths_fromfile(data_path + \"TestOutput_J1.txt\")\n",
    "\n",
    "fractions = [0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0]\n",
    "\n",
    "train_len = TrainingPathsInput.size\n",
    "val_len = ValidationPathsInput.size\n",
    "test_len = TestPathsInput.size\n",
    "\n",
    "\n",
    "\n",
    "#print(train_len, val_len, test_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 27 13\n",
      "1:  0\n",
      "1:  1\n",
      "1:  2\n",
      "1:  3\n",
      "1:  4\n",
      "1:  5\n",
      "1:  6\n",
      "1:  7\n",
      "1:  8\n",
      "1:  9\n",
      "1:  10\n",
      "1:  11\n",
      "1:  12\n",
      "1:  13\n",
      "1:  14\n",
      "1:  15\n",
      "1:  16\n",
      "1:  17\n",
      "1:  18\n",
      "1:  19\n",
      "1:  20\n",
      "1:  21\n",
      "1:  22\n",
      "1:  23\n",
      "1:  24\n",
      "1:  25\n",
      "1:  26\n",
      "1:  27\n",
      "1:  28\n",
      "1:  29\n",
      "1:  30\n",
      "1:  31\n",
      "1:  32\n",
      "1:  33\n",
      "1:  34\n",
      "1:  35\n",
      "1:  36\n",
      "1:  37\n",
      "1:  38\n",
      "1:  39\n",
      "1:  40\n",
      "1:  41\n",
      "1:  42\n",
      "1:  43\n",
      "1:  44\n",
      "1:  45\n",
      "1:  46\n",
      "1:  47\n",
      "1:  48\n",
      "1:  49\n",
      "1:  50\n",
      "1:  51\n",
      "1:  52\n",
      "1:  53\n",
      "1:  54\n",
      "1:  55\n",
      "1:  56\n",
      "1:  57\n",
      "1:  58\n",
      "1:  59\n",
      "1:  60\n",
      "1:  61\n",
      "1:  62\n",
      "1:  63\n",
      "1:  64\n",
      "1:  65\n",
      "1:  66\n",
      "1:  67\n",
      "1:  68\n",
      "1:  69\n",
      "1:  70\n",
      "1:  71\n",
      "1:  72\n",
      "1:  73\n",
      "1:  74\n",
      "1:  75\n",
      "1:  76\n",
      "1:  77\n",
      "1:  78\n",
      "1:  79\n",
      "1:  80\n",
      "1:  81\n",
      "1:  82\n",
      "1:  83\n",
      "1:  84\n",
      "1:  85\n",
      "1:  86\n",
      "1:  87\n",
      "1:  88\n",
      "1:  89\n",
      "1:  90\n",
      "1:  91\n",
      "1:  92\n",
      "1:  93\n",
      "1:  94\n",
      "1:  95\n",
      "1:  96\n",
      "1:  97\n",
      "1:  98\n",
      "1:  99\n",
      "1:  100\n",
      "1:  101\n",
      "1:  102\n",
      "1:  103\n",
      "1:  104\n",
      "1:  105\n",
      "1:  106\n",
      "1:  107\n",
      "1:  108\n",
      "1:  109\n",
      "1:  110\n",
      "1:  111\n",
      "1:  112\n",
      "1:  113\n",
      "1:  114\n",
      "1:  115\n",
      "1:  116\n",
      "1:  117\n",
      "1:  118\n",
      "1:  119\n",
      "1:  120\n",
      "1:  121\n",
      "1:  122\n",
      "1:  123\n",
      "1:  124\n",
      "1:  125\n",
      "1:  126\n",
      "1:  127\n",
      "1:  128\n",
      "1:  129\n",
      "1:  130\n",
      "1:  131\n",
      "1:  132\n",
      "1:  133\n",
      "1:  134\n",
      "1:  135\n",
      "1:  136\n",
      "1:  137\n",
      "1:  138\n",
      "1:  139\n",
      "1:  140\n",
      "1:  141\n",
      "1:  142\n",
      "1:  143\n",
      "1:  144\n",
      "1:  145\n",
      "1:  146\n",
      "1:  147\n",
      "1:  148\n",
      "1:  149\n",
      "1:  150\n",
      "1:  151\n",
      "1:  152\n",
      "1:  153\n",
      "1:  154\n",
      "1:  155\n",
      "1:  156\n",
      "1:  157\n",
      "1:  158\n",
      "1:  159\n",
      "1:  160\n",
      "1:  161\n",
      "1:  162\n",
      "1:  163\n",
      "1:  164\n",
      "1:  165\n",
      "1:  166\n",
      "1:  167\n",
      "1:  168\n",
      "1:  169\n",
      "1:  170\n",
      "1:  171\n",
      "1:  172\n",
      "1:  173\n",
      "1:  174\n",
      "1:  175\n",
      "1:  176\n",
      "1:  177\n",
      "1:  178\n",
      "1:  179\n",
      "1:  180\n",
      "1:  181\n",
      "1:  182\n",
      "1:  183\n",
      "1:  184\n",
      "1:  185\n",
      "1:  186\n",
      "1:  187\n",
      "1:  188\n",
      "1:  189\n",
      "1:  190\n",
      "1:  191\n",
      "1:  192\n",
      "1:  193\n",
      "1:  194\n",
      "1:  195\n",
      "1:  196\n",
      "1:  197\n",
      "1:  198\n",
      "1:  199\n",
      "1:  200\n",
      "1:  201\n",
      "1:  202\n",
      "1:  203\n",
      "1:  204\n",
      "1:  205\n",
      "1:  206\n",
      "1:  207\n",
      "1:  208\n",
      "1:  209\n",
      "1:  210\n",
      "1:  211\n",
      "1:  212\n",
      "1:  213\n",
      "1:  214\n",
      "1:  215\n",
      "1:  216\n",
      "1:  217\n",
      "1:  218\n",
      "1:  219\n",
      "1:  220\n",
      "1:  221\n",
      "1:  222\n",
      "1:  223\n",
      "1:  224\n",
      "1:  225\n",
      "1:  226\n",
      "1:  227\n",
      "1:  228\n",
      "1:  229\n",
      "1:  230\n",
      "2:  0\n",
      "2:  1\n",
      "2:  2\n",
      "2:  3\n",
      "2:  4\n",
      "2:  5\n",
      "2:  6\n",
      "2:  7\n",
      "2:  8\n",
      "2:  9\n",
      "2:  10\n",
      "2:  11\n",
      "2:  12\n",
      "2:  13\n",
      "2:  14\n",
      "2:  15\n",
      "2:  16\n",
      "2:  17\n",
      "2:  18\n",
      "2:  19\n",
      "2:  20\n",
      "2:  21\n",
      "2:  22\n",
      "2:  23\n",
      "2:  24\n",
      "2:  25\n",
      "2:  26\n",
      "2:  27\n",
      "2:  28\n",
      "2:  29\n",
      "2:  30\n",
      "2:  31\n",
      "2:  32\n",
      "2:  33\n",
      "2:  34\n",
      "2:  35\n",
      "2:  36\n",
      "2:  37\n",
      "2:  38\n",
      "2:  39\n",
      "2:  40\n",
      "2:  41\n",
      "2:  42\n",
      "2:  43\n",
      "2:  44\n",
      "2:  45\n",
      "2:  46\n",
      "2:  47\n",
      "2:  48\n",
      "2:  49\n",
      "2:  50\n",
      "2:  51\n",
      "2:  52\n",
      "2:  53\n",
      "2:  54\n",
      "2:  55\n",
      "2:  56\n",
      "2:  57\n",
      "2:  58\n",
      "2:  59\n",
      "2:  60\n",
      "2:  61\n",
      "2:  62\n",
      "2:  63\n",
      "2:  64\n",
      "2:  65\n",
      "2:  66\n",
      "2:  67\n",
      "2:  68\n",
      "2:  69\n",
      "2:  70\n",
      "2:  71\n",
      "2:  72\n",
      "2:  73\n",
      "2:  74\n",
      "2:  75\n",
      "2:  76\n",
      "2:  77\n",
      "2:  78\n",
      "2:  79\n",
      "2:  80\n",
      "2:  81\n",
      "2:  82\n",
      "2:  83\n",
      "2:  84\n",
      "2:  85\n",
      "2:  86\n",
      "2:  87\n",
      "2:  88\n",
      "2:  89\n",
      "2:  90\n",
      "2:  91\n",
      "2:  92\n",
      "2:  93\n",
      "2:  94\n",
      "2:  95\n",
      "2:  96\n",
      "2:  97\n",
      "2:  98\n",
      "2:  99\n",
      "2:  100\n",
      "2:  101\n",
      "2:  102\n",
      "2:  103\n",
      "2:  104\n",
      "2:  105\n",
      "2:  106\n",
      "2:  107\n",
      "2:  108\n",
      "2:  109\n",
      "2:  110\n",
      "2:  111\n",
      "2:  112\n",
      "2:  113\n",
      "2:  114\n",
      "2:  115\n",
      "2:  116\n",
      "2:  117\n",
      "2:  118\n",
      "2:  119\n",
      "2:  120\n",
      "2:  121\n",
      "2:  122\n",
      "2:  123\n",
      "2:  124\n",
      "2:  125\n",
      "2:  126\n",
      "2:  127\n",
      "2:  128\n",
      "2:  129\n",
      "2:  130\n",
      "2:  131\n",
      "2:  132\n",
      "2:  133\n",
      "2:  134\n",
      "2:  135\n",
      "2:  136\n",
      "2:  137\n",
      "2:  138\n",
      "2:  139\n",
      "2:  140\n",
      "2:  141\n",
      "2:  142\n",
      "2:  143\n",
      "2:  144\n",
      "2:  145\n",
      "2:  146\n",
      "2:  147\n",
      "2:  148\n",
      "2:  149\n",
      "2:  150\n",
      "2:  151\n",
      "2:  152\n",
      "2:  153\n",
      "2:  154\n",
      "2:  155\n",
      "2:  156\n",
      "2:  157\n",
      "2:  158\n",
      "2:  159\n",
      "2:  160\n",
      "2:  161\n",
      "2:  162\n",
      "2:  163\n",
      "2:  164\n",
      "2:  165\n",
      "2:  166\n",
      "2:  167\n",
      "2:  168\n",
      "2:  169\n",
      "2:  170\n",
      "2:  171\n",
      "2:  172\n",
      "2:  173\n",
      "2:  174\n",
      "2:  175\n",
      "2:  176\n",
      "2:  177\n",
      "2:  178\n",
      "2:  179\n",
      "2:  180\n",
      "2:  181\n",
      "2:  182\n",
      "2:  183\n",
      "2:  184\n",
      "2:  185\n",
      "2:  186\n",
      "2:  187\n",
      "2:  188\n",
      "2:  189\n",
      "2:  190\n",
      "2:  191\n",
      "2:  192\n",
      "2:  193\n",
      "2:  194\n",
      "2:  195\n",
      "2:  196\n",
      "2:  197\n",
      "2:  198\n",
      "2:  199\n",
      "2:  200\n",
      "2:  201\n",
      "2:  202\n",
      "2:  203\n",
      "2:  204\n",
      "2:  205\n",
      "2:  206\n",
      "2:  207\n",
      "2:  208\n",
      "2:  209\n",
      "2:  210\n",
      "2:  211\n",
      "2:  212\n",
      "2:  213\n",
      "2:  214\n",
      "2:  215\n",
      "2:  216\n",
      "2:  217\n",
      "2:  218\n",
      "2:  219\n",
      "2:  220\n",
      "2:  221\n",
      "2:  222\n",
      "2:  223\n",
      "2:  224\n",
      "2:  225\n",
      "2:  226\n",
      "2:  227\n",
      "2:  228\n",
      "2:  229\n",
      "2:  230\n",
      "3:  0\n",
      "3:  1\n",
      "3:  2\n",
      "3:  3\n",
      "3:  4\n",
      "3:  5\n",
      "3:  6\n",
      "3:  7\n",
      "3:  8\n",
      "3:  9\n",
      "3:  10\n",
      "3:  11\n",
      "3:  12\n",
      "3:  13\n",
      "3:  14\n",
      "3:  15\n",
      "3:  16\n",
      "3:  17\n",
      "3:  18\n",
      "3:  19\n",
      "3:  20\n",
      "3:  21\n",
      "3:  22\n",
      "3:  23\n",
      "3:  24\n",
      "3:  25\n",
      "3:  26\n",
      "4:  0\n",
      "4:  1\n",
      "4:  2\n",
      "4:  3\n",
      "4:  4\n",
      "4:  5\n",
      "4:  6\n",
      "4:  7\n",
      "4:  8\n",
      "4:  9\n",
      "4:  10\n",
      "4:  11\n",
      "4:  12\n",
      "1:  0\n",
      "1:  1\n",
      "1:  2\n",
      "1:  3\n",
      "1:  4\n",
      "1:  5\n",
      "1:  6\n",
      "1:  7\n",
      "1:  8\n",
      "1:  9\n",
      "1:  10\n",
      "1:  11\n",
      "1:  12\n",
      "1:  13\n",
      "1:  14\n",
      "1:  15\n",
      "1:  16\n",
      "1:  17\n",
      "1:  18\n",
      "1:  19\n",
      "1:  20\n",
      "1:  21\n",
      "1:  22\n",
      "1:  23\n",
      "1:  24\n",
      "1:  25\n",
      "1:  26\n",
      "2:  0\n",
      "2:  1\n",
      "2:  2\n",
      "2:  3\n",
      "2:  4\n",
      "2:  5\n",
      "2:  6\n",
      "2:  7\n",
      "2:  8\n",
      "2:  9\n",
      "2:  10\n",
      "2:  11\n",
      "2:  12\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 0 / 1500 : \n",
      "Training: \n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9f2131f68e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m#print(vae.encoder.sampling.gamma)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mtrain_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtrain_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reconstruction_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 794\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2945\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    792\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 794\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-08c220562be6>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#losses.MSE(y, reconstruction), axis=(1, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d5bc49a88371>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m#x = self.Conv3(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1148\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2592\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2593\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    936\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "#vae = models.load_model(\"/home/ug-ml/felix-ML/VAE_000/Data/Models/VAE_3\")\n",
    "batch_size=32\n",
    "epochs = 1500\n",
    "patience = 100\n",
    "best_model_name = \"VAE_Reduced_J1_V2\"\n",
    "\n",
    "for frac in fractions:\n",
    "    #training and validation histories, containing [0] the total loss, [1] the reconstruction loss, and [2] the kl loss.\n",
    "    val_hist = np.zeros(shape=(3,1,epochs))\n",
    "    train_hist = np.zeros(shape=(3,3,epochs))\n",
    "    james_hist = np.zeros(shape=(3,2))\n",
    "    for run in range(3):\n",
    "        train_indexes = np.arange(0, int(train_len*frac))\n",
    "        val_indexes = np.arange(0, int(val_len*frac))\n",
    "        test_indexes = np.arange(0, int(test_len*frac))\n",
    "        \n",
    "        np.random.shuffle(train_indexes)\n",
    "        wrk_train_in = TrainingPathsInput[train_indexes]\n",
    "        wrk_train_out = TrainingPathsOutput[train_indexes]\n",
    "        \n",
    "        np.random.shuffle(val_indexes)\n",
    "        wrk_val_in = ValidationPathsInput[val_indexes]\n",
    "        wrk_val_out = ValidationPathsOutput[val_indexes]\n",
    "        \n",
    "        np.random.shuffle(test_indexes)\n",
    "        wrk_test_in = TestPathsInput[test_indexes]\n",
    "        wrk_test_out = TestPathsOutput[test_indexes]\n",
    "        \n",
    "        print(wrk_train_in.size, wrk_val_in.size, wrk_test_in.size)\n",
    "        \n",
    "        encoder = Encoder(gamma = 0, name=\"encoder\")\n",
    "        encoder(Input(batch_shape=(None,128,128,1)))\n",
    "        \n",
    "        decoder = Decoder(encoder.layers[1].output_shape, name=\"decoder\")\n",
    "        decoder(Input(batch_shape=(None, latent_dim)))\n",
    "        \n",
    "        \n",
    "        james_hist[run][0], james_hist[run][1] = JeremyFunc([wrk_train_in, wrk_train_out], \n",
    "                                                            [wrk_val_in, wrk_val_out], \n",
    "                                                            [wrk_test_in, wrk_test_out])\n",
    "\n",
    "\n",
    "        vae = VAE(encoder, decoder)\n",
    "        #vae.add_metric(trainable_metric(vae), name=\"testMetric\")\n",
    "        vae.compile(optimizer=optimizers.Adam())\n",
    "\n",
    "\n",
    "        #data_path = \"/home/ug-ml/felix-ML/VAE_000/Data/Data/\"\n",
    "\n",
    "        #data = [i for i in gen_paths_labels(data_path)]\n",
    "        #val_seq = FelixSequence(data[2][0], data[2][1], batch_size)\n",
    "        #train_seq = FelixSequence(data[1][0], data[1][1], batch_size)\n",
    "        #test_seq = FelixSequence(data[0][0], data[0][1], batch_size)\n",
    "\n",
    "        train_seq = FelixSequence(wrk_train_in, wrk_train_out, batch_size)\n",
    "        val_seq = FelixSequence(wrk_val_in, wrk_val_out, batch_size)\n",
    "        test_seq = FelixSequence(wrk_test_in, wrk_test_out, batch_size)\n",
    "\n",
    "        #vae.fit(train_seq, shuffle=True, workers=16, epochs=1500)\n",
    "\n",
    "        \n",
    "        patience_i = 0\n",
    "        best_val_loss = np.inf\n",
    "\n",
    "\n",
    "        for epoch in range(0, epochs):\n",
    "            print(\"-------------------------------------------------------------------------\")\n",
    "            print(\"Epoch\", epoch, \"/\", epochs, \": \")\n",
    "            print(\"Training: \")\n",
    "            vae.encoder.sampling.gamma=1\n",
    "            #print(vae.encoder.sampling.gamma)\n",
    "            hist = vae.fit(x = train_seq, shuffle=True, epochs = epoch+1, workers = 16, initial_epoch=epoch)\n",
    "            train_hist[run][0][epoch] = hist.history[\"loss\"][0]\n",
    "            train_hist[run][1][epoch] = hist.history[\"reconstruction_loss\"][0]\n",
    "            train_hist[run][2][epoch] = hist.history[\"kl_loss\"][0]\n",
    "            print(\"Validation: \")\n",
    "\n",
    "            tot_batch_recon_loss = 0\n",
    "            count = 0\n",
    "            vae.encoder.sampling.gamma=0\n",
    "            #print(vae.encoder.sampling.gamma)\n",
    "            for x, y in val_seq:\n",
    "                #rint(x.shape, y.shape)\n",
    "                count += 1\n",
    "                reconstruction = vae(x)\n",
    "\n",
    "\n",
    "                reconstruction_loss = tf.reduce_mean(\n",
    "                        tf.reduce_sum(\n",
    "                        losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)\n",
    "                        )\n",
    "                    )\n",
    "                tot_batch_recon_loss += reconstruction_loss\n",
    "                #print(batch_log_loss)\n",
    "\n",
    "\n",
    "            avg_recon_loss = float(tot_batch_recon_loss/count)\n",
    "            if(avg_recon_loss < best_val_loss):\n",
    "                vae.save(\"/home/ug-ml/felix-ML/VAE_000/Data/Models/V3/\"+str(frac)+\"_\"+str(run)+\"_\"+str(best_model_name))\n",
    "                print(\"The model improved from: \",best_val_loss, \"to: \", avg_recon_loss)\n",
    "                best_val_loss = avg_recon_loss\n",
    "                patience_i = 0\n",
    "            else:\n",
    "                patience_i+=1\n",
    "                print(\"The model did not improve, patience_i = \", patience_i)\n",
    "\n",
    "            print(\"Average reconstruction loss: \", avg_recon_loss)\n",
    "            val_hist[run][0][epoch] = avg_recon_loss\n",
    "            if(patience_i > patience):\n",
    "                print(\"Early Stopping, the model did not improve from: \", best_val_loss)\n",
    "                break\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "    np.save(str(frac)+\"train_hist.npy\",train_hist)\n",
    "    np.save(str(frac)+\"val_hist.npy\",val_hist)\n",
    "    np.save(str(frac)+\"james_hist.npy\",james_hist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = models.load_model(\"/home/ug-ml/felix-ML/VAE_000/Data/Models/V3/VAE_Reduced_J1_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Log loss is:  150.9521035780591\n",
      "1\n",
      "Log loss is:  139.58232597654379\n",
      "2\n",
      "Log loss is:  140.25573521729714\n",
      "3\n",
      "Log loss is:  159.74543296290943\n",
      "4\n",
      "Log loss is:  970.5655357965074\n",
      "5\n",
      "Log loss is:  299.2838059849387\n",
      "6\n",
      "Log loss is:  863.4023440986342\n",
      "7\n",
      "Log loss is:  256.01782950937604\n",
      "8\n",
      "Log loss is:  16.858475431838652\n",
      "9\n",
      "Log loss is:  15.343558708298012\n",
      "10\n",
      "Log loss is:  10.604404841996622\n",
      "11\n",
      "Log loss is:  16.45698653168146\n",
      "12\n",
      "Log loss is:  727.6787045702097\n",
      "13\n",
      "Log loss is:  741.8464297207776\n",
      "14\n",
      "Log loss is:  729.1622960787136\n",
      "15\n",
      "Log loss is:  782.0975803183998\n",
      "16\n",
      "Log loss is:  828.0612622289904\n",
      "17\n",
      "Log loss is:  786.2943505032459\n",
      "18\n",
      "Log loss is:  917.7346617030947\n",
      "19\n",
      "Log loss is:  820.1610219043052\n",
      "20\n",
      "Log loss is:  19.01610904276879\n",
      "21\n",
      "Log loss is:  9.885530392628585\n",
      "22\n",
      "Log loss is:  15.581409904224715\n",
      "23\n",
      "Log loss is:  17.930257188739006\n",
      "24\n",
      "Log loss is:  85.63968410640935\n",
      "25\n",
      "Log loss is:  74.07340403087139\n",
      "26\n",
      "Log loss is:  74.07129458910568\n",
      "27\n",
      "Log loss is:  85.61590410893363\n",
      "28\n",
      "Log loss is:  1249.795572133403\n",
      "29\n",
      "Log loss is:  1249.7968622846033\n",
      "30\n",
      "Log loss is:  1249.7972783755376\n",
      "31\n",
      "Log loss is:  1249.797370859644\n",
      "32\n",
      "Log loss is:  68.62922046829783\n",
      "33\n",
      "Log loss is:  73.43615149505264\n",
      "34\n",
      "Log loss is:  73.43563141551478\n",
      "35\n",
      "Log loss is:  68.63682237132247\n",
      "36\n",
      "Log loss is:  24.86418494970015\n",
      "37\n",
      "Log loss is:  31.92248205980095\n",
      "38\n",
      "Log loss is:  31.926566116579092\n",
      "39\n",
      "Log loss is:  24.869432683429515\n",
      "40\n",
      "Log loss is:  14.080931960733453\n",
      "41\n",
      "Log loss is:  9.155537462589514\n",
      "42\n",
      "Log loss is:  9.157713876013853\n",
      "43\n",
      "Log loss is:  14.073526388620241\n",
      "44\n",
      "Log loss is:  9.702076489112795\n",
      "45\n",
      "Log loss is:  9.457055659149352\n",
      "46\n",
      "Log loss is:  9.465143059230394\n",
      "47\n",
      "Log loss is:  9.745593454489097\n",
      "48\n",
      "Log loss is:  303.3081886123319\n",
      "49\n",
      "Log loss is:  560.0415018303445\n",
      "50\n",
      "Log loss is:  560.0940668016846\n",
      "51\n",
      "Log loss is:  303.2880601677742\n",
      "52\n",
      "Log loss is:  44.45436839303055\n",
      "53\n",
      "Log loss is:  38.72084957776701\n",
      "54\n",
      "Log loss is:  38.717395543288035\n",
      "55\n",
      "Log loss is:  44.45595704777442\n",
      "56\n",
      "Log loss is:  53.234766953270416\n",
      "57\n",
      "Log loss is:  70.28414358503481\n",
      "58\n",
      "Log loss is:  70.28855430455303\n",
      "59\n",
      "Log loss is:  53.23095913618722\n",
      "60\n",
      "Log loss is:  29.29347360005464\n",
      "61\n",
      "Log loss is:  30.077464899989167\n",
      "62\n",
      "Log loss is:  30.070913958981983\n",
      "63\n",
      "Log loss is:  29.302313663445606\n",
      "64\n",
      "Log loss is:  16.33740721313534\n",
      "65\n",
      "Log loss is:  19.65784888736776\n",
      "66\n",
      "Log loss is:  19.663785717929727\n",
      "67\n",
      "Log loss is:  16.36288509521019\n",
      "68\n",
      "Log loss is:  256.6081538993804\n",
      "69\n",
      "Log loss is:  183.28442120381987\n",
      "70\n",
      "Log loss is:  183.28957035245446\n",
      "71\n",
      "Log loss is:  256.5912314655395\n",
      "72\n",
      "Log loss is:  22.704757293976765\n",
      "73\n",
      "Log loss is:  23.88188300032787\n",
      "74\n",
      "Log loss is:  23.875070445770827\n",
      "75\n",
      "Log loss is:  22.7217151268527\n",
      "76\n",
      "Log loss is:  29.242853845197754\n",
      "77\n",
      "Log loss is:  29.79378464478381\n",
      "78\n",
      "Log loss is:  29.811908343686348\n",
      "79\n",
      "Log loss is:  29.327907762004266\n",
      "80\n",
      "Log loss is:  36.22585142159368\n",
      "81\n",
      "Log loss is:  42.09186643295402\n",
      "82\n",
      "Log loss is:  42.0924257931053\n",
      "83\n",
      "Log loss is:  36.2184578163559\n",
      "84\n",
      "Log loss is:  42.60864866395863\n",
      "85\n",
      "Log loss is:  28.059246564609364\n",
      "86\n",
      "Log loss is:  28.05082980639475\n",
      "87\n",
      "Log loss is:  42.52350815523132\n",
      "88\n",
      "Log loss is:  16.30909216841989\n",
      "89\n",
      "Log loss is:  15.769821722104304\n",
      "90\n",
      "Log loss is:  15.7812883131816\n",
      "91\n",
      "Log loss is:  16.35080280353186\n",
      "92\n",
      "Log loss is:  35.85715878903507\n",
      "93\n",
      "Log loss is:  31.619193924223506\n",
      "94\n",
      "Log loss is:  31.642010942414366\n",
      "95\n",
      "Log loss is:  35.84095694210833\n",
      "96\n",
      "Log loss is:  32.695278452886114\n",
      "97\n",
      "Log loss is:  18.565260607124944\n",
      "98\n",
      "Log loss is:  18.598528035453178\n",
      "99\n",
      "Log loss is:  32.73057513090667\n",
      "100\n",
      "Log loss is:  24.12203068553716\n",
      "101\n",
      "Log loss is:  22.858742783853362\n",
      "102\n",
      "Log loss is:  22.858876944713373\n",
      "103\n",
      "Log loss is:  24.12631870540127\n",
      "104\n",
      "Log loss is:  44.267008776225886\n",
      "105\n",
      "Log loss is:  43.289070309179955\n",
      "106\n",
      "Log loss is:  43.272808326186556\n",
      "107\n",
      "Log loss is:  44.26760795993757\n",
      "108\n",
      "Log loss is:  12.230428047980684\n",
      "109\n",
      "Log loss is:  12.725591011275581\n",
      "110\n",
      "Log loss is:  12.730060625218357\n",
      "111\n",
      "Log loss is:  12.231508860577492\n",
      "112\n",
      "Log loss is:  235.2469927687154\n",
      "113\n",
      "Log loss is:  230.01763351089346\n",
      "114\n",
      "Log loss is:  230.00725583949568\n",
      "115\n",
      "Log loss is:  235.36069472756466\n",
      "116\n",
      "Log loss is:  48.40082795453548\n",
      "117\n",
      "Log loss is:  41.492754723366005\n",
      "118\n",
      "Log loss is:  41.48653961509828\n",
      "119\n",
      "Log loss is:  48.37382990266874\n",
      "120\n",
      "Log loss is:  20.289486774950266\n",
      "121\n",
      "Log loss is:  21.300148921717707\n",
      "122\n",
      "Log loss is:  21.300430764168294\n",
      "123\n",
      "Log loss is:  20.29254664508713\n",
      "124\n",
      "Log loss is:  14.040977162286872\n",
      "125\n",
      "Log loss is:  14.14869676914394\n",
      "126\n",
      "Log loss is:  14.139234131072435\n",
      "127\n",
      "Log loss is:  14.038678535652819\n",
      "128\n",
      "Log loss is:  112.91935133721228\n",
      "129\n",
      "Log loss is:  108.17653443175853\n",
      "130\n",
      "Log loss is:  108.17689217096526\n",
      "131\n",
      "Log loss is:  112.9228435454539\n",
      "132\n",
      "Log loss is:  23.485050175377896\n",
      "133\n",
      "Log loss is:  21.388325341989784\n",
      "134\n",
      "Log loss is:  21.38569626152229\n",
      "135\n",
      "Log loss is:  23.494640201137813\n",
      "136\n",
      "Log loss is:  7.921609480198227\n",
      "137\n",
      "Log loss is:  8.8790824601368\n",
      "138\n",
      "Log loss is:  8.889040648320622\n",
      "139\n",
      "Log loss is:  7.959980004763502\n",
      "140\n",
      "Log loss is:  192.20219951776954\n",
      "141\n",
      "Log loss is:  227.7115875633247\n",
      "142\n",
      "Log loss is:  227.58340515494072\n",
      "143\n",
      "Log loss is:  192.12062352291784\n",
      "144\n",
      "Log loss is:  8.385447826629735\n",
      "145\n",
      "Log loss is:  7.8122664344544335\n",
      "146\n",
      "Log loss is:  7.81117882022243\n",
      "147\n",
      "Log loss is:  8.393940242776994\n",
      "148\n",
      "Log loss is:  36.78572649797857\n",
      "149\n",
      "Log loss is:  36.05158187800848\n",
      "150\n",
      "Log loss is:  36.052125445008215\n",
      "151\n",
      "Log loss is:  36.787649763556864\n",
      "152\n",
      "Log loss is:  10.838140237214851\n",
      "153\n",
      "Log loss is:  9.848700329400213\n",
      "154\n",
      "Log loss is:  9.850331337929871\n",
      "155\n",
      "Log loss is:  10.8420751022286\n",
      "156\n",
      "Log loss is:  319.114059639414\n",
      "157\n",
      "Log loss is:  249.77400141104093\n",
      "158\n",
      "Log loss is:  249.79920229433512\n",
      "159\n",
      "Log loss is:  319.0178918045991\n",
      "160\n",
      "Log loss is:  46.49519485667055\n",
      "161\n",
      "Log loss is:  40.89510152029252\n",
      "162\n",
      "Log loss is:  40.87974556803676\n",
      "163\n",
      "Log loss is:  46.92064792893916\n",
      "164\n",
      "Log loss is:  7.835885531387104\n",
      "165\n",
      "Log loss is:  9.039790058468126\n",
      "166\n",
      "Log loss is:  9.04415438524701\n",
      "167\n",
      "Log loss is:  7.842238816020872\n",
      "168\n",
      "Log loss is:  108.29482253349185\n",
      "169\n",
      "Log loss is:  42.70255307606447\n",
      "170\n",
      "Log loss is:  42.53270115544156\n",
      "171\n",
      "Log loss is:  108.44647567690242\n",
      "172\n",
      "Log loss is:  47.78093960453299\n",
      "173\n",
      "Log loss is:  33.955646576333244\n",
      "174\n",
      "Log loss is:  33.96149744728704\n",
      "175\n",
      "Log loss is:  47.96125578838398\n",
      "176\n",
      "Log loss is:  22.360949527998784\n",
      "177\n",
      "Log loss is:  15.52920713334431\n",
      "178\n",
      "Log loss is:  23.363484009910945\n",
      "179\n",
      "Log loss is:  13.630672270572088\n",
      "180\n",
      "Log loss is:  165.3058299738189\n",
      "181\n",
      "Log loss is:  161.05217281259615\n",
      "182\n",
      "Log loss is:  221.0352454202356\n",
      "183\n",
      "Log loss is:  183.6558867433916\n",
      "184\n",
      "Log loss is:  99.10167644083828\n",
      "185\n",
      "Log loss is:  98.62586279730164\n",
      "186\n",
      "Log loss is:  95.81928563462732\n",
      "187\n",
      "Log loss is:  96.3071097873726\n",
      "188\n",
      "Log loss is:  318.93878847259674\n",
      "189\n",
      "Log loss is:  247.09742395039902\n",
      "190\n",
      "Log loss is:  560.0797127758045\n",
      "191\n",
      "Log loss is:  174.38686888323525\n",
      "192\n",
      "Log loss is:  42.683822662279496\n",
      "193\n",
      "Log loss is:  50.97861430748823\n",
      "194\n",
      "Log loss is:  44.25412321639756\n",
      "195\n",
      "Log loss is:  48.09257890664117\n",
      "196\n",
      "Log loss is:  11.515097845050152\n",
      "197\n",
      "Log loss is:  19.278178464955722\n",
      "198\n",
      "Log loss is:  19.254673025498384\n",
      "199\n",
      "Log loss is:  11.50950609665939\n",
      "200\n",
      "Log loss is:  585.5929241908043\n",
      "201\n",
      "Log loss is:  584.9557341625363\n",
      "202\n",
      "Log loss is:  1236.47231459972\n",
      "203\n",
      "Log loss is:  1244.6985474874234\n",
      "204\n",
      "Log loss is:  304.7942864525976\n",
      "205\n",
      "Log loss is:  491.2087344316997\n",
      "206\n",
      "Log loss is:  405.5612750349357\n",
      "207\n",
      "Log loss is:  295.5659839994553\n",
      "208\n",
      "Log loss is:  155.80265729218456\n",
      "209\n",
      "Log loss is:  141.2742458954957\n",
      "210\n",
      "Log loss is:  171.28976151530523\n",
      "211\n",
      "Log loss is:  121.27203252953797\n",
      "212\n",
      "Log loss is:  341.4682483454776\n",
      "213\n",
      "Log loss is:  703.370684329337\n",
      "214\n",
      "Log loss is:  458.07781780529984\n",
      "215\n",
      "Log loss is:  551.9948368604389\n",
      "216\n",
      "Log loss is:  537.2335378436316\n",
      "217\n",
      "Log loss is:  607.4594907824187\n",
      "218\n",
      "Log loss is:  591.2729274409976\n",
      "219\n",
      "Log loss is:  443.5431178095225\n",
      "220\n",
      "Log loss is:  41.835664233080955\n",
      "221\n",
      "Log loss is:  71.6827067486308\n",
      "222\n",
      "Log loss is:  45.454566336777084\n",
      "223\n",
      "Log loss is:  33.958202219139615\n",
      "224\n",
      "Log loss is:  266.6111431724402\n",
      "225\n",
      "Log loss is:  176.69766037012718\n",
      "226\n",
      "Log loss is:  121.11400405288018\n",
      "227\n",
      "Log loss is:  407.79123250502954\n",
      "228\n",
      "Log loss is:  27.841827848451867\n",
      "229\n",
      "Log loss is:  30.295887135915283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "Log loss is:  25.265844647946096\n",
      "231\n",
      "Log loss is:  25.64150304465424\n",
      "232\n",
      "Log loss is:  274.88143201044204\n",
      "233\n",
      "Log loss is:  185.07714091633656\n",
      "234\n",
      "Log loss is:  258.44187633023466\n",
      "235\n",
      "Log loss is:  257.7984857925024\n",
      "236\n",
      "Log loss is:  137.19110035050974\n",
      "237\n",
      "Log loss is:  343.492106407778\n",
      "238\n",
      "Log loss is:  500.5312499921055\n",
      "239\n",
      "Log loss is:  166.51183603794996\n",
      "240\n",
      "Log loss is:  46.84907485280093\n",
      "241\n",
      "Log loss is:  35.142878827488715\n",
      "242\n",
      "Log loss is:  35.14989730567991\n",
      "243\n",
      "Log loss is:  46.98161373917586\n",
      "244\n",
      "Log loss is:  443.5051947743535\n",
      "245\n",
      "Log loss is:  610.538058865001\n",
      "246\n",
      "Log loss is:  484.6431768443484\n",
      "247\n",
      "Log loss is:  385.7182324644637\n",
      "248\n",
      "Log loss is:  477.0927680288722\n",
      "249\n",
      "Log loss is:  326.53149048695286\n",
      "250\n",
      "Log loss is:  66.01124134831731\n",
      "251\n",
      "Log loss is:  863.7135223742094\n",
      "252\n",
      "Log loss is:  389.5655991661281\n",
      "253\n",
      "Log loss is:  338.56572414869186\n",
      "254\n",
      "Log loss is:  338.6674652979036\n",
      "255\n",
      "Log loss is:  389.5811565276222\n",
      "256\n",
      "Log loss is:  45.341873249367154\n",
      "257\n",
      "Log loss is:  35.87217613924923\n",
      "258\n",
      "Log loss is:  35.86919244525194\n",
      "259\n",
      "Log loss is:  45.35551255130643\n",
      "260\n",
      "Log loss is:  443.20591139153396\n",
      "261\n",
      "Log loss is:  699.7205806245148\n",
      "262\n",
      "Log loss is:  699.7658350221022\n",
      "263\n",
      "Log loss is:  442.7964013144881\n",
      "264\n",
      "Log loss is:  17.588927920980495\n",
      "265\n",
      "Log loss is:  15.250286095248976\n",
      "266\n",
      "Log loss is:  15.239253917958349\n",
      "267\n",
      "Log loss is:  17.600236169839935\n",
      "268\n",
      "Log loss is:  13.074471720285704\n",
      "269\n",
      "Log loss is:  18.425326804980358\n",
      "270\n",
      "Log loss is:  18.380599426205887\n",
      "271\n",
      "Log loss is:  13.091406174053079\n",
      "272\n",
      "Log loss is:  20.003705572936877\n",
      "273\n",
      "Log loss is:  12.642724602942764\n",
      "274\n",
      "Log loss is:  12.634025364928066\n",
      "275\n",
      "Log loss is:  20.011133485855275\n",
      "276\n",
      "Log loss is:  15.022661428278276\n",
      "277\n",
      "Log loss is:  18.418494494070238\n",
      "278\n",
      "Log loss is:  18.414692666345168\n",
      "279\n",
      "Log loss is:  15.022458215301901\n",
      "280\n",
      "Log loss is:  26.19217489882667\n",
      "281\n",
      "Log loss is:  26.539556815558715\n",
      "282\n",
      "Log loss is:  26.5380007133306\n",
      "283\n",
      "Log loss is:  26.196123960831216\n",
      "284\n",
      "Log loss is:  18.02911690417977\n",
      "285\n",
      "Log loss is:  12.262079441594867\n",
      "286\n",
      "Log loss is:  12.228842643945896\n",
      "287\n",
      "Log loss is:  18.03127828854919\n",
      "288\n",
      "Log loss is:  19.923582158231575\n",
      "289\n",
      "Log loss is:  19.367351582909464\n",
      "290\n",
      "Log loss is:  19.356529217774366\n",
      "291\n",
      "Log loss is:  19.947095334220943\n",
      "292\n",
      "Log loss is:  15.173249260224484\n",
      "293\n",
      "Log loss is:  33.14154642906422\n",
      "294\n",
      "Log loss is:  33.12487353492191\n",
      "295\n",
      "Log loss is:  15.19730375149727\n",
      "296\n",
      "Log loss is:  6.758164755941894\n",
      "297\n",
      "Log loss is:  5.122774110160344\n",
      "298\n",
      "Log loss is:  5.1395383866918785\n",
      "299\n",
      "Log loss is:  6.770799750689044\n",
      "300\n",
      "Log loss is:  116.98430254458997\n",
      "301\n",
      "Log loss is:  128.08151024019062\n",
      "302\n",
      "Log loss is:  128.09547754481392\n",
      "303\n",
      "Log loss is:  117.0016548456161\n",
      "304\n",
      "Log loss is:  49.79553218594784\n",
      "305\n",
      "Log loss is:  46.106882334777254\n",
      "306\n",
      "Log loss is:  46.08437631856594\n",
      "307\n",
      "Log loss is:  49.79759511454244\n",
      "308\n",
      "Log loss is:  327.5370429912045\n",
      "309\n",
      "Log loss is:  328.21791425066806\n",
      "310\n",
      "Log loss is:  328.2452029107949\n",
      "311\n",
      "Log loss is:  327.45378520805986\n",
      "312\n",
      "Log loss is:  25.679986406592956\n",
      "313\n",
      "Log loss is:  25.612939435530517\n",
      "314\n",
      "Log loss is:  25.620821911800842\n",
      "315\n",
      "Log loss is:  25.691053666861222\n",
      "316\n",
      "Log loss is:  14.726082628185212\n",
      "317\n",
      "Log loss is:  15.513531016677447\n",
      "318\n",
      "Log loss is:  15.51696726314483\n",
      "319\n",
      "Log loss is:  14.725928560835575\n",
      "320\n",
      "Log loss is:  485.25059149381457\n",
      "321\n",
      "Log loss is:  107.10557250036763\n",
      "322\n",
      "Log loss is:  107.10488575387241\n",
      "323\n",
      "Log loss is:  485.2485888217722\n",
      "324\n",
      "Log loss is:  9.192415680159113\n",
      "325\n",
      "Log loss is:  8.408737057887924\n",
      "326\n",
      "Log loss is:  8.418813320497836\n",
      "327\n",
      "Log loss is:  9.1847122115126\n",
      "328\n",
      "Log loss is:  8.614841874461398\n",
      "329\n",
      "Log loss is:  7.057630756939411\n",
      "330\n",
      "Log loss is:  7.054176132017642\n",
      "331\n",
      "Log loss is:  8.618551443871931\n",
      "332\n",
      "Log loss is:  18.509220391002245\n",
      "333\n",
      "Log loss is:  18.599042656815655\n",
      "334\n",
      "Log loss is:  18.59034796769593\n",
      "335\n",
      "Log loss is:  18.567549595994947\n",
      "336\n",
      "Log loss is:  17.094312921634792\n",
      "337\n",
      "Log loss is:  16.74935485533276\n",
      "338\n",
      "Log loss is:  16.733435682058584\n",
      "339\n",
      "Log loss is:  17.221269663820127\n",
      "340\n",
      "Log loss is:  12.642541337832975\n",
      "341\n",
      "Log loss is:  17.17221338756711\n",
      "342\n",
      "Log loss is:  17.13877926862948\n",
      "343\n",
      "Log loss is:  12.670214388065254\n",
      "344\n",
      "Log loss is:  49.32783628647514\n",
      "345\n",
      "Log loss is:  51.92399592542144\n",
      "346\n",
      "Log loss is:  51.921473831778385\n",
      "347\n",
      "Log loss is:  49.3598008714887\n",
      "348\n",
      "Log loss is:  135.89938685351652\n",
      "349\n",
      "Log loss is:  135.8929439459158\n",
      "350\n",
      "Log loss is:  135.9005891184556\n",
      "351\n",
      "Log loss is:  135.97817474873955\n",
      "352\n",
      "Log loss is:  61.95621709841744\n",
      "353\n",
      "Log loss is:  56.43126834451648\n",
      "354\n",
      "Log loss is:  62.0722916445407\n",
      "355\n",
      "Log loss is:  54.12787229585586\n",
      "356\n",
      "Log loss is:  109.85888948620313\n",
      "357\n",
      "Log loss is:  152.2206103829751\n",
      "358\n",
      "Log loss is:  127.80881440425176\n",
      "359\n",
      "Log loss is:  126.73629516880536\n",
      "360\n",
      "Log loss is:  39.98868814234344\n",
      "361\n",
      "Log loss is:  53.77500392934551\n",
      "362\n",
      "Log loss is:  55.11355108864526\n",
      "363\n",
      "Log loss is:  37.33014200167804\n",
      "364\n",
      "Log loss is:  14.86670921414796\n",
      "365\n",
      "Log loss is:  10.853524751116073\n",
      "366\n",
      "Log loss is:  10.977380630913974\n",
      "367\n",
      "Log loss is:  12.694110764540477\n",
      "368\n",
      "Log loss is:  208.56174986657126\n",
      "369\n",
      "Log loss is:  123.24717521497762\n",
      "370\n",
      "Log loss is:  193.32621421072048\n",
      "371\n",
      "Log loss is:  90.4289003878354\n",
      "372\n",
      "Log loss is:  85.94643244699095\n",
      "373\n",
      "Log loss is:  67.56371130827605\n",
      "374\n",
      "Log loss is:  46.71597012753776\n",
      "375\n",
      "Log loss is:  52.2877979099872\n",
      "376\n",
      "Log loss is:  349.472346328921\n",
      "377\n",
      "Log loss is:  340.78862725073725\n",
      "378\n",
      "Log loss is:  326.5447586296946\n",
      "379\n",
      "Log loss is:  205.4118652021669\n",
      "380\n",
      "Log loss is:  45.70850023003838\n",
      "381\n",
      "Log loss is:  46.69682659791468\n",
      "382\n",
      "Log loss is:  43.18146239181699\n",
      "383\n",
      "Log loss is:  41.219145071233946\n",
      "384\n",
      "Log loss is:  24.682338599538962\n",
      "385\n",
      "Log loss is:  37.77844327033871\n",
      "386\n",
      "Log loss is:  23.669862848281888\n",
      "387\n",
      "Log loss is:  27.429747042517477\n",
      "388\n",
      "Log loss is:  98.52559635084984\n",
      "389\n",
      "Log loss is:  138.11154541114524\n",
      "390\n",
      "Log loss is:  148.8068048890347\n",
      "391\n",
      "Log loss is:  101.92895706642615\n",
      "392\n",
      "Log loss is:  51.454210707841995\n",
      "393\n",
      "Log loss is:  51.88771380315737\n",
      "394\n",
      "Log loss is:  53.98389502675384\n",
      "395\n",
      "Log loss is:  53.95156304905906\n",
      "396\n",
      "Log loss is:  180.49195241701625\n",
      "397\n",
      "Log loss is:  176.60435653821443\n",
      "398\n",
      "Log loss is:  194.6154785155654\n",
      "399\n",
      "Log loss is:  178.9608771596153\n",
      "400\n",
      "Log loss is:  14.87233999503761\n",
      "401\n",
      "Log loss is:  14.28568169003029\n",
      "402\n",
      "Log loss is:  14.493756964407114\n",
      "403\n",
      "Log loss is:  12.577764414747492\n",
      "404\n",
      "Log loss is:  87.68295383327334\n",
      "405\n",
      "Log loss is:  90.71764869798767\n",
      "406\n",
      "Log loss is:  90.72367089897878\n",
      "407\n",
      "Log loss is:  95.10344517302302\n",
      "408\n",
      "Log loss is:  70.16694211419758\n",
      "409\n",
      "Log loss is:  69.10635012976654\n",
      "410\n",
      "Log loss is:  69.18932806779132\n",
      "411\n",
      "Log loss is:  64.85697752556136\n",
      "412\n",
      "Log loss is:  42.92100196320158\n",
      "413\n",
      "Log loss is:  51.58057892067933\n",
      "414\n",
      "Log loss is:  51.60482641931138\n",
      "415\n",
      "Log loss is:  44.38401435283322\n",
      "416\n",
      "Log loss is:  274.2249802215779\n",
      "417\n",
      "Log loss is:  274.1023148230767\n",
      "418\n",
      "Log loss is:  274.1047235657489\n",
      "419\n",
      "Log loss is:  274.15540871590014\n",
      "420\n",
      "Log loss is:  627.2879624715312\n",
      "421\n",
      "Log loss is:  627.5260245148701\n",
      "422\n",
      "Log loss is:  627.512851059123\n",
      "423\n",
      "Log loss is:  627.2887358186742\n",
      "424\n",
      "Log loss is:  55.720324527277555\n",
      "425\n",
      "Log loss is:  55.67498964901624\n",
      "426\n",
      "Log loss is:  55.67157331648144\n",
      "427\n",
      "Log loss is:  55.696067443236046\n",
      "428\n",
      "Log loss is:  63.29982494525585\n",
      "429\n",
      "Log loss is:  60.68650519674452\n",
      "430\n",
      "Log loss is:  61.67872293379121\n",
      "431\n",
      "Log loss is:  63.727365511977816\n",
      "432\n",
      "Log loss is:  25.302190417892678\n",
      "433\n",
      "Log loss is:  25.302593763114405\n",
      "434\n",
      "Log loss is:  25.30246208110346\n",
      "435\n",
      "Log loss is:  25.30229710265556\n",
      "436\n",
      "Log loss is:  84.46127858572345\n",
      "437\n",
      "Log loss is:  110.45592486517373\n",
      "438\n",
      "Log loss is:  113.48916458745879\n",
      "439\n",
      "Log loss is:  58.59546328523968\n",
      "440\n",
      "Log loss is:  87.24115081402253\n",
      "441\n",
      "Log loss is:  81.72373075323091\n",
      "442\n",
      "Log loss is:  93.085039323377\n",
      "443\n",
      "Log loss is:  112.74720738424563\n",
      "444\n",
      "Log loss is:  295.57739691549205\n",
      "445\n",
      "Log loss is:  295.6107561368644\n",
      "446\n",
      "Log loss is:  295.6096550548223\n",
      "447\n",
      "Log loss is:  295.5982097716372\n",
      "448\n",
      "Log loss is:  46.70584685667079\n",
      "449\n",
      "Log loss is:  46.70584492993546\n",
      "450\n",
      "Log loss is:  46.70584713468318\n",
      "451\n",
      "Log loss is:  46.70584478482108\n",
      "452\n",
      "Log loss is:  74.38674518094474\n",
      "453\n",
      "Log loss is:  74.3867625000418\n",
      "454\n",
      "Log loss is:  74.38676549607614\n",
      "455\n",
      "Log loss is:  74.38676526278331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "Log loss is:  60.31906338067299\n",
      "457\n",
      "Log loss is:  60.34611012809597\n",
      "458\n",
      "Log loss is:  60.34080502482572\n",
      "459\n",
      "Log loss is:  60.361852265724856\n",
      "460\n",
      "Log loss is:  56.770740437128104\n",
      "461\n",
      "Log loss is:  56.77059467859766\n",
      "462\n",
      "Log loss is:  56.77077946005718\n",
      "463\n",
      "Log loss is:  56.77090299225435\n",
      "464\n",
      "Log loss is:  14.937363366528242\n",
      "465\n",
      "Log loss is:  14.901773701438684\n",
      "466\n",
      "Log loss is:  14.919099083188204\n",
      "467\n",
      "Log loss is:  14.93488142548405\n",
      "468\n",
      "Log loss is:  127.40276274667458\n",
      "469\n",
      "Log loss is:  127.40919922528559\n",
      "470\n",
      "Log loss is:  127.40832654742137\n",
      "471\n",
      "Log loss is:  127.40317622318874\n",
      "472\n",
      "Log loss is:  174.19939232321843\n",
      "473\n",
      "Log loss is:  174.20473303975461\n",
      "474\n",
      "Log loss is:  174.2017302187228\n",
      "475\n",
      "Log loss is:  174.1937583324145\n",
      "476\n",
      "Log loss is:  46.45424307258068\n",
      "477\n",
      "Log loss is:  46.31875095967196\n",
      "478\n",
      "Log loss is:  46.37101640250841\n",
      "479\n",
      "Log loss is:  46.50395030228677\n",
      "480\n",
      "Log loss is:  23.243466988097143\n",
      "481\n",
      "Log loss is:  28.281872362537776\n",
      "482\n",
      "Log loss is:  25.39598556829798\n",
      "483\n",
      "Log loss is:  75.93555869026771\n",
      "484\n",
      "Log loss is:  216.6015607744899\n",
      "485\n",
      "Log loss is:  216.79323750745854\n",
      "486\n",
      "Log loss is:  216.81736481426057\n",
      "487\n",
      "Log loss is:  216.64016940771458\n",
      "488\n",
      "Log loss is:  30.566426089951328\n",
      "489\n",
      "Log loss is:  30.56664821638101\n",
      "490\n",
      "Log loss is:  30.567912491062433\n",
      "491\n",
      "Log loss is:  30.566590070766924\n",
      "492\n",
      "Log loss is:  20.557782085185966\n",
      "493\n",
      "Log loss is:  20.567866226121094\n",
      "494\n",
      "Log loss is:  20.5586627237085\n",
      "495\n",
      "Log loss is:  20.55097437984359\n",
      "496\n",
      "Log loss is:  165.50191424955585\n",
      "497\n",
      "Log loss is:  165.50507316286343\n",
      "498\n",
      "Log loss is:  165.5032362460939\n",
      "499\n",
      "Log loss is:  165.48000227108122\n",
      "500\n",
      "Log loss is:  108.20244606122873\n",
      "501\n",
      "Log loss is:  108.20270273913215\n",
      "502\n",
      "Log loss is:  108.20270835124644\n",
      "503\n",
      "Log loss is:  108.20244633469285\n",
      "504\n",
      "Log loss is:  536.4211629533386\n",
      "505\n",
      "Log loss is:  206.143112461801\n",
      "506\n",
      "Log loss is:  206.14448897787236\n",
      "507\n",
      "Log loss is:  536.4334576473885\n",
      "508\n",
      "Log loss is:  7.799896965361506\n",
      "509\n",
      "Log loss is:  7.8009747560928915\n",
      "510\n",
      "Log loss is:  7.800131474058861\n",
      "511\n",
      "Log loss is:  7.799413519094966\n",
      "512\n",
      "Log loss is:  96.57616035818756\n",
      "513\n",
      "Log loss is:  96.42293380228334\n",
      "514\n",
      "Log loss is:  96.4321650676541\n",
      "515\n",
      "Log loss is:  96.53647749133462\n",
      "516\n",
      "Log loss is:  190.7093115291284\n",
      "517\n",
      "Log loss is:  190.71069192051195\n",
      "518\n",
      "Log loss is:  190.7111776223839\n",
      "519\n",
      "Log loss is:  190.71075725415298\n",
      "520\n",
      "Log loss is:  15.83514173552723\n",
      "521\n",
      "Log loss is:  15.852741540429362\n",
      "522\n",
      "Log loss is:  15.836902618430134\n",
      "523\n",
      "Log loss is:  15.834240480286248\n",
      "524\n",
      "Log loss is:  25.619673695523897\n",
      "525\n",
      "Log loss is:  25.630629673748174\n",
      "526\n",
      "Log loss is:  25.620392391859998\n",
      "527\n",
      "Log loss is:  25.619725854554268\n",
      "528\n",
      "Log loss is:  211.22853360776602\n",
      "529\n",
      "Log loss is:  211.21740405241252\n",
      "530\n",
      "Log loss is:  211.22498651608805\n",
      "531\n",
      "Log loss is:  211.24014731403858\n",
      "532\n",
      "Log loss is:  971.5775356027917\n",
      "533\n",
      "Log loss is:  971.8752951087838\n",
      "534\n",
      "Log loss is:  971.7860877632439\n",
      "535\n",
      "Log loss is:  971.6572858452516\n",
      "536\n",
      "Log loss is:  18.47874523568753\n",
      "537\n",
      "Log loss is:  25.75145902236281\n",
      "538\n",
      "Log loss is:  24.816046728043855\n",
      "539\n",
      "Log loss is:  18.34638345495244\n",
      "540\n",
      "Log loss is:  6.993989966609398\n",
      "541\n",
      "Log loss is:  6.987249938770233\n",
      "542\n",
      "Log loss is:  6.9864847959514496\n",
      "543\n",
      "Log loss is:  7.017739441322442\n",
      "544\n",
      "Log loss is:  22.73375814284452\n",
      "545\n",
      "Log loss is:  22.715844810972726\n",
      "546\n",
      "Log loss is:  22.693961219286795\n",
      "547\n",
      "Log loss is:  22.756954147282176\n",
      "548\n",
      "Log loss is:  642.6530967709324\n",
      "549\n",
      "Log loss is:  642.7950876456429\n",
      "550\n",
      "Log loss is:  642.8374473397103\n",
      "551\n",
      "Log loss is:  642.68417551487\n",
      "552\n",
      "Log loss is:  15.261879084676071\n",
      "553\n",
      "Log loss is:  22.58270944547212\n",
      "554\n",
      "Log loss is:  22.230679678050244\n",
      "555\n",
      "Log loss is:  28.034340458159217\n",
      "556\n",
      "Log loss is:  32.229695029614426\n",
      "557\n",
      "Log loss is:  32.167536891526034\n",
      "558\n",
      "Log loss is:  32.17544002146328\n",
      "559\n",
      "Log loss is:  32.18131993021038\n",
      "560\n",
      "Log loss is:  7.932787948009244\n",
      "561\n",
      "Log loss is:  7.946739869474279\n",
      "562\n",
      "Log loss is:  7.945583967287663\n",
      "563\n",
      "Log loss is:  7.982911053204557\n",
      "564\n",
      "Log loss is:  12.20981549743282\n",
      "565\n",
      "Log loss is:  12.208928924188465\n",
      "566\n",
      "Log loss is:  12.21048628270964\n",
      "567\n",
      "Log loss is:  12.212456391057591\n",
      "568\n",
      "Log loss is:  237.98031111506768\n",
      "569\n",
      "Log loss is:  252.96168455522786\n",
      "570\n",
      "Log loss is:  305.55472901169543\n",
      "571\n",
      "Log loss is:  458.39589267763137\n",
      "572\n",
      "Log loss is:  494.658966063188\n",
      "573\n",
      "Log loss is:  494.78080379805454\n",
      "574\n",
      "Log loss is:  494.7921525653833\n",
      "575\n",
      "Log loss is:  494.8317115502404\n",
      "576\n",
      "Log loss is:  188.31258738451572\n",
      "577\n",
      "Log loss is:  211.77393776977186\n",
      "578\n",
      "Log loss is:  166.81244664022947\n",
      "579\n",
      "Log loss is:  178.50082771066246\n",
      "580\n",
      "Log loss is:  8.764473094591663\n",
      "581\n",
      "Log loss is:  11.077385836179634\n",
      "582\n",
      "Log loss is:  11.076491359371436\n",
      "583\n",
      "Log loss is:  8.770215679600224\n",
      "584\n",
      "Log loss is:  30.946344377979344\n",
      "585\n",
      "Log loss is:  25.449060492416685\n",
      "586\n",
      "Log loss is:  25.448005842115805\n",
      "587\n",
      "Log loss is:  30.942541208855175\n",
      "588\n",
      "Log loss is:  31.574144938146016\n",
      "589\n",
      "Log loss is:  30.17333923974799\n",
      "590\n",
      "Log loss is:  30.166999704608394\n",
      "591\n",
      "Log loss is:  31.591822807942666\n",
      "592\n",
      "Log loss is:  11.31827785425981\n",
      "593\n",
      "Log loss is:  11.806383204098056\n",
      "594\n",
      "Log loss is:  11.808275439082289\n",
      "595\n",
      "Log loss is:  11.32754054881849\n",
      "596\n",
      "Log loss is:  20.76214499485713\n",
      "597\n",
      "Log loss is:  21.146671678771813\n",
      "598\n",
      "Log loss is:  21.14578423376765\n",
      "599\n",
      "Log loss is:  20.763513605986947\n",
      "600\n",
      "Log loss is:  86.06070771737244\n",
      "601\n",
      "Log loss is:  60.165775766010036\n",
      "602\n",
      "Log loss is:  60.16427726905094\n",
      "603\n",
      "Log loss is:  86.06164304870946\n",
      "604\n",
      "Log loss is:  9.891458318029247\n",
      "605\n",
      "Log loss is:  9.84115579347805\n",
      "606\n",
      "Log loss is:  9.839708061688262\n",
      "607\n",
      "Log loss is:  9.915206002659936\n",
      "608\n",
      "Log loss is:  6.535469117352765\n",
      "609\n",
      "Log loss is:  5.775540227728378\n",
      "610\n",
      "Log loss is:  5.775321019182329\n",
      "611\n",
      "Log loss is:  6.553110454365046\n",
      "612\n",
      "Log loss is:  13.521591740617163\n",
      "613\n",
      "Log loss is:  14.576289774416754\n",
      "614\n",
      "Log loss is:  14.574128316047604\n",
      "615\n",
      "Log loss is:  13.521696805281907\n",
      "616\n",
      "Log loss is:  7.702646794413116\n",
      "617\n",
      "Log loss is:  6.182879104678214\n",
      "618\n",
      "Log loss is:  6.182933169200254\n",
      "619\n",
      "Log loss is:  7.703380767348774\n",
      "620\n",
      "Log loss is:  44.29930322994144\n",
      "621\n",
      "Log loss is:  56.882961670255895\n",
      "622\n",
      "Log loss is:  56.8655788584788\n",
      "623\n",
      "Log loss is:  44.322058775556165\n",
      "624\n",
      "Log loss is:  38.566896311533576\n",
      "625\n",
      "Log loss is:  38.55207069613082\n",
      "626\n",
      "Log loss is:  38.544572101098815\n",
      "627\n",
      "Log loss is:  38.55285882473937\n",
      "628\n",
      "Log loss is:  168.91812333764918\n",
      "629\n",
      "Log loss is:  168.8818492602963\n",
      "630\n",
      "Log loss is:  168.86679476251658\n",
      "631\n",
      "Log loss is:  168.95197839790026\n",
      "632\n",
      "Log loss is:  24.416618558682657\n",
      "633\n",
      "Log loss is:  18.778004192652283\n",
      "634\n",
      "Log loss is:  18.780413734692573\n",
      "635\n",
      "Log loss is:  20.673435094609545\n",
      "636\n",
      "Log loss is:  131.48324120159026\n",
      "637\n",
      "Log loss is:  360.17780352805073\n",
      "638\n",
      "Log loss is:  360.2025361330927\n",
      "639\n",
      "Log loss is:  223.78221477512616\n",
      "640\n",
      "Log loss is:  16.027438380165975\n",
      "641\n",
      "Log loss is:  8.447240534547282\n",
      "642\n",
      "Log loss is:  8.447707816514127\n",
      "643\n",
      "Log loss is:  11.906223603323236\n",
      "644\n",
      "Log loss is:  111.56908954059053\n",
      "645\n",
      "Log loss is:  107.17090917322763\n",
      "646\n",
      "Log loss is:  107.18514479692158\n",
      "647\n",
      "Log loss is:  119.54716492298242\n",
      "648\n",
      "Log loss is:  72.40511612671777\n",
      "649\n",
      "Log loss is:  40.86290846152178\n",
      "650\n",
      "Log loss is:  40.84371626433003\n",
      "651\n",
      "Log loss is:  37.29339713276693\n",
      "652\n",
      "Log loss is:  140.3293318082155\n",
      "653\n",
      "Log loss is:  185.43781293533578\n",
      "654\n",
      "Log loss is:  185.4381156499126\n",
      "655\n",
      "Log loss is:  115.71712541003149\n",
      "656\n",
      "Log loss is:  9.433632231419981\n",
      "657\n",
      "Log loss is:  9.085177666402668\n",
      "658\n",
      "Log loss is:  9.090967798383351\n",
      "659\n",
      "Log loss is:  10.62673185201437\n",
      "660\n",
      "Log loss is:  69.23971862531046\n",
      "661\n",
      "Log loss is:  79.61340952818955\n",
      "662\n",
      "Log loss is:  79.5935499560856\n",
      "663\n",
      "Log loss is:  67.57953351977527\n",
      "664\n",
      "Log loss is:  129.35193103806876\n",
      "665\n",
      "Log loss is:  110.86809358689277\n",
      "666\n",
      "Log loss is:  110.89168232366332\n",
      "667\n",
      "Log loss is:  109.7505071844511\n",
      "668\n",
      "Log loss is:  53.90576550670827\n",
      "669\n",
      "Log loss is:  78.87232167564576\n",
      "670\n",
      "Log loss is:  78.85300436854571\n",
      "671\n",
      "Log loss is:  68.41518525850132\n",
      "672\n",
      "Log loss is:  53.0751929339685\n",
      "673\n",
      "Log loss is:  51.108526200969884\n",
      "674\n",
      "Log loss is:  51.100885757210165\n",
      "675\n",
      "Log loss is:  37.77615845254766\n",
      "676\n",
      "Log loss is:  72.0420205314338\n",
      "677\n",
      "Log loss is:  40.384325670885715\n",
      "678\n",
      "Log loss is:  40.36240602001696\n",
      "679\n",
      "Log loss is:  39.84817353083334\n",
      "680\n",
      "Log loss is:  16.320591878083455\n",
      "681\n",
      "Log loss is:  12.842920766127351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\n",
      "Log loss is:  12.839472934496676\n",
      "683\n",
      "Log loss is:  13.51692235716715\n",
      "684\n",
      "Log loss is:  12.894380587673457\n",
      "685\n",
      "Log loss is:  8.686711305022374\n",
      "686\n",
      "Log loss is:  8.687593639094562\n",
      "687\n",
      "Log loss is:  10.061263004503866\n",
      "688\n",
      "Log loss is:  25.409184913088172\n",
      "689\n",
      "Log loss is:  26.88026463366701\n",
      "690\n",
      "Log loss is:  26.865530140698297\n",
      "691\n",
      "Log loss is:  21.068508101301088\n",
      "692\n",
      "Log loss is:  38.75149860057214\n",
      "693\n",
      "Log loss is:  60.98055868790701\n",
      "694\n",
      "Log loss is:  60.97984768976811\n",
      "695\n",
      "Log loss is:  58.32116914261931\n",
      "696\n",
      "Log loss is:  137.63022180109382\n",
      "697\n",
      "Log loss is:  110.5159678298297\n",
      "698\n",
      "Log loss is:  110.51374154773583\n",
      "699\n",
      "Log loss is:  122.46240657402839\n",
      "700\n",
      "Log loss is:  7.830830801600502\n",
      "701\n",
      "Log loss is:  5.071805646694991\n",
      "702\n",
      "Log loss is:  5.072642142844768\n",
      "703\n",
      "Log loss is:  11.488962769767104\n",
      "704\n",
      "Log loss is:  436.466646083492\n",
      "705\n",
      "Log loss is:  379.1241688797482\n",
      "706\n",
      "Log loss is:  379.0577787134122\n",
      "707\n",
      "Log loss is:  195.51730875870356\n",
      "708\n",
      "Log loss is:  246.78515529051296\n",
      "709\n",
      "Log loss is:  157.12884216554397\n",
      "710\n",
      "Log loss is:  157.12353672016906\n",
      "711\n",
      "Log loss is:  222.41352289192125\n",
      "712\n",
      "Log loss is:  30.08036083862098\n",
      "713\n",
      "Log loss is:  24.39904973897834\n",
      "714\n",
      "Log loss is:  24.391081378785895\n",
      "715\n",
      "Log loss is:  32.503651104992045\n",
      "716\n",
      "Log loss is:  18.065887500152254\n",
      "717\n",
      "Log loss is:  14.455681606240304\n",
      "718\n",
      "Log loss is:  14.45455670933282\n",
      "719\n",
      "Log loss is:  23.207222480410298\n",
      "720\n",
      "Log loss is:  17.661379103440744\n",
      "721\n",
      "Log loss is:  18.502902095574914\n",
      "722\n",
      "Log loss is:  18.505611492298904\n",
      "723\n",
      "Log loss is:  16.009069588593036\n",
      "724\n",
      "Log loss is:  247.00136019670222\n",
      "725\n",
      "Log loss is:  383.84591167561064\n",
      "726\n",
      "Log loss is:  383.8360274234999\n",
      "727\n",
      "Log loss is:  302.57076284674747\n",
      "728\n",
      "Log loss is:  38.36920173965263\n",
      "729\n",
      "Log loss is:  46.96182286408224\n",
      "730\n",
      "Log loss is:  46.93118879365603\n",
      "731\n",
      "Log loss is:  48.648994207967185\n",
      "732\n",
      "Log loss is:  13.043317908078922\n",
      "733\n",
      "Log loss is:  12.1180619610544\n",
      "734\n",
      "Log loss is:  12.116421409403795\n",
      "735\n",
      "Log loss is:  9.292406271809428\n",
      "736\n",
      "Log loss is:  17.278644046888697\n",
      "737\n",
      "Log loss is:  34.44854534412602\n",
      "738\n",
      "Log loss is:  34.44059787258752\n",
      "739\n",
      "Log loss is:  69.42847627738465\n",
      "740\n",
      "Log loss is:  519.8595396380978\n",
      "741\n",
      "Log loss is:  600.1945640180668\n",
      "742\n",
      "Log loss is:  600.2309372312591\n",
      "743\n",
      "Log loss is:  601.1966903201189\n",
      "744\n",
      "Log loss is:  59.97109223011359\n",
      "745\n",
      "Log loss is:  59.49179820372531\n",
      "746\n",
      "Log loss is:  59.48746102412923\n",
      "747\n",
      "Log loss is:  61.20178236337933\n",
      "748\n",
      "Log loss is:  84.25742659060151\n",
      "749\n",
      "Log loss is:  73.80373159057935\n",
      "750\n",
      "Log loss is:  73.78727186961062\n",
      "751\n",
      "Log loss is:  79.51206406455726\n",
      "752\n",
      "Log loss is:  14.251565361572945\n",
      "753\n",
      "Log loss is:  22.797018155120135\n",
      "754\n",
      "Log loss is:  22.799971703315077\n",
      "755\n",
      "Log loss is:  13.55681269219754\n",
      "756\n",
      "Log loss is:  441.2568215140513\n",
      "757\n",
      "Log loss is:  441.2567855943628\n",
      "758\n",
      "Log loss is:  441.2568121942143\n",
      "759\n",
      "Log loss is:  441.25678808617266\n",
      "760\n",
      "Log loss is:  43.49944500874812\n",
      "761\n",
      "Log loss is:  43.49806930279545\n",
      "762\n",
      "Log loss is:  43.495280625583916\n",
      "763\n",
      "Log loss is:  43.502792588768465\n",
      "764\n",
      "Log loss is:  183.58656826878638\n",
      "765\n",
      "Log loss is:  183.60090338147052\n",
      "766\n",
      "Log loss is:  183.59776378833777\n",
      "767\n",
      "Log loss is:  183.60946112839093\n",
      "768\n",
      "Log loss is:  69.68222311461825\n",
      "769\n",
      "Log loss is:  67.51355672255004\n",
      "770\n",
      "Log loss is:  67.51623979418395\n",
      "771\n",
      "Log loss is:  69.711150955523\n",
      "772\n",
      "Log loss is:  407.35319163764257\n",
      "773\n",
      "Log loss is:  405.7833330454571\n",
      "774\n",
      "Log loss is:  405.7826754472681\n",
      "775\n",
      "Log loss is:  407.34910512255294\n",
      "776\n",
      "Log loss is:  406.65548004774183\n",
      "777\n",
      "Log loss is:  327.73202304221104\n",
      "778\n",
      "Log loss is:  327.6557308530076\n",
      "779\n",
      "Log loss is:  406.51686453187665\n",
      "780\n",
      "Log loss is:  542.7236194399969\n",
      "781\n",
      "Log loss is:  300.0399612356689\n",
      "782\n",
      "Log loss is:  541.8564934814675\n",
      "783\n",
      "Log loss is:  300.6368661187905\n",
      "784\n",
      "Log loss is:  18.619797246578557\n",
      "785\n",
      "Log loss is:  16.966797761570138\n",
      "786\n",
      "Log loss is:  16.969044364083018\n",
      "787\n",
      "Log loss is:  18.633107100204416\n",
      "788\n",
      "Log loss is:  9.795849274776627\n",
      "789\n",
      "Log loss is:  9.1545394482598\n",
      "790\n",
      "Log loss is:  9.180681619252145\n",
      "791\n",
      "Log loss is:  9.807638641672703\n",
      "792\n",
      "Log loss is:  155.86947497823795\n",
      "793\n",
      "Log loss is:  128.01735736751243\n",
      "794\n",
      "Log loss is:  128.03091723927506\n",
      "795\n",
      "Log loss is:  155.85582506473796\n",
      "796\n",
      "Log loss is:  36.13519004417111\n",
      "797\n",
      "Log loss is:  39.94120474653057\n",
      "798\n",
      "Log loss is:  39.93591637203871\n",
      "799\n",
      "Log loss is:  36.21673606985483\n",
      "800\n",
      "Log loss is:  9.968405810298247\n",
      "801\n",
      "Log loss is:  10.903516456517146\n",
      "802\n",
      "Log loss is:  10.906650297879219\n",
      "803\n",
      "Log loss is:  9.9820345875942\n",
      "804\n",
      "Log loss is:  27.981668125102928\n",
      "805\n",
      "Log loss is:  21.327566249317925\n",
      "806\n",
      "Log loss is:  21.317961208306105\n",
      "807\n",
      "Log loss is:  28.00663964287392\n",
      "808\n",
      "Log loss is:  13.039402190947676\n",
      "809\n",
      "Log loss is:  10.678240271661974\n",
      "810\n",
      "Log loss is:  10.676826688506415\n",
      "811\n",
      "Log loss is:  13.042400705017185\n",
      "812\n",
      "Log loss is:  14.465040086107955\n",
      "813\n",
      "Log loss is:  10.012809271707498\n",
      "814\n",
      "Log loss is:  9.999793126254454\n",
      "815\n",
      "Log loss is:  14.521408032109385\n",
      "816\n",
      "Log loss is:  19.45280202446778\n",
      "817\n",
      "Log loss is:  14.815767564313312\n",
      "818\n",
      "Log loss is:  14.812257388705378\n",
      "819\n",
      "Log loss is:  19.41361689569965\n",
      "820\n",
      "Log loss is:  95.35701176933544\n",
      "821\n",
      "Log loss is:  102.54600536092292\n",
      "822\n",
      "Log loss is:  102.54677609135197\n",
      "823\n",
      "Log loss is:  95.36253757320485\n",
      "824\n",
      "Log loss is:  29.421413991985016\n",
      "825\n",
      "Log loss is:  26.611336987861566\n",
      "826\n",
      "Log loss is:  26.60576991954538\n",
      "827\n",
      "Log loss is:  29.38936637275881\n",
      "828\n",
      "Log loss is:  6.928824889047563\n",
      "829\n",
      "Log loss is:  5.01615920720706\n",
      "830\n",
      "Log loss is:  5.01754848713468\n",
      "831\n",
      "Log loss is:  6.950792536682657\n",
      "832\n",
      "Log loss is:  31.654777230673677\n",
      "833\n",
      "Log loss is:  41.70420674612031\n",
      "834\n",
      "Log loss is:  41.70385319297059\n",
      "835\n",
      "Log loss is:  31.64678215679117\n",
      "836\n",
      "Log loss is:  121.25552153899038\n",
      "837\n",
      "Log loss is:  124.19422417009973\n",
      "838\n",
      "Log loss is:  124.21852283161914\n",
      "839\n",
      "Log loss is:  121.28223498138544\n",
      "840\n",
      "Log loss is:  106.61358404151012\n",
      "841\n",
      "Log loss is:  96.80312845707994\n",
      "842\n",
      "Log loss is:  96.89634368041446\n",
      "843\n",
      "Log loss is:  106.76914355036209\n",
      "844\n",
      "Log loss is:  12.646219854397547\n",
      "845\n",
      "Log loss is:  18.763511862255562\n",
      "846\n",
      "Log loss is:  18.747575291209134\n",
      "847\n",
      "Log loss is:  12.65824117704863\n",
      "848\n",
      "Log loss is:  246.32429310149726\n",
      "849\n",
      "Log loss is:  321.4339718484826\n",
      "850\n",
      "Log loss is:  321.5257579535793\n",
      "851\n",
      "Log loss is:  245.93875863945632\n",
      "852\n",
      "Log loss is:  14.237383778822883\n",
      "853\n",
      "Log loss is:  13.265663447421554\n",
      "854\n",
      "Log loss is:  13.279081731820504\n",
      "855\n",
      "Log loss is:  14.25313244267071\n",
      "856\n",
      "Log loss is:  34.99022674525492\n",
      "857\n",
      "Log loss is:  32.090334839634444\n",
      "858\n",
      "Log loss is:  32.07136987353927\n",
      "859\n",
      "Log loss is:  35.10362425067897\n",
      "860\n",
      "Log loss is:  90.21215255707766\n",
      "861\n",
      "Log loss is:  73.17609392191947\n",
      "862\n",
      "Log loss is:  73.2007723349702\n",
      "863\n",
      "Log loss is:  90.25749426560343\n",
      "864\n",
      "Log loss is:  39.12707144255412\n",
      "865\n",
      "Log loss is:  33.85266777388863\n",
      "866\n",
      "Log loss is:  33.850824899842564\n",
      "867\n",
      "Log loss is:  39.13806680505902\n",
      "868\n",
      "Log loss is:  51.84957403661606\n",
      "869\n",
      "Log loss is:  51.84957890515669\n",
      "870\n",
      "Log loss is:  51.8495692435817\n",
      "871\n",
      "Log loss is:  51.84958174332494\n",
      "872\n",
      "Log loss is:  49.246562680773955\n",
      "873\n",
      "Log loss is:  41.184510653059\n",
      "874\n",
      "Log loss is:  49.25464125176756\n",
      "875\n",
      "Log loss is:  41.15920077541505\n",
      "876\n",
      "Log loss is:  23.46020383056309\n",
      "877\n",
      "Log loss is:  21.58889897123958\n",
      "878\n",
      "Log loss is:  23.45413363583628\n",
      "879\n",
      "Log loss is:  21.587928463767497\n",
      "880\n",
      "Log loss is:  254.75766149880036\n",
      "881\n",
      "Log loss is:  308.928535951026\n",
      "882\n",
      "Log loss is:  254.79021575418284\n",
      "883\n",
      "Log loss is:  308.9230325149017\n",
      "884\n",
      "Log loss is:  352.36370898552946\n",
      "885\n",
      "Log loss is:  379.70709888283756\n",
      "886\n",
      "Log loss is:  352.2928206297229\n",
      "887\n",
      "Log loss is:  379.80126595567356\n",
      "888\n",
      "Log loss is:  45.18018336426279\n",
      "889\n",
      "Log loss is:  38.975095937393455\n",
      "890\n",
      "Log loss is:  45.15814841050637\n",
      "891\n",
      "Log loss is:  38.969873906610644\n",
      "892\n",
      "Log loss is:  64.87458327526413\n",
      "893\n",
      "Log loss is:  64.8690143709547\n",
      "894\n",
      "Log loss is:  64.8694802759389\n",
      "895\n",
      "Log loss is:  64.87712641226506\n",
      "896\n",
      "Log loss is:  49.43425796735146\n",
      "897\n",
      "Log loss is:  49.434282312874736\n",
      "898\n",
      "Log loss is:  49.43431221899919\n",
      "899\n",
      "Log loss is:  49.4342690373741\n",
      "900\n",
      "Log loss is:  182.98240224660978\n",
      "901\n",
      "Log loss is:  183.00860227781263\n",
      "902\n",
      "Log loss is:  182.97943734005406\n",
      "903\n",
      "Log loss is:  183.020484123983\n",
      "904\n",
      "Log loss is:  199.35521237208613\n",
      "905\n",
      "Log loss is:  179.4277451161938\n",
      "906\n",
      "Log loss is:  179.41832280617282\n",
      "907\n",
      "Log loss is:  199.32448984318233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "Log loss is:  270.75587755399386\n",
      "909\n",
      "Log loss is:  270.75581071099117\n",
      "910\n",
      "Log loss is:  270.7556743723442\n",
      "911\n",
      "Log loss is:  270.7557850042352\n",
      "912\n",
      "Log loss is:  526.6503350507927\n",
      "913\n",
      "Log loss is:  526.6531225296774\n",
      "914\n",
      "Log loss is:  526.6527789489592\n",
      "915\n",
      "Log loss is:  526.6498928819194\n",
      "916\n",
      "Log loss is:  22.65941499239007\n",
      "917\n",
      "Log loss is:  22.66250772982706\n",
      "918\n",
      "Log loss is:  22.662385826018166\n",
      "919\n",
      "Log loss is:  22.65816681029523\n",
      "920\n",
      "Log loss is:  40.35992693560515\n",
      "921\n",
      "Log loss is:  40.359751940081345\n",
      "922\n",
      "Log loss is:  40.35695725708167\n",
      "923\n",
      "Log loss is:  40.36391099123988\n",
      "924\n",
      "Log loss is:  723.913235130178\n",
      "925\n",
      "Log loss is:  723.9174886416005\n",
      "926\n",
      "Log loss is:  723.9114718769251\n",
      "927\n",
      "Log loss is:  723.8575399645749\n",
      "928\n",
      "Log loss is:  64.61973828872004\n",
      "929\n",
      "Log loss is:  64.62923599998774\n",
      "930\n",
      "Log loss is:  64.6166957757524\n",
      "931\n",
      "Log loss is:  64.64179708739321\n",
      "932\n",
      "Log loss is:  242.91258286699372\n",
      "933\n",
      "Log loss is:  242.91256646448267\n",
      "934\n",
      "Log loss is:  242.91258333274243\n",
      "935\n",
      "Log loss is:  242.91256715156723\n",
      "936\n",
      "Log loss is:  152.21310798943924\n",
      "937\n",
      "Log loss is:  152.21311191369205\n",
      "938\n",
      "Log loss is:  152.21310876434507\n",
      "939\n",
      "Log loss is:  152.21311122897052\n",
      "940\n",
      "Log loss is:  415.60335733146934\n",
      "941\n",
      "Log loss is:  415.60334715174287\n",
      "942\n",
      "Log loss is:  415.6033556801384\n",
      "943\n",
      "Log loss is:  415.60330095142007\n",
      "944\n",
      "Log loss is:  30.022766065034546\n",
      "945\n",
      "Log loss is:  30.022766147817322\n",
      "946\n",
      "Log loss is:  30.02276650069944\n",
      "947\n",
      "Log loss is:  30.022766338187825\n",
      "948\n",
      "Log loss is:  630.6261729178626\n",
      "949\n",
      "Log loss is:  630.6275577646895\n",
      "950\n",
      "Log loss is:  630.6337871966936\n",
      "951\n",
      "Log loss is:  630.6274862584493\n",
      "952\n",
      "Log loss is:  688.5121164922834\n",
      "953\n",
      "Log loss is:  688.0371410119209\n",
      "954\n",
      "Log loss is:  687.9654899125256\n",
      "955\n",
      "Log loss is:  688.4949704203141\n",
      "956\n",
      "Log loss is:  171.4994228219735\n",
      "957\n",
      "Log loss is:  171.49956291411408\n",
      "958\n",
      "Log loss is:  171.4995592100342\n",
      "959\n",
      "Log loss is:  171.5004655681517\n",
      "960\n",
      "Log loss is:  30.34013370457855\n",
      "961\n",
      "Log loss is:  30.340133382909187\n",
      "962\n",
      "Log loss is:  30.340133512839365\n",
      "963\n",
      "Log loss is:  30.340133609994417\n",
      "964\n",
      "Log loss is:  44.363401545775616\n",
      "965\n",
      "Log loss is:  44.37796168457547\n",
      "966\n",
      "Log loss is:  44.3779187660015\n",
      "967\n",
      "Log loss is:  44.38613284184877\n",
      "968\n",
      "Log loss is:  26.47696355787414\n",
      "969\n",
      "Log loss is:  29.755998154016048\n",
      "970\n",
      "Log loss is:  29.73842788085523\n",
      "971\n",
      "Log loss is:  26.536874787314122\n",
      "972\n",
      "Log loss is:  44.13142771347819\n",
      "973\n",
      "Log loss is:  44.13142791287592\n",
      "974\n",
      "Log loss is:  44.1314278801492\n",
      "975\n",
      "Log loss is:  44.131428210760184\n",
      "976\n",
      "Log loss is:  95.04393305910808\n",
      "977\n",
      "Log loss is:  95.04393788348229\n",
      "978\n",
      "Log loss is:  95.0439345646382\n",
      "979\n",
      "Log loss is:  95.0439346376745\n",
      "980\n",
      "Log loss is:  109.7788858907154\n",
      "981\n",
      "Log loss is:  109.78793827966079\n",
      "982\n",
      "Log loss is:  109.78545068486868\n",
      "983\n",
      "Log loss is:  109.7778043402473\n",
      "984\n",
      "Log loss is:  383.77117398741416\n",
      "985\n",
      "Log loss is:  383.7709239138086\n",
      "986\n",
      "Log loss is:  383.7714570609633\n",
      "987\n",
      "Log loss is:  383.77080622014637\n",
      "988\n",
      "Log loss is:  46.31695097581139\n",
      "989\n",
      "Log loss is:  59.71719164571974\n",
      "990\n",
      "Log loss is:  47.70475060369759\n",
      "991\n",
      "Log loss is:  35.0948668622862\n",
      "992\n",
      "Log loss is:  16.500021469230095\n",
      "993\n",
      "Log loss is:  16.490723465606873\n",
      "994\n",
      "Log loss is:  16.490524504832194\n",
      "995\n",
      "Log loss is:  16.492128968912265\n",
      "996\n",
      "Log loss is:  15.483903950998691\n",
      "997\n",
      "Log loss is:  15.499062868566373\n",
      "998\n",
      "Log loss is:  15.498508626563929\n",
      "999\n",
      "Log loss is:  15.512113572237439\n",
      "1000\n",
      "Log loss is:  442.8582277422396\n",
      "1001\n",
      "Log loss is:  764.138203102464\n",
      "1002\n",
      "Log loss is:  764.3252805882018\n",
      "1003\n",
      "Log loss is:  442.7359703600526\n",
      "1004\n",
      "Log loss is:  233.17851346907656\n",
      "1005\n",
      "Log loss is:  233.20616411898175\n",
      "1006\n",
      "Log loss is:  233.196554861663\n",
      "1007\n",
      "Log loss is:  233.14311608981782\n",
      "1008\n",
      "Log loss is:  182.4178523061571\n",
      "1009\n",
      "Log loss is:  182.43169430756015\n",
      "1010\n",
      "Log loss is:  182.46738643985\n",
      "1011\n",
      "Log loss is:  182.36808255378338\n",
      "1012\n",
      "Log loss is:  44.65255319349188\n",
      "1013\n",
      "Log loss is:  44.6216417639663\n",
      "1014\n",
      "Log loss is:  44.64731545848126\n",
      "1015\n",
      "Log loss is:  44.62991287475933\n",
      "1016\n",
      "Log loss is:  131.14055482893096\n",
      "1017\n",
      "Log loss is:  131.1016269662427\n",
      "1018\n",
      "Log loss is:  131.10868533486746\n",
      "1019\n",
      "Log loss is:  131.1244075916302\n",
      "1020\n",
      "Log loss is:  22.679468922784256\n",
      "1021\n",
      "Log loss is:  22.66576912893902\n",
      "1022\n",
      "Log loss is:  22.673814211093624\n",
      "1023\n",
      "Log loss is:  22.676752372281143\n",
      "1024\n",
      "Log loss is:  69.64743016399919\n",
      "1025\n",
      "Log loss is:  69.62641488224185\n",
      "1026\n",
      "Log loss is:  69.62268818142233\n",
      "1027\n",
      "Log loss is:  69.67327656201317\n",
      "1028\n",
      "Log loss is:  57.947974964772996\n",
      "1029\n",
      "Log loss is:  57.892979945754654\n",
      "1030\n",
      "Log loss is:  57.923399171276216\n",
      "1031\n",
      "Log loss is:  57.9224519009928\n",
      "1032\n",
      "Log loss is:  173.71545930032926\n",
      "1033\n",
      "Log loss is:  173.66358841832727\n",
      "1034\n",
      "Log loss is:  173.643479864859\n",
      "1035\n",
      "Log loss is:  173.64370789625755\n",
      "1036\n",
      "Log loss is:  103.13925653453755\n",
      "1037\n",
      "Log loss is:  103.149545442561\n",
      "1038\n",
      "Log loss is:  103.14721839463344\n",
      "1039\n",
      "Log loss is:  103.13577890458741\n",
      "1040\n",
      "Log loss is:  62.4586084883048\n",
      "1041\n",
      "Log loss is:  62.460429604786036\n",
      "1042\n",
      "Log loss is:  62.45946372524795\n",
      "1043\n",
      "Log loss is:  62.458971641291754\n",
      "1044\n",
      "Log loss is:  21.693306914771007\n",
      "1045\n",
      "Log loss is:  28.97290591094699\n",
      "1046\n",
      "Log loss is:  37.77125935959903\n",
      "1047\n",
      "Log loss is:  29.377235492903484\n",
      "1048\n",
      "Log loss is:  605.7607743104503\n",
      "1049\n",
      "Log loss is:  564.2087680241226\n",
      "1050\n",
      "Log loss is:  281.10753032099547\n",
      "1051\n",
      "Log loss is:  327.0537232221839\n",
      "1052\n",
      "Log loss is:  48.272738269671855\n",
      "1053\n",
      "Log loss is:  106.39253716668608\n",
      "1054\n",
      "Log loss is:  37.14633983422306\n",
      "1055\n",
      "Log loss is:  45.58342790407135\n",
      "1056\n",
      "Log loss is:  60.003636949128264\n",
      "1057\n",
      "Log loss is:  92.6637792804471\n",
      "1058\n",
      "Log loss is:  67.43951139589883\n",
      "1059\n",
      "Log loss is:  70.7043630471875\n",
      "1060\n",
      "Log loss is:  37.67924909543703\n",
      "1061\n",
      "Log loss is:  42.421722030965036\n",
      "1062\n",
      "Log loss is:  42.425156982546504\n",
      "1063\n",
      "Log loss is:  37.715628369769334\n",
      "1064\n",
      "Log loss is:  2052.4432165486874\n",
      "1065\n",
      "Log loss is:  2052.4414670763535\n",
      "1066\n",
      "Log loss is:  2052.435244042772\n",
      "1067\n",
      "Log loss is:  2052.4255477023526\n",
      "1068\n",
      "Log loss is:  931.1974926835495\n",
      "1069\n",
      "Log loss is:  1039.5040329470376\n",
      "1070\n",
      "Log loss is:  800.6953876005192\n",
      "1071\n",
      "Log loss is:  864.0903045822436\n",
      "1072\n",
      "Log loss is:  22.845366270815248\n",
      "1073\n",
      "Log loss is:  15.742537223129833\n",
      "1074\n",
      "Log loss is:  23.677335939482642\n",
      "1075\n",
      "Log loss is:  18.576458116102213\n",
      "1076\n",
      "Log loss is:  226.02384344476724\n",
      "1077\n",
      "Log loss is:  152.2619964507496\n",
      "1078\n",
      "Log loss is:  224.06279712634225\n",
      "1079\n",
      "Log loss is:  44.57744173424427\n",
      "1080\n",
      "Log loss is:  17.807359834292\n",
      "1081\n",
      "Log loss is:  14.252677140923153\n",
      "1082\n",
      "Log loss is:  14.25548092119713\n",
      "1083\n",
      "Log loss is:  17.799839553267322\n",
      "1084\n",
      "Log loss is:  11.417977233974925\n",
      "1085\n",
      "Log loss is:  11.999957029244788\n",
      "1086\n",
      "Log loss is:  12.003281226474014\n",
      "1087\n",
      "Log loss is:  11.429817077682698\n",
      "1088\n",
      "Log loss is:  277.45866250205455\n",
      "1089\n",
      "Log loss is:  224.73155218788165\n",
      "1090\n",
      "Log loss is:  305.4406034240154\n",
      "1091\n",
      "Log loss is:  257.8011057543937\n",
      "Average loss:  144.4603467238633\n",
      "Average loss of each orentation  [144.2632803058547, 143.73872960750333, 147.08843927901984, 142.75093770307532]\n",
      "Best reconstruction:  829 5.01615920720706\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_loss = 0\n",
    "\n",
    "#data = [i for i in gen_paths_labels(data_path)]\n",
    "#data[0][0], data[0][1]\n",
    "best_image = [None, None, None, None]\n",
    "lowest_loss = np.inf\n",
    "vae.encoder.sampling.gamma=0\n",
    "AugmentedLoss = [0, 0, 0, 0]\n",
    "for i in range(0, len(TestPathsInput)):\n",
    "    x = np.load(TestPathsInput[i])\n",
    "    y = np.load(TestPathsOutput[i])\n",
    "    #x = np.load(data[0][i])\n",
    "    #y = np.load(data[1][i])\n",
    "\n",
    "    a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "\n",
    "    #print(i)\n",
    "    log_loss = 0\n",
    "\n",
    "    for j in range(0, a.shape[0]):\n",
    "        for k in range(0, a.shape[1]):\n",
    "            log_loss+=(math.log(1+a[j][k]) - math.log(1+y[j][k])) ** 2\n",
    "    \n",
    "    average_loss += log_loss\n",
    "    AugmentedLoss[i % 4]+=log_loss / (len(TestPathsInput) / 4)\n",
    "    if log_loss > 0:\n",
    "        if log_loss < lowest_loss:\n",
    "            best_image = [x, y, a, i]\n",
    "            lowest_loss = log_loss\n",
    "        print(i)\n",
    "        print(\"Log loss is: \", log_loss)\n",
    "        w=10\n",
    "        h=10\n",
    "        #fig=plt.figure(figsize=(8, 8))\n",
    "        #columns = 3\n",
    "        #rows = 1\n",
    "        #fig.add_subplot(rows, columns, 1)\n",
    "        #plt.imshow(x)\n",
    "        #fig.add_subplot(rows, columns, 2)\n",
    "        #plt.imshow(y)\n",
    "        #fig.add_subplot(rows, columns, 3)\n",
    "        #plt.imshow(a)\n",
    "        #plt.show()\n",
    "    \n",
    "    \n",
    "        \n",
    "AugmentedLoss = AugmentedLoss\n",
    "print(\"Average loss: \", average_loss / len(TestPathsInput))\n",
    "print(\"Average loss of each orentation \", AugmentedLoss)\n",
    "print(\"Best reconstruction: \", best_image[3], lowest_loss)\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 3\n",
    "rows = 1\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(best_image[0])\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(best_image[1])\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(best_image[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(TrainingPaths[0])):\n",
    "    #x = np.load(data[0][0][i])\n",
    "    #y = np.load(data[0][1][i])\n",
    "    x = np.load(TrainingPaths[0][i])\n",
    "    y = np.load(TrainingPaths[1][i])\n",
    "    a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "    print(TrainingPaths[0][i])\n",
    "\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    columns = 3\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(x)\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(y)\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(a)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
