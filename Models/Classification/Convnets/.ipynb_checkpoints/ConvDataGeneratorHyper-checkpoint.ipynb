{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from keras.utils import Sequence\n",
    "#from keras.models import load_model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "Path = \"/home/ug-ml/felix-ML/DataGenerator2/Data\"\n",
    "DataSets = [\"/train/\", \"/validation/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type), to_categorical(np.array(batch_y),10)\n",
    "\n",
    "def gen_paths_labels(base_path = \"D:\\\\Uni Work\\\\Masters Project\\\\test_dir\"):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        segment_paths = []\n",
    "        segment_labels = []\n",
    "        for label in os.listdir(segment_path):\n",
    "            label_path = os.path.join(segment_path, label)\n",
    "            for crystal in os.listdir(label_path):\n",
    "                segment_paths.append(os.path.join(label_path, crystal))\n",
    "                segment_labels.append(label)\n",
    "        indexes = np.arange(len(segment_labels))\n",
    "        rng.shuffle(indexes)\n",
    "        yield [np.array(segment_paths)[indexes], np.array(list(map(int,segment_labels)))[indexes]]\n",
    "\n",
    "def arrs_from_paths(paths, file_type):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name) for file_name in paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data done.\n",
      "training_seq done.\n",
      "val_images done.\n",
      "val_lab done.\n"
     ]
    }
   ],
   "source": [
    "data = [i for i in gen_paths_labels(Path)]\n",
    "#data[0][0] is training paths data[0][1] is training labels\n",
    "#data[1][0] is val paths data[1][1] is val labels\n",
    "print(\"data done.\")\n",
    "training_seq = FelixSequence(data[0][0], data[0][1], 32, \"npy\")\n",
    "print(\"training_seq done.\")\n",
    "#print(data[1][0])\n",
    "val_images = arrs_from_paths(data[1][0], \"npy\")\n",
    "print(\"val_images done.\")\n",
    "val_lab = to_categorical(data[1][1])\n",
    "print(\"val_lab done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_6 (Separabl (None, 128, 126, 126)     5060      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 63, 126)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 128, 61, 124)      8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 64, 30, 124)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 128, 28, 122)      8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 14, 122)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 109312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 109312)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                6996032   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,019,534\n",
      "Trainable params: 7,019,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(loss, regularizers_n, lr):\n",
    "    strategy = MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', data_format='channels_first', input_shape=(36, 128, 128)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.SeparableConv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.SeparableConv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(32, activation='relu', kernel_regularizer = l2(regularizers_n)))\n",
    "        model.add(layers.Dense(10, activation='softmax', kernel_regularizer = l2(regularizers_n)))\n",
    "\n",
    "        model.compile(loss=loss, optimizer=optimizers.RMSprop(learning_rate = lr), metrics=['acc'])\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /home/ug-ml/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 13 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 13 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "560/560 [==============================] - ETA: 0s - loss: 1.9903 - acc: 0.2539INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "560/560 [==============================] - 130s 232ms/step - loss: 1.9903 - acc: 0.2539 - val_loss: 2.0319 - val_acc: 0.3136\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 109s 195ms/step - loss: 1.6258 - acc: 0.4397 - val_loss: 3.6244 - val_acc: 0.4995\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 107s 190ms/step - loss: 1.2780 - acc: 0.5743 - val_loss: 3.5800 - val_acc: 0.5754\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 108s 193ms/step - loss: 1.0897 - acc: 0.6492 - val_loss: 3.5950 - val_acc: 0.6236\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 108s 192ms/step - loss: 0.9663 - acc: 0.6943 - val_loss: 3.2599 - val_acc: 0.6583\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 110s 196ms/step - loss: 0.8766 - acc: 0.7310 - val_loss: 3.8667 - val_acc: 0.6864\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 110s 197ms/step - loss: 0.8101 - acc: 0.7589 - val_loss: 2.7973 - val_acc: 0.6975\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 109s 194ms/step - loss: 0.7358 - acc: 0.7861 - val_loss: 1.9046 - val_acc: 0.6980\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 110s 196ms/step - loss: 0.6828 - acc: 0.8077 - val_loss: 4.6275 - val_acc: 0.7030\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 122s 218ms/step - loss: 0.6333 - acc: 0.8246 - val_loss: 4.6934 - val_acc: 0.7246\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 111s 198ms/step - loss: 0.5874 - acc: 0.8453 - val_loss: 4.7492 - val_acc: 0.7588\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 111s 199ms/step - loss: 0.5481 - acc: 0.8586 - val_loss: 5.2405 - val_acc: 0.7337\n",
      "Epoch 13/100\n",
      "241/560 [===========>..................] - ETA: 1:03 - loss: 0.4772 - acc: 0.8868"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose = 2)\n",
    "lr = [0.001, 0.0005, 0.0001, 0.00005]\n",
    "epochs = [50]\n",
    "batches = [64]\n",
    "loss = [\"categorical_crossentropy\"]\n",
    "regularizers_n = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "param_grid = dict(lr = lr, epochs = epochs, batch_size = batches, loss = loss, regularizers_n = regularizers_n)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3)\n",
    "\n",
    "grid_result = grid.fit(training_seq, \n",
    "                       validation_data = (val_images, val_lab), \n",
    "                       workers = 16, \n",
    "                       use_multiprocessing = False)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Conv_seq_36_3000_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
