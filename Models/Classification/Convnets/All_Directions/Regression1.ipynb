{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model\n",
    "from tensorflow.distribute import MirroredStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths\n",
    "\n",
    "Path = \"/home/ug-ml/felix-ML/DataGenerator2/Data\" #Path where training and validation data is\n",
    "SaveDataPath = \"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder\" #Base directory of place you store information of models\n",
    "CifFlolder = \"/home/ug-ml/felix-ML/DataGenerator2/CifFolder\"\n",
    "SaveFolderName = \"/ConvnetR3\" #Will create a folder and put in information about the outcome / inputs\n",
    "ModelName = \"/ConvnetR3.hdf5\"\n",
    "\n",
    "\n",
    "#Many variables\n",
    "\n",
    "#Model Variables\n",
    "input_shape = (36, 128, 128)\n",
    "\n",
    "#Hyper parameters\n",
    "learning_rate = 0.0005\n",
    "l2_regularizer = 0.0001\n",
    "loss = 'MeanSquaredError'\n",
    "optimizer = \"RMSprop\" #Not a variable ONLY used for a note\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "ShuffleTrainData = True\n",
    "\n",
    "#Call back variables\n",
    "TrainingPatience = 20\n",
    "CheckPointMonitor = 'val_loss'\n",
    "EarlyStopMonitor = 'val_loss'\n",
    "\n",
    "#CPU variables\n",
    "CPUworkers = 16\n",
    "\n",
    "#Limit range\n",
    "LatticeRange = [6, 11]\n",
    "\n",
    "\n",
    "#List the name of the variables you want to save in a file\n",
    "VariableListName = [\"input_shape\", \n",
    "                   \"learning_rate\", \"l2_regularizer\", \"loss\", \"optimizer\", \"batch_size\", \"epochs\", \"ShuffleTrainData\",\n",
    "                   \"TrainingPatience\", \"CheckPointMonitor\", \"EarlyStopMonitor\",\n",
    "                   \"CPUworkers\",\n",
    "                   \"LatticeRange\"]\n",
    "\n",
    "#List the variables in the same order as VariableListName\n",
    "VariableListValues = [input_shape, \n",
    "                   learning_rate, l2_regularizer, loss, optimizer, batch_size, epochs, ShuffleTrainData,\n",
    "                   TrainingPatience, CheckPointMonitor, EarlyStopMonitor,\n",
    "                    CPUworkers,\n",
    "                      LatticeRange]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder failed to be created, it may already exist\n"
     ]
    }
   ],
   "source": [
    "#Early stopping and check points\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor = EarlyStopMonitor,\n",
    "                          mode = 'auto',\n",
    "                          verbose = 1,\n",
    "                          patience = TrainingPatience)\n",
    "\n",
    "NewPath = SaveDataPath + SaveFolderName\n",
    "Checkpoint = ModelCheckpoint(NewPath + ModelName, #Save path\n",
    "                             monitor = CheckPointMonitor,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 'epoch')\n",
    "\n",
    "\n",
    "#Make folder to put model and history information\n",
    "try:\n",
    "    os.mkdir(NewPath)\n",
    "except:\n",
    "    print(\"Folder failed to be created, it may already exist\")\n",
    "    \n",
    "File1  = open(NewPath +\"/Parameters.txt\", \"w+\")\n",
    "if(len(VariableListName) == len(VariableListValues)):\n",
    "    for i in range(0, len(VariableListName)):\n",
    "        File1.write(VariableListName[i] + \" \" + str(VariableListValues[i]) + \"\\n\")\n",
    "    File1.close()\n",
    "else:\n",
    "    print(\"VariableListName and VariableListValues do not match up, so file can not be saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_9 (Separabl (None, 128, 126, 126)     5060      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 128, 63, 63)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 128, 61, 61)       17664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 128, 28, 28)       17664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 128, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 6,463,429\n",
      "Trainable params: 6,463,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3),\n",
    "                                     activation='relu',\n",
    "                                     data_format='channels_first',\n",
    "                                     input_shape= input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(256, activation='relu',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(loss = loss,\n",
    "                  optimizer = optimizers.RMSprop(learning_rate = learning_rate))\n",
    "\n",
    "#Save summary of model\n",
    "with open(NewPath + '/summary.txt','w') as fh:\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data done.\n",
      "training_seq done.\n",
      "val_images done.\n",
      "val_lab done.\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#Load data generators\n",
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type), np.array(batch_y)\n",
    "\n",
    "def arrs_from_paths(paths, file_type):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name) for file_name in paths]) \n",
    "    \n",
    "    \n",
    "#Define Data gemerator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "PathOfFile = CifFlolder +\"/FilePaths.txt\"\n",
    "with open(PathOfFile) as textFile:\n",
    "    lines = [line.split() for line in textFile]\n",
    "\n",
    "\n",
    "training_path = []\n",
    "training_labels = []\n",
    "validation_path = []\n",
    "validation_labels = []\n",
    "for i in lines:\n",
    "    PathSplit = i[0].split(\"/\")\n",
    "    for j in PathSplit:\n",
    "        if(j == \"training\"):\n",
    "            if(float(i[3]) > LatticeRange[0] and float(i[3]) < LatticeRange[1]):\n",
    "                training_path.append(i[0])\n",
    "                training_labels.append(int(i[2]) / 9)\n",
    "                break\n",
    "            \n",
    "        elif(j == \"validation\"):\n",
    "            if(float(i[3]) > LatticeRange[0] and float(i[3]) < LatticeRange[1]):\n",
    "                validation_path.append(i[0])\n",
    "                validation_labels.append(int(i[2]) / 9)\n",
    "                break\n",
    "\n",
    "                \n",
    "trainsize = len(training_path)\n",
    "validationsize = len(validation_path)\n",
    "\n",
    "ShuffleTraining = np.arange(trainsize, dtype = np.int)\n",
    "ShuffleValidation = np.arange(validationsize, dtype = np.int)\n",
    "\n",
    "training_path_shuffled = training_path.copy()\n",
    "training_labels_shuffled = training_labels.copy()\n",
    "validation_path_shuffled = validation_path.copy()\n",
    "validation_labels_shuffled = validation_labels.copy()\n",
    "\n",
    "rng.shuffle(ShuffleTraining)\n",
    "rng.shuffle(ShuffleValidation)\n",
    "\n",
    "for i in range(0, trainsize):\n",
    "    training_path_shuffled[i] = training_path[ShuffleTraining[i]]\n",
    "    training_labels_shuffled[i] = training_labels[ShuffleTraining[i]]\n",
    "    #print(training_path_shuffled[i], training_labels_shuffled[i])\n",
    "\n",
    "for i in range(0, validationsize):\n",
    "    validation_path_shuffled[i] = validation_path[ShuffleValidation[i]]\n",
    "    validation_labels_shuffled[i] = validation_labels[ShuffleValidation[i]]\n",
    "    #print(validation_path_shuffled[i], validation_labels_shuffled[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"data done.\")\n",
    "training_seq = FelixSequence(training_path_shuffled, training_labels_shuffled, batch_size, \"npy\")\n",
    "print(\"training_seq done.\")\n",
    "val_images = arrs_from_paths(validation_path_shuffled, \"npy\")\n",
    "print(\"val_images done.\")\n",
    "val_lab = np.array(validation_labels_shuffled.copy())\n",
    "print(\"val_lab done.\")\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training_labels_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 13 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 13 all-reduces with algorithm = nccl, num_packs = 1\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0776\n",
      "Epoch 00001: val_loss improved from inf to 129.89903, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 90s 242ms/step - loss: 0.0776 - val_loss: 129.8990\n",
      "Epoch 2/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0350\n",
      "Epoch 00002: val_loss improved from 129.89903 to 38.47725, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 79s 212ms/step - loss: 0.0350 - val_loss: 38.4772\n",
      "Epoch 3/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 00003: val_loss improved from 38.47725 to 1.05135, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 82s 222ms/step - loss: 0.0256 - val_loss: 1.0513\n",
      "Epoch 4/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00004: val_loss improved from 1.05135 to 0.01982, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 80s 217ms/step - loss: 0.0205 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 00005: val_loss did not improve from 0.01982\n",
      "370/370 [==============================] - 81s 218ms/step - loss: 0.0176 - val_loss: 2.4188\n",
      "Epoch 6/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00006: val_loss improved from 0.01982 to 0.01527, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 78s 210ms/step - loss: 0.0157 - val_loss: 0.0153\n",
      "Epoch 7/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00007: val_loss did not improve from 0.01527\n",
      "370/370 [==============================] - 79s 215ms/step - loss: 0.0143 - val_loss: 6.7647\n",
      "Epoch 8/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 00008: val_loss improved from 0.01527 to 0.01371, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 79s 214ms/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 9/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 00009: val_loss did not improve from 0.01371\n",
      "370/370 [==============================] - 78s 210ms/step - loss: 0.0127 - val_loss: 2.3572\n",
      "Epoch 10/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0118- E\n",
      "Epoch 00010: val_loss did not improve from 0.01371\n",
      "370/370 [==============================] - 82s 223ms/step - loss: 0.0118 - val_loss: 0.4780\n",
      "Epoch 11/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00011: val_loss did not improve from 0.01371\n",
      "370/370 [==============================] - 78s 212ms/step - loss: 0.0110 - val_loss: 0.0786\n",
      "Epoch 12/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00012: val_loss improved from 0.01371 to 0.01236, saving model to /home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetR2/ConvnetR2.hdf5\n",
      "370/370 [==============================] - 82s 223ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00013: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 201ms/step - loss: 0.0100 - val_loss: 1.6316\n",
      "Epoch 14/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 00014: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 78s 210ms/step - loss: 0.0095 - val_loss: 4.1500\n",
      "Epoch 15/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 00015: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 76s 206ms/step - loss: 0.0090 - val_loss: 8.4085\n",
      "Epoch 16/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 00016: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 203ms/step - loss: 0.0087 - val_loss: 12.1053\n",
      "Epoch 17/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0082- ETA: 2s \n",
      "Epoch 00017: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 76s 206ms/step - loss: 0.0082 - val_loss: 0.2690\n",
      "Epoch 18/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 00018: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 203ms/step - loss: 0.0080 - val_loss: 0.0296\n",
      "Epoch 19/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 00019: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 203ms/step - loss: 0.0075 - val_loss: 19.3465\n",
      "Epoch 20/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 00020: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 76s 204ms/step - loss: 0.0073 - val_loss: 13.2439\n",
      "Epoch 21/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 00021: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 203ms/step - loss: 0.0069 - val_loss: 7.0472\n",
      "Epoch 22/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 00022: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 76s 205ms/step - loss: 0.0069 - val_loss: 7.5920\n",
      "Epoch 23/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00023: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 201ms/step - loss: 0.0063 - val_loss: 9.2606\n",
      "Epoch 24/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00024: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 202ms/step - loss: 0.0062 - val_loss: 32.5286\n",
      "Epoch 25/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00025: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 74s 201ms/step - loss: 0.0060 - val_loss: 24.7052\n",
      "Epoch 26/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00026: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 74s 201ms/step - loss: 0.0059 - val_loss: 26.9996\n",
      "Epoch 27/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00027: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 202ms/step - loss: 0.0057 - val_loss: 10.4361\n",
      "Epoch 28/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00028: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 202ms/step - loss: 0.0055 - val_loss: 4.8460\n",
      "Epoch 29/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 00029: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 74s 201ms/step - loss: 0.0054 - val_loss: 2.8330\n",
      "Epoch 30/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00030: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 203ms/step - loss: 0.0052 - val_loss: 30.5407\n",
      "Epoch 31/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00031: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 75s 202ms/step - loss: 0.0051 - val_loss: 8.4864\n",
      "Epoch 32/100\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00032: val_loss did not improve from 0.01236\n",
      "370/370 [==============================] - 76s 206ms/step - loss: 0.0050 - val_loss: 3.4296\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Run model\n",
    "history = model.fit(training_seq, \n",
    "                    epochs=epochs, \n",
    "                    validation_data = (val_images, val_lab), \n",
    "                    callbacks=[EarlyStop, Checkpoint], \n",
    "                    workers = CPUworkers,\n",
    "                    shuffle = ShuffleTrainData,\n",
    "                    use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Save history\n",
    "with open(NewPath + '/TrainHistoryDict.dict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "\n",
    "#Plot 2\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
