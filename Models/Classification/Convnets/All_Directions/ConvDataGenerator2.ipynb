{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model\n",
    "from tensorflow.distribute import MirroredStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise random generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define FelixDataflow classes and functions.\n",
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type), to_categorical(np.array(batch_y),10)\n",
    "\n",
    "def gen_paths_labels(base_path = \"D:\\\\Uni Work\\\\Masters Project\\\\test_dir\"):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        segment_paths = []\n",
    "        segment_labels = []\n",
    "        for label in os.listdir(segment_path):\n",
    "            label_path = os.path.join(segment_path, label)\n",
    "            for crystal in os.listdir(label_path):\n",
    "                segment_paths.append(os.path.join(label_path, crystal))\n",
    "                segment_labels.append(label)\n",
    "        indexes = np.arange(len(segment_labels))\n",
    "        rng.shuffle(indexes)\n",
    "        yield [np.array(segment_paths)[indexes], np.array(list(map(int,segment_labels)))[indexes]]\n",
    "\n",
    "def arrs_from_paths(paths, file_type):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name) for file_name in paths])\n",
    "\n",
    "\n",
    "def felix_fit(model, batch_size, epochs, workers, callbacks, base_path, file_type):\n",
    "    \"\"\"A fit function to allow validation and test data to be supplied via a\n",
    "    generator.\"\"\"\n",
    "    data = [i for i in gen_paths_labels(base_path)]\n",
    "    val_seq = FelixSequence(data[2][0], data[2][1], batch_size, file_type)\n",
    "    train_seq = FelixSequence(data[1][0], data[1][1], batch_size, file_type)\n",
    "    test_seq = FelixSequence(data[0][0], data[0][1], batch_size, file_type)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(\"Epoch\", epoch+1, \"/\", epochs, \": \")\n",
    "        print(\"Training: \")\n",
    "        model.fit(x = train_seq, epochs = epoch+1, workers = workers, initial_epoch = epoch)\n",
    "        print(\"Validation: \")\n",
    "        model.evaluate(x = val_seq, workers = workers, callbacks = callbacks)\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Testing: \")\n",
    "    model.evaluate(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths\n",
    "\n",
    "Path = \"/home/ug-ml/felix-ML/angle_3_data\" #Path where training, validation, and test data is\n",
    "SaveDataPath = \"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder\" #Base directory of place you store information of models\n",
    "SaveFolderName = \"/ConvnetAllData2\" #Will create a folder and put in information about the outcome / inputs\n",
    "ModelName = \"/ConvnetAllData2.hdf5\"\n",
    "\n",
    "\n",
    "#Many variables\n",
    "\n",
    "#Model Variables\n",
    "input_shape = (36, 128, 128)\n",
    "\n",
    "#Hyper parameters\n",
    "learning_rate = 0.0005\n",
    "l2_regularizer = 0.0001\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = \"RMSprop\" #Not a variable ONLY used for a note\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "ShuffleTrainData = True\n",
    "\n",
    "#Call back variables\n",
    "TrainingPatience = 30\n",
    "CheckPointMonitor = 'val_acc'\n",
    "EarlyStopMonitor = 'val_acc'\n",
    "\n",
    "#CPU variables\n",
    "CPUworkers = 16\n",
    "\n",
    "\n",
    "#List the name of the variables you want to save in a file\n",
    "VariableListName = [\"input_shape\", \n",
    "                   \"learning_rate\", \"l2_regularizer\", \"loss\", \"optimizer\", \"batch_size\", \"epochs\", \"ShuffleTrainData\",\n",
    "                   \"TrainingPatience\", \"CheckPointMonitor\", \"EarlyStopMonitor\",\n",
    "                   \"CPUworkers\"]\n",
    "\n",
    "#List the variables in the same order as VariableListName\n",
    "VariableListValues = [input_shape, \n",
    "                   learning_rate, l2_regularizer, loss, optimizer, batch_size, epochs, ShuffleTrainData,\n",
    "                   TrainingPatience, CheckPointMonitor, EarlyStopMonitor,\n",
    "                   CPUworkers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder failed to be created, it may already exist\n"
     ]
    }
   ],
   "source": [
    "#Early stopping and check points\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor = EarlyStopMonitor,\n",
    "                          mode = 'min',\n",
    "                          verbose = 1,\n",
    "                          patience = TrainingPatience)\n",
    "\n",
    "NewPath = SaveDataPath + SaveFolderName\n",
    "Checkpoint = ModelCheckpoint(NewPath + ModelName, #Save path\n",
    "                             monitor = CheckPointMonitor,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 'epoch')\n",
    "\n",
    "\n",
    "#Make folder to put model and history information\n",
    "try:\n",
    "    os.mkdir(NewPath)\n",
    "except:\n",
    "    print(\"Folder failed to be created, it may already exist\")\n",
    "    \n",
    "File1  = open(NewPath +\"/Parameters.txt\", \"w+\")\n",
    "if(len(VariableListName) == len(VariableListValues)):\n",
    "    for i in range(0, len(VariableListName)):\n",
    "        File1.write(VariableListName[i] + \" \" + str(VariableListValues[i]) + \"\\n\")\n",
    "    File1.close()\n",
    "else:\n",
    "    print(\"VariableListName and VariableListValues do not match up, so file can not be saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_3 (Separabl (None, 256, 125, 125)     10048     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 62, 62)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 256, 59, 59)       69888     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 256, 29, 29)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 256, 26, 26)       69888     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 256, 13, 13)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               5537920   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 5,689,034\n",
      "Trainable params: 5,689,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.SeparableConv2D(256, (4, 4),\n",
    "                                     activation='relu',\n",
    "                                     data_format='channels_first',\n",
    "                                     input_shape= input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.SeparableConv2D(256, (4, 4),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.SeparableConv2D(256, (4, 4),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "    \n",
    "    model.add(layers.Dense(10, activation='softmax',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "\n",
    "    model.compile(loss = loss,\n",
    "                  optimizer = optimizers.RMSprop(learning_rate = learning_rate),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "#Save summary of model\n",
    "with open(NewPath + '/summary.txt','w') as fh:\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 100 : \n",
      "Training: \n",
      "2389/2389 [==============================] - ETA: 0s - loss: 1.7021 - acc: 0.364 - 508s 213ms/step - loss: 1.7021 - acc: 0.3643\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 1.4776 - acc: 0.4505\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 2 / 100 : \n",
      "Training: \n",
      "Epoch 2/2\n",
      "2389/2389 [==============================] - 502s 210ms/step - loss: 1.4160 - acc: 0.4884\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 1.2801 - acc: 0.5425\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 3 / 100 : \n",
      "Training: \n",
      "Epoch 3/3\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 1.2912 - acc: 0.5629\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 212ms/step - loss: 1.1747 - acc: 0.6034\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 4 / 100 : \n",
      "Training: \n",
      "Epoch 4/4\n",
      "2389/2389 [==============================] - 511s 214ms/step - loss: 1.1546 - acc: 0.6181\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 1.0938 - acc: 0.6451\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 5 / 100 : \n",
      "Training: \n",
      "Epoch 5/5\n",
      "2389/2389 [==============================] - 508s 213ms/step - loss: 1.0700 - acc: 0.6598\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 1.0255 - acc: 0.6709\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 6 / 100 : \n",
      "Training: \n",
      "Epoch 6/6\n",
      "2389/2389 [==============================] - 513s 215ms/step - loss: 0.9771 - acc: 0.6942\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 213ms/step - loss: 0.9753 - acc: 0.6997\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 7 / 100 : \n",
      "Training: \n",
      "Epoch 7/7\n",
      "2389/2389 [==============================] - 509s 213ms/step - loss: 0.9242 - acc: 0.7194\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.9445 - acc: 0.7200\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 8 / 100 : \n",
      "Training: \n",
      "Epoch 8/8\n",
      "2389/2389 [==============================] - 516s 216ms/step - loss: 0.8761 - acc: 0.7414\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.9194 - acc: 0.7368\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 9 / 100 : \n",
      "Training: \n",
      "Epoch 9/9\n",
      "2389/2389 [==============================] - 506s 212ms/step - loss: 0.8318 - acc: 0.7577\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.9472 - acc: 0.7242\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 10 / 100 : \n",
      "Training: \n",
      "Epoch 10/10\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 0.8021 - acc: 0.7703\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.8998 - acc: 0.7513\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 11 / 100 : \n",
      "Training: \n",
      "Epoch 11/11\n",
      "2389/2389 [==============================] - 510s 214ms/step - loss: 0.7810 - acc: 0.7814\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 0.9301 - acc: 0.7412\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 12 / 100 : \n",
      "Training: \n",
      "Epoch 12/12\n",
      "2389/2389 [==============================] - 504s 211ms/step - loss: 0.7937 - acc: 0.7909\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.8566 - acc: 0.7662\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 13 / 100 : \n",
      "Training: \n",
      "Epoch 13/13\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 0.7471 - acc: 0.7995\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 208ms/step - loss: 0.9058 - acc: 0.7469\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 14 / 100 : \n",
      "Training: \n",
      "Epoch 14/14\n",
      "2389/2389 [==============================] - 503s 211ms/step - loss: 0.7630 - acc: 0.8039\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.8993 - acc: 0.7552\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 15 / 100 : \n",
      "Training: \n",
      "Epoch 15/15\n",
      "2389/2389 [==============================] - 498s 208ms/step - loss: 0.7288 - acc: 0.8107\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 208ms/step - loss: 0.8980 - acc: 0.7713\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 16 / 100 : \n",
      "Training: \n",
      "Epoch 16/16\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 0.7027 - acc: 0.8171\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.8946 - acc: 0.7621\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 17 / 100 : \n",
      "Training: \n",
      "Epoch 17/17\n",
      "2389/2389 [==============================] - 492s 206ms/step - loss: 0.6876 - acc: 0.8199\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 206ms/step - loss: 0.9318 - acc: 0.75672s - loss: 0.9320 - \n",
      "-------------------------------------------------------------------------\n",
      "Epoch 18 / 100 : \n",
      "Training: \n",
      "Epoch 18/18\n",
      "2389/2389 [==============================] - 490s 205ms/step - loss: 0.7194 - acc: 0.8240\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 205ms/step - loss: 0.9835 - acc: 0.7747\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 19 / 100 : \n",
      "Training: \n",
      "Epoch 19/19\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.6731 - acc: 0.8271\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.8649 - acc: 0.7739\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 20 / 100 : \n",
      "Training: \n",
      "Epoch 20/20\n",
      "2389/2389 [==============================] - 490s 205ms/step - loss: 0.6632 - acc: 0.8320\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.9180 - acc: 0.7814\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 21 / 100 : \n",
      "Training: \n",
      "Epoch 21/21\n",
      "2389/2389 [==============================] - 489s 205ms/step - loss: 0.6525 - acc: 0.8354\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 203ms/step - loss: 0.8913 - acc: 0.7803\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 22 / 100 : \n",
      "Training: \n",
      "Epoch 22/22\n",
      "2389/2389 [==============================] - 491s 205ms/step - loss: 0.6585 - acc: 0.8401\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.8918 - acc: 0.77890s - loss: 0.8918 - acc: 0.778\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 23 / 100 : \n",
      "Training: \n",
      "Epoch 23/23\n",
      "2389/2389 [==============================] - 491s 205ms/step - loss: 0.6501 - acc: 0.8408\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.8524 - acc: 0.7901\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 24 / 100 : \n",
      "Training: \n",
      "Epoch 24/24\n",
      "2389/2389 [==============================] - 491s 205ms/step - loss: 0.6557 - acc: 0.8449\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.8595 - acc: 0.7971\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 25 / 100 : \n",
      "Training: \n",
      "Epoch 25/25\n",
      "2389/2389 [==============================] - 492s 206ms/step - loss: 0.6335 - acc: 0.8456\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8978 - acc: 0.7859\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 26 / 100 : \n",
      "Training: \n",
      "Epoch 26/26\n",
      "2389/2389 [==============================] - 493s 207ms/step - loss: 0.6562 - acc: 0.8474\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 206ms/step - loss: 0.8949 - acc: 0.7911\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 27 / 100 : \n",
      "Training: \n",
      "Epoch 27/27\n",
      "2389/2389 [==============================] - 493s 207ms/step - loss: 0.6191 - acc: 0.8495\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.9484 - acc: 0.7933\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 28 / 100 : \n",
      "Training: \n",
      "Epoch 28/28\n",
      "2389/2389 [==============================] - 491s 206ms/step - loss: 0.6113 - acc: 0.8529\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.9060 - acc: 0.7652\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 29 / 100 : \n",
      "Training: \n",
      "Epoch 29/29\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.6590 - acc: 0.8550\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 209ms/step - loss: 0.8864 - acc: 0.8060\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 30 / 100 : \n",
      "Training: \n",
      "Epoch 30/30\n",
      "2389/2389 [==============================] - 494s 207ms/step - loss: 0.6067 - acc: 0.8575\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.8498 - acc: 0.7968\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 31 / 100 : \n",
      "Training: \n",
      "Epoch 31/31\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.6135 - acc: 0.8556\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.9911 - acc: 0.7945\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 32 / 100 : \n",
      "Training: \n",
      "Epoch 32/32\n",
      "2389/2389 [==============================] - 499s 209ms/step - loss: 0.6142 - acc: 0.8592\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8823 - acc: 0.7973\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 33 / 100 : \n",
      "Training: \n",
      "Epoch 33/33\n",
      "2389/2389 [==============================] - 504s 211ms/step - loss: 0.5998 - acc: 0.8635\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 0.8477 - acc: 0.7993\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 34 / 100 : \n",
      "Training: \n",
      "Epoch 34/34\n",
      "2389/2389 [==============================] - 501s 210ms/step - loss: 0.5877 - acc: 0.8646\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.9090 - acc: 0.8051\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 35 / 100 : \n",
      "Training: \n",
      "Epoch 35/35\n",
      "2389/2389 [==============================] - 500s 209ms/step - loss: 0.5687 - acc: 0.8666\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.9833 - acc: 0.7707\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 36 / 100 : \n",
      "Training: \n",
      "Epoch 36/36\n",
      "2389/2389 [==============================] - 497s 208ms/step - loss: 0.5746 - acc: 0.8676\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.8663 - acc: 0.8028\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 37 / 100 : \n",
      "Training: \n",
      "Epoch 37/37\n",
      "2389/2389 [==============================] - 499s 209ms/step - loss: 0.5595 - acc: 0.8706\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 209ms/step - loss: 0.8574 - acc: 0.7941\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 38 / 100 : \n",
      "Training: \n",
      "Epoch 38/38\n",
      "2389/2389 [==============================] - 499s 209ms/step - loss: 0.5653 - acc: 0.8697\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.9254 - acc: 0.7894\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 39 / 100 : \n",
      "Training: \n",
      "Epoch 39/39\n",
      "2389/2389 [==============================] - 500s 209ms/step - loss: 0.5593 - acc: 0.8720\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.8558 - acc: 0.8051\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 40 / 100 : \n",
      "Training: \n",
      "Epoch 40/40\n",
      "2389/2389 [==============================] - 497s 208ms/step - loss: 0.6492 - acc: 0.8752\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 205ms/step - loss: 0.8985 - acc: 0.8071\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 41 / 100 : \n",
      "Training: \n",
      "Epoch 41/41\n",
      "2389/2389 [==============================] - 499s 209ms/step - loss: 0.5451 - acc: 0.8765\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.8551 - acc: 0.8039\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 42 / 100 : \n",
      "Training: \n",
      "Epoch 42/42\n",
      "2389/2389 [==============================] - 500s 209ms/step - loss: 0.5585 - acc: 0.8756\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8878 - acc: 0.8145\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 43 / 100 : \n",
      "Training: \n",
      "Epoch 43/43\n",
      "2389/2389 [==============================] - 496s 208ms/step - loss: 0.5439 - acc: 0.8769\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8568 - acc: 0.8065\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 44 / 100 : \n",
      "Training: \n",
      "Epoch 44/44\n",
      "2389/2389 [==============================] - 501s 210ms/step - loss: 0.5372 - acc: 0.8787\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8877 - acc: 0.8066\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 45 / 100 : \n",
      "Training: \n",
      "Epoch 45/45\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.5450 - acc: 0.8793\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 209ms/step - loss: 1.0269 - acc: 0.7924\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 46 / 100 : \n",
      "Training: \n",
      "Epoch 46/46\n",
      "2389/2389 [==============================] - 497s 208ms/step - loss: 0.5215 - acc: 0.8831\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.8746 - acc: 0.8071\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 47 / 100 : \n",
      "Training: \n",
      "Epoch 47/47\n",
      "2389/2389 [==============================] - 501s 210ms/step - loss: 0.5283 - acc: 0.8817\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 209ms/step - loss: 0.9525 - acc: 0.8061\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 48 / 100 : \n",
      "Training: \n",
      "Epoch 48/48\n",
      "2389/2389 [==============================] - 499s 209ms/step - loss: 0.5392 - acc: 0.8841\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.9772 - acc: 0.8051\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 49 / 100 : \n",
      "Training: \n",
      "Epoch 49/49\n",
      "2389/2389 [==============================] - 500s 209ms/step - loss: 0.5274 - acc: 0.8875\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 212ms/step - loss: 0.8445 - acc: 0.8155\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 50 / 100 : \n",
      "Training: \n",
      "Epoch 50/50\n",
      "2389/2389 [==============================] - 502s 210ms/step - loss: 0.5220 - acc: 0.8869\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 212ms/step - loss: 0.8799 - acc: 0.8086\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 51 / 100 : \n",
      "Training: \n",
      "Epoch 51/51\n",
      "2389/2389 [==============================] - 510s 214ms/step - loss: 0.5107 - acc: 0.8852\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.9233 - acc: 0.8071\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 52 / 100 : \n",
      "Training: \n",
      "Epoch 52/52\n",
      "2389/2389 [==============================] - 507s 212ms/step - loss: 0.5245 - acc: 0.8881\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.8862 - acc: 0.8031\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 53 / 100 : \n",
      "Training: \n",
      "Epoch 53/53\n",
      "2389/2389 [==============================] - 501s 210ms/step - loss: 0.5208 - acc: 0.8880\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 213ms/step - loss: 0.9234 - acc: 0.8070\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 54 / 100 : \n",
      "Training: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/54\n",
      "2389/2389 [==============================] - 509s 213ms/step - loss: 0.5096 - acc: 0.8880\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 0.8335 - acc: 0.8106\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 55 / 100 : \n",
      "Training: \n",
      "Epoch 55/55\n",
      "2389/2389 [==============================] - 503s 211ms/step - loss: 0.4994 - acc: 0.8891\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.9266 - acc: 0.8083\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 56 / 100 : \n",
      "Training: \n",
      "Epoch 56/56\n",
      "2389/2389 [==============================] - 509s 213ms/step - loss: 0.5155 - acc: 0.8899\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.9409 - acc: 0.8158\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 57 / 100 : \n",
      "Training: \n",
      "Epoch 57/57\n",
      "2389/2389 [==============================] - 502s 210ms/step - loss: 0.4912 - acc: 0.8918\n",
      "Validation: \n",
      "281/281 [==============================] - 61s 215ms/step - loss: 0.9266 - acc: 0.8122\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 58 / 100 : \n",
      "Training: \n",
      "Epoch 58/58\n",
      "2389/2389 [==============================] - 500s 209ms/step - loss: 0.5013 - acc: 0.8906\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 213ms/step - loss: 0.9234 - acc: 0.8072\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 59 / 100 : \n",
      "Training: \n",
      "Epoch 59/59\n",
      "2389/2389 [==============================] - 513s 215ms/step - loss: 0.4906 - acc: 0.8921\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 1.0042 - acc: 0.8087\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 60 / 100 : \n",
      "Training: \n",
      "Epoch 60/60\n",
      "2389/2389 [==============================] - 506s 212ms/step - loss: 0.5105 - acc: 0.8920\n",
      "Validation: \n",
      "281/281 [==============================] - 61s 217ms/step - loss: 0.8851 - acc: 0.8176\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 61 / 100 : \n",
      "Training: \n",
      "Epoch 61/61\n",
      "2389/2389 [==============================] - 506s 212ms/step - loss: 0.4879 - acc: 0.8920\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 0.8730 - acc: 0.8052\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 62 / 100 : \n",
      "Training: \n",
      "Epoch 62/62\n",
      "2389/2389 [==============================] - 516s 216ms/step - loss: 0.5304 - acc: 0.8936\n",
      "Validation: \n",
      "281/281 [==============================] - 61s 216ms/step - loss: 0.9082 - acc: 0.8101\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 63 / 100 : \n",
      "Training: \n",
      "Epoch 63/63\n",
      "2389/2389 [==============================] - 504s 211ms/step - loss: 0.4844 - acc: 0.8940\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.9642 - acc: 0.8073\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 64 / 100 : \n",
      "Training: \n",
      "Epoch 64/64\n",
      "2389/2389 [==============================] - 515s 216ms/step - loss: 0.5139 - acc: 0.8946\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.9096 - acc: 0.8180\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 65 / 100 : \n",
      "Training: \n",
      "Epoch 65/65\n",
      "2389/2389 [==============================] - 516s 216ms/step - loss: 0.4911 - acc: 0.8928\n",
      "Validation: \n",
      "281/281 [==============================] - 61s 217ms/step - loss: 0.8241 - acc: 0.8112\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 66 / 100 : \n",
      "Training: \n",
      "Epoch 66/66\n",
      "2389/2389 [==============================] - 512s 214ms/step - loss: 0.4983 - acc: 0.8948\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.9696 - acc: 0.8133\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 67 / 100 : \n",
      "Training: \n",
      "Epoch 67/67\n",
      "2389/2389 [==============================] - 513s 215ms/step - loss: 0.4796 - acc: 0.8953\n",
      "Validation: \n",
      "281/281 [==============================] - 65s 232ms/step - loss: 0.9482 - acc: 0.8156\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 68 / 100 : \n",
      "Training: \n",
      "Epoch 68/68\n",
      "2389/2389 [==============================] - 545s 228ms/step - loss: 0.5001 - acc: 0.8975s - loss: \n",
      "Validation: \n",
      "281/281 [==============================] - 69s 246ms/step - loss: 0.9126 - acc: 0.8171\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 69 / 100 : \n",
      "Training: \n",
      "Epoch 69/69\n",
      "2389/2389 [==============================] - 513s 215ms/step - loss: 0.4708 - acc: 0.8979\n",
      "Validation: \n",
      "281/281 [==============================] - 82s 291ms/step - loss: 0.9256 - acc: 0.8108\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 70 / 100 : \n",
      "Training: \n",
      "Epoch 70/70\n",
      "2389/2389 [==============================] - 515s 215ms/step - loss: 0.4694 - acc: 0.8963\n",
      "Validation: \n",
      "281/281 [==============================] - 98s 348ms/step - loss: 0.9089 - acc: 0.8127\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 71 / 100 : \n",
      "Training: \n",
      "Epoch 71/71\n",
      "2389/2389 [==============================] - 598s 250ms/step - loss: 0.5234 - acc: 0.8967\n",
      "Validation: \n",
      "281/281 [==============================] - 108s 383ms/step - loss: 0.9274 - acc: 0.8186\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 72 / 100 : \n",
      "Training: \n",
      "Epoch 72/72\n",
      "2389/2389 [==============================] - 904s 379ms/step - loss: 0.4802 - acc: 0.8937\n",
      "Validation: \n",
      "281/281 [==============================] - 110s 390ms/step - loss: 0.8944 - acc: 0.8128\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 73 / 100 : \n",
      "Training: \n",
      "Epoch 73/73\n",
      "2389/2389 [==============================] - 1012s 424ms/step - loss: 0.4941 - acc: 0.8961\n",
      "Validation: \n",
      "281/281 [==============================] - 109s 388ms/step - loss: 0.9361 - acc: 0.8155\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 74 / 100 : \n",
      "Training: \n",
      "Epoch 74/74\n",
      "2389/2389 [==============================] - 978s 409ms/step - loss: 0.4599 - acc: 0.8980\n",
      "Validation: \n",
      "281/281 [==============================] - 102s 365ms/step - loss: 0.8363 - acc: 0.8075\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 75 / 100 : \n",
      "Training: \n",
      "Epoch 75/75\n",
      "2389/2389 [==============================] - 897s 376ms/step - loss: 0.4601 - acc: 0.8989\n",
      "Validation: \n",
      "281/281 [==============================] - 95s 338ms/step - loss: 1.0104 - acc: 0.8093\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 76 / 100 : \n",
      "Training: \n",
      "Epoch 76/76\n",
      "2389/2389 [==============================] - 763s 319ms/step - loss: 0.4899 - acc: 0.8986\n",
      "Validation: \n",
      "281/281 [==============================] - 92s 326ms/step - loss: 0.9815 - acc: 0.8140\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 77 / 100 : \n",
      "Training: \n",
      "Epoch 77/77\n",
      "2389/2389 [==============================] - 635s 266ms/step - loss: 0.4487 - acc: 0.9004\n",
      "Validation: \n",
      "281/281 [==============================] - 86s 307ms/step - loss: 1.0121 - acc: 0.8103\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 78 / 100 : \n",
      "Training: \n",
      "Epoch 78/78\n",
      "2389/2389 [==============================] - 598s 251ms/step - loss: 0.4500 - acc: 0.8993\n",
      "Validation: \n",
      "281/281 [==============================] - 82s 291ms/step - loss: 0.8750 - acc: 0.8156\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 79 / 100 : \n",
      "Training: \n",
      "Epoch 79/79\n",
      "2389/2389 [==============================] - 582s 244ms/step - loss: 0.4493 - acc: 0.9026\n",
      "Validation: \n",
      "281/281 [==============================] - 81s 287ms/step - loss: 0.9338 - acc: 0.8116\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 80 / 100 : \n",
      "Training: \n",
      "Epoch 80/80\n",
      "2389/2389 [==============================] - 562s 235ms/step - loss: 0.4428 - acc: 0.9005\n",
      "Validation: \n",
      "281/281 [==============================] - 77s 274ms/step - loss: 0.8935 - acc: 0.8171\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 81 / 100 : \n",
      "Training: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/81\n",
      "2389/2389 [==============================] - 555s 232ms/step - loss: 0.4852 - acc: 0.9024\n",
      "Validation: \n",
      "281/281 [==============================] - 73s 261ms/step - loss: 1.0012 - acc: 0.8113\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 82 / 100 : \n",
      "Training: \n",
      "Epoch 82/82\n",
      "2389/2389 [==============================] - 542s 227ms/step - loss: 0.4515 - acc: 0.9018\n",
      "Validation: \n",
      "281/281 [==============================] - 71s 253ms/step - loss: 0.9870 - acc: 0.8079\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 83 / 100 : \n",
      "Training: \n",
      "Epoch 83/83\n",
      "2389/2389 [==============================] - 540s 226ms/step - loss: 0.4431 - acc: 0.9021\n",
      "Validation: \n",
      "281/281 [==============================] - 67s 239ms/step - loss: 1.0068 - acc: 0.8123\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 84 / 100 : \n",
      "Training: \n",
      "Epoch 84/84\n",
      "2389/2389 [==============================] - 532s 223ms/step - loss: 0.4359 - acc: 0.9024\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 228ms/step - loss: 1.0511 - acc: 0.8097\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 85 / 100 : \n",
      "Training: \n",
      "Epoch 85/85\n",
      "2389/2389 [==============================] - 528s 221ms/step - loss: 0.4409 - acc: 0.9035\n",
      "Validation: \n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.9879 - acc: 0.8152\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 86 / 100 : \n",
      "Training: \n",
      "Epoch 86/86\n",
      "2389/2389 [==============================] - 534s 223ms/step - loss: 0.4233 - acc: 0.9045\n",
      "Validation: \n",
      "281/281 [==============================] - 63s 224ms/step - loss: 0.9491 - acc: 0.8175\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 87 / 100 : \n",
      "Training: \n",
      "Epoch 87/87\n",
      "2389/2389 [==============================] - 533s 223ms/step - loss: 0.4206 - acc: 0.9079\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 227ms/step - loss: 0.9249 - acc: 0.8119\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 88 / 100 : \n",
      "Training: \n",
      "Epoch 88/88\n",
      "2389/2389 [==============================] - 535s 224ms/step - loss: 0.4500 - acc: 0.9092\n",
      "Validation: \n",
      "281/281 [==============================] - 63s 224ms/step - loss: 0.9398 - acc: 0.8096\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 89 / 100 : \n",
      "Training: \n",
      "Epoch 89/89\n",
      "2389/2389 [==============================] - 523s 219ms/step - loss: 0.4003 - acc: 0.9114\n",
      "Validation: \n",
      "281/281 [==============================] - 65s 230ms/step - loss: 0.8945 - acc: 0.8209\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 90 / 100 : \n",
      "Training: \n",
      "Epoch 90/90\n",
      "2389/2389 [==============================] - 529s 222ms/step - loss: 0.4086 - acc: 0.9120\n",
      "Validation: \n",
      "281/281 [==============================] - 63s 224ms/step - loss: 0.8911 - acc: 0.8168\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 91 / 100 : \n",
      "Training: \n",
      "Epoch 91/91\n",
      "2389/2389 [==============================] - 538s 225ms/step - loss: 0.3935 - acc: 0.9150\n",
      "Validation: \n",
      "281/281 [==============================] - 63s 226ms/step - loss: 1.0043 - acc: 0.8121\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 92 / 100 : \n",
      "Training: \n",
      "Epoch 92/92\n",
      "2389/2389 [==============================] - 533s 223ms/step - loss: 0.3883 - acc: 0.9150\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 228ms/step - loss: 0.9838 - acc: 0.8111\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 93 / 100 : \n",
      "Training: \n",
      "Epoch 93/93\n",
      "2389/2389 [==============================] - 540s 226ms/step - loss: 0.3809 - acc: 0.9176\n",
      "Validation: \n",
      "281/281 [==============================] - 65s 231ms/step - loss: 0.9107 - acc: 0.8199\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 94 / 100 : \n",
      "Training: \n",
      "Epoch 94/94\n",
      "2389/2389 [==============================] - 545s 228ms/step - loss: 0.4028 - acc: 0.9175\n",
      "Validation: \n",
      "281/281 [==============================] - 65s 232ms/step - loss: 0.9925 - acc: 0.8206\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 95 / 100 : \n",
      "Training: \n",
      "Epoch 95/95\n",
      "2389/2389 [==============================] - 533s 223ms/step - loss: 0.3783 - acc: 0.9187\n",
      "Validation: \n",
      "281/281 [==============================] - 63s 226ms/step - loss: 1.2681 - acc: 0.8048\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 96 / 100 : \n",
      "Training: \n",
      "Epoch 96/96\n",
      "2389/2389 [==============================] - 538s 225ms/step - loss: 0.3739 - acc: 0.9199\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 226ms/step - loss: 0.9654 - acc: 0.7979\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 97 / 100 : \n",
      "Training: \n",
      "Epoch 97/97\n",
      "2389/2389 [==============================] - 539s 225ms/step - loss: 0.3632 - acc: 0.9215\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 229ms/step - loss: 0.8691 - acc: 0.7889\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 98 / 100 : \n",
      "Training: \n",
      "Epoch 98/98\n",
      "2389/2389 [==============================] - 536s 224ms/step - loss: 0.3790 - acc: 0.9216\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 227ms/step - loss: 1.0547 - acc: 0.8155\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 99 / 100 : \n",
      "Training: \n",
      "Epoch 99/99\n",
      "2389/2389 [==============================] - 547s 229ms/step - loss: 0.3581 - acc: 0.9236\n",
      "Validation: \n",
      "281/281 [==============================] - 64s 228ms/step - loss: 1.0354 - acc: 0.8199\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 100 / 100 : \n",
      "Training: \n",
      "Epoch 100/100\n",
      "2389/2389 [==============================] - 539s 226ms/step - loss: 0.3507 - acc: 0.9250\n",
      "Validation: \n",
      "281/281 [==============================] - 66s 235ms/step - loss: 0.9184 - acc: 0.8253\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "141/141 [==============================] - 86s 608ms/step - loss: 0.8806 - acc: 0.8420\n"
     ]
    }
   ],
   "source": [
    "felix_fit(model, batch_size, epochs, CPUworkers, [EarlyStop, Checkpoint], Path, \"npy\")\n",
    "#data = [i for i in gen_paths_labels(Path)]\n",
    "#val_seq = FelixSequence(data[2][0], data[2][1], batch_size, \"npy\")\n",
    "#print(data[1][0].shape)\n",
    "#train_seq = FelixSequence(data[1][0], data[1][1], batch_size, \"npy\")\n",
    "#model.fit(x = train_seq, epochs = epochs, workers = CPUworkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder/ConvnetAllData2/ConvnetAllData2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
