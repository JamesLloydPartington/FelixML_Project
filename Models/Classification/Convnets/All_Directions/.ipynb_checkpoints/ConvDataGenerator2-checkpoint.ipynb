{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model\n",
    "from tensorflow.distribute import MirroredStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise random generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define FelixDataflow classes and functions.\n",
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type), to_categorical(np.array(batch_y),10)\n",
    "\n",
    "def gen_paths_labels(base_path = \"D:\\\\Uni Work\\\\Masters Project\\\\test_dir\"):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        segment_paths = []\n",
    "        segment_labels = []\n",
    "        for label in os.listdir(segment_path):\n",
    "            label_path = os.path.join(segment_path, label)\n",
    "            for crystal in os.listdir(label_path):\n",
    "                segment_paths.append(os.path.join(label_path, crystal))\n",
    "                segment_labels.append(label)\n",
    "        indexes = np.arange(len(segment_labels))\n",
    "        rng.shuffle(indexes)\n",
    "        yield [np.array(segment_paths)[indexes], np.array(list(map(int,segment_labels)))[indexes]]\n",
    "\n",
    "def arrs_from_paths(paths, file_type):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name) for file_name in paths])\n",
    "\n",
    "\n",
    "def felix_fit(model, batch_size, epochs, workers, callbacks, base_path, file_type):\n",
    "    \"\"\"A fit function to allow validation and test data to be supplied via a\n",
    "    generator.\"\"\"\n",
    "    data = [i for i in gen_paths_labels(base_path)]\n",
    "    val_seq = FelixSequence(data[2][0], data[2][1], batch_size, file_type)\n",
    "    train_seq = FelixSequence(data[1][0], data[1][1], batch_size, file_type)\n",
    "    test_seq = FelixSequence(data[0][0], data[0][1], batch_size, file_type)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(\"Epoch\", epoch+1, \"/\", epochs, \": \")\n",
    "        print(\"Training: \")\n",
    "        model.fit(x = train_seq, epochs = epoch+1, workers = workers, initial_epoch = epoch)\n",
    "        print(\"Validation: \")\n",
    "        model.evaluate(x = val_seq, workers = workers, callbacks = callbacks)\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Testing: \")\n",
    "    model.evaluate(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths\n",
    "\n",
    "Path = \"/home/ug-ml/felix-ML/angle_3_data\" #Path where training, validation, and test data is\n",
    "SaveDataPath = \"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder\" #Base directory of place you store information of models\n",
    "SaveFolderName = \"/ConvnetAllData2\" #Will create a folder and put in information about the outcome / inputs\n",
    "ModelName = \"/ConvnetAllData2.hdf5\"\n",
    "\n",
    "\n",
    "#Many variables\n",
    "\n",
    "#Model Variables\n",
    "input_shape = (36, 128, 128)\n",
    "\n",
    "#Hyper parameters\n",
    "learning_rate = 0.0005\n",
    "l2_regularizer = 0.0001\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = \"RMSprop\" #Not a variable ONLY used for a note\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "ShuffleTrainData = True\n",
    "\n",
    "#Call back variables\n",
    "TrainingPatience = 30\n",
    "CheckPointMonitor = 'val_acc'\n",
    "EarlyStopMonitor = 'val_acc'\n",
    "\n",
    "#CPU variables\n",
    "CPUworkers = 16\n",
    "\n",
    "\n",
    "#List the name of the variables you want to save in a file\n",
    "VariableListName = [\"input_shape\", \n",
    "                   \"learning_rate\", \"l2_regularizer\", \"loss\", \"optimizer\", \"batch_size\", \"epochs\", \"ShuffleTrainData\",\n",
    "                   \"TrainingPatience\", \"CheckPointMonitor\", \"EarlyStopMonitor\",\n",
    "                   \"CPUworkers\"]\n",
    "\n",
    "#List the variables in the same order as VariableListName\n",
    "VariableListValues = [input_shape, \n",
    "                   learning_rate, l2_regularizer, loss, optimizer, batch_size, epochs, ShuffleTrainData,\n",
    "                   TrainingPatience, CheckPointMonitor, EarlyStopMonitor,\n",
    "                   CPUworkers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder failed to be created, it may already exist\n"
     ]
    }
   ],
   "source": [
    "#Early stopping and check points\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor = EarlyStopMonitor,\n",
    "                          mode = 'min',\n",
    "                          verbose = 1,\n",
    "                          patience = TrainingPatience)\n",
    "\n",
    "NewPath = SaveDataPath + SaveFolderName\n",
    "Checkpoint = ModelCheckpoint(NewPath + ModelName, #Save path\n",
    "                             monitor = CheckPointMonitor,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 'epoch')\n",
    "\n",
    "\n",
    "#Make folder to put model and history information\n",
    "try:\n",
    "    os.mkdir(NewPath)\n",
    "except:\n",
    "    print(\"Folder failed to be created, it may already exist\")\n",
    "    \n",
    "File1  = open(NewPath +\"/Parameters.txt\", \"w+\")\n",
    "if(len(VariableListName) == len(VariableListValues)):\n",
    "    for i in range(0, len(VariableListName)):\n",
    "        File1.write(VariableListName[i] + \" \" + str(VariableListValues[i]) + \"\\n\")\n",
    "    File1.close()\n",
    "else:\n",
    "    print(\"VariableListName and VariableListValues do not match up, so file can not be saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_3 (Separabl (None, 256, 125, 125)     10048     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 62, 62)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 256, 59, 59)       69888     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 256, 29, 29)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 256, 26, 26)       69888     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 256, 13, 13)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               5537920   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 5,689,034\n",
      "Trainable params: 5,689,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.SeparableConv2D(256, (4, 4),\n",
    "                                     activation='relu',\n",
    "                                     data_format='channels_first',\n",
    "                                     input_shape= input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.SeparableConv2D(256, (4, 4),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.SeparableConv2D(256, (4, 4),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "    \n",
    "    model.add(layers.Dense(10, activation='softmax',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "\n",
    "    model.compile(loss = loss,\n",
    "                  optimizer = optimizers.RMSprop(learning_rate = learning_rate),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "#Save summary of model\n",
    "with open(NewPath + '/summary.txt','w') as fh:\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 100 : \n",
      "Training: \n",
      "2389/2389 [==============================] - ETA: 0s - loss: 1.7021 - acc: 0.364 - 508s 213ms/step - loss: 1.7021 - acc: 0.3643\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 1.4776 - acc: 0.4505\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 2 / 100 : \n",
      "Training: \n",
      "Epoch 2/2\n",
      "2389/2389 [==============================] - 502s 210ms/step - loss: 1.4160 - acc: 0.4884\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 1.2801 - acc: 0.5425\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 3 / 100 : \n",
      "Training: \n",
      "Epoch 3/3\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 1.2912 - acc: 0.5629\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 212ms/step - loss: 1.1747 - acc: 0.6034\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 4 / 100 : \n",
      "Training: \n",
      "Epoch 4/4\n",
      "2389/2389 [==============================] - 511s 214ms/step - loss: 1.1546 - acc: 0.6181\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 1.0938 - acc: 0.6451\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 5 / 100 : \n",
      "Training: \n",
      "Epoch 5/5\n",
      "2389/2389 [==============================] - 508s 213ms/step - loss: 1.0700 - acc: 0.6598\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 1.0255 - acc: 0.6709\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 6 / 100 : \n",
      "Training: \n",
      "Epoch 6/6\n",
      "2389/2389 [==============================] - 513s 215ms/step - loss: 0.9771 - acc: 0.6942\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 213ms/step - loss: 0.9753 - acc: 0.6997\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 7 / 100 : \n",
      "Training: \n",
      "Epoch 7/7\n",
      "2389/2389 [==============================] - 509s 213ms/step - loss: 0.9242 - acc: 0.7194\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.9445 - acc: 0.7200\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 8 / 100 : \n",
      "Training: \n",
      "Epoch 8/8\n",
      "2389/2389 [==============================] - 516s 216ms/step - loss: 0.8761 - acc: 0.7414\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.9194 - acc: 0.7368\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 9 / 100 : \n",
      "Training: \n",
      "Epoch 9/9\n",
      "2389/2389 [==============================] - 506s 212ms/step - loss: 0.8318 - acc: 0.7577\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 215ms/step - loss: 0.9472 - acc: 0.7242\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 10 / 100 : \n",
      "Training: \n",
      "Epoch 10/10\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 0.8021 - acc: 0.7703\n",
      "Validation: \n",
      "281/281 [==============================] - 60s 214ms/step - loss: 0.8998 - acc: 0.7513\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 11 / 100 : \n",
      "Training: \n",
      "Epoch 11/11\n",
      "2389/2389 [==============================] - 510s 214ms/step - loss: 0.7810 - acc: 0.7814\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 212ms/step - loss: 0.9301 - acc: 0.7412\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 12 / 100 : \n",
      "Training: \n",
      "Epoch 12/12\n",
      "2389/2389 [==============================] - 504s 211ms/step - loss: 0.7937 - acc: 0.7909\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.8566 - acc: 0.7662\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 13 / 100 : \n",
      "Training: \n",
      "Epoch 13/13\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 0.7471 - acc: 0.7995\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 208ms/step - loss: 0.9058 - acc: 0.7469\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 14 / 100 : \n",
      "Training: \n",
      "Epoch 14/14\n",
      "2389/2389 [==============================] - 503s 211ms/step - loss: 0.7630 - acc: 0.8039\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.8993 - acc: 0.7552\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 15 / 100 : \n",
      "Training: \n",
      "Epoch 15/15\n",
      "2389/2389 [==============================] - 498s 208ms/step - loss: 0.7288 - acc: 0.8107\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 208ms/step - loss: 0.8980 - acc: 0.7713\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 16 / 100 : \n",
      "Training: \n",
      "Epoch 16/16\n",
      "2389/2389 [==============================] - 505s 211ms/step - loss: 0.7027 - acc: 0.8171\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 211ms/step - loss: 0.8946 - acc: 0.7621\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 17 / 100 : \n",
      "Training: \n",
      "Epoch 17/17\n",
      "2389/2389 [==============================] - 492s 206ms/step - loss: 0.6876 - acc: 0.8199\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 206ms/step - loss: 0.9318 - acc: 0.75672s - loss: 0.9320 - \n",
      "-------------------------------------------------------------------------\n",
      "Epoch 18 / 100 : \n",
      "Training: \n",
      "Epoch 18/18\n",
      "2389/2389 [==============================] - 490s 205ms/step - loss: 0.7194 - acc: 0.8240\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 205ms/step - loss: 0.9835 - acc: 0.7747\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 19 / 100 : \n",
      "Training: \n",
      "Epoch 19/19\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.6731 - acc: 0.8271\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.8649 - acc: 0.7739\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 20 / 100 : \n",
      "Training: \n",
      "Epoch 20/20\n",
      "2389/2389 [==============================] - 490s 205ms/step - loss: 0.6632 - acc: 0.8320\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.9180 - acc: 0.7814\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 21 / 100 : \n",
      "Training: \n",
      "Epoch 21/21\n",
      "2389/2389 [==============================] - 489s 205ms/step - loss: 0.6525 - acc: 0.8354\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 203ms/step - loss: 0.8913 - acc: 0.7803\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 22 / 100 : \n",
      "Training: \n",
      "Epoch 22/22\n",
      "2389/2389 [==============================] - 491s 205ms/step - loss: 0.6585 - acc: 0.8401\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.8918 - acc: 0.77890s - loss: 0.8918 - acc: 0.778\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 23 / 100 : \n",
      "Training: \n",
      "Epoch 23/23\n",
      "2389/2389 [==============================] - 491s 205ms/step - loss: 0.6501 - acc: 0.8408\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.8524 - acc: 0.7901\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 24 / 100 : \n",
      "Training: \n",
      "Epoch 24/24\n",
      "2389/2389 [==============================] - 491s 205ms/step - loss: 0.6557 - acc: 0.8449\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.8595 - acc: 0.7971\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 25 / 100 : \n",
      "Training: \n",
      "Epoch 25/25\n",
      "2389/2389 [==============================] - 492s 206ms/step - loss: 0.6335 - acc: 0.8456\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8978 - acc: 0.7859\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 26 / 100 : \n",
      "Training: \n",
      "Epoch 26/26\n",
      "2389/2389 [==============================] - 493s 207ms/step - loss: 0.6562 - acc: 0.8474\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 206ms/step - loss: 0.8949 - acc: 0.7911\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 27 / 100 : \n",
      "Training: \n",
      "Epoch 27/27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2389/2389 [==============================] - 493s 207ms/step - loss: 0.6191 - acc: 0.8495\n",
      "Validation: \n",
      "281/281 [==============================] - 57s 204ms/step - loss: 0.9484 - acc: 0.7933\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 28 / 100 : \n",
      "Training: \n",
      "Epoch 28/28\n",
      "2389/2389 [==============================] - 491s 206ms/step - loss: 0.6113 - acc: 0.8529\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.9060 - acc: 0.7652\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 29 / 100 : \n",
      "Training: \n",
      "Epoch 29/29\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.6590 - acc: 0.8550\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 209ms/step - loss: 0.8864 - acc: 0.8060\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 30 / 100 : \n",
      "Training: \n",
      "Epoch 30/30\n",
      "2389/2389 [==============================] - 494s 207ms/step - loss: 0.6067 - acc: 0.8575\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 207ms/step - loss: 0.8498 - acc: 0.7968\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 31 / 100 : \n",
      "Training: \n",
      "Epoch 31/31\n",
      "2389/2389 [==============================] - 495s 207ms/step - loss: 0.6135 - acc: 0.8556\n",
      "Validation: \n",
      "281/281 [==============================] - 59s 210ms/step - loss: 0.9911 - acc: 0.7945\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 32 / 100 : \n",
      "Training: \n",
      "Epoch 32/32\n",
      "2389/2389 [==============================] - 499s 209ms/step - loss: 0.6142 - acc: 0.8592\n",
      "Validation: \n",
      "281/281 [==============================] - 58s 208ms/step - loss: 0.8823 - acc: 0.7973\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 33 / 100 : \n",
      "Training: \n",
      "Epoch 33/33\n",
      "2340/2389 [============================>.] - ETA: 10s - loss: 0.5994 - acc: 0.8637"
     ]
    }
   ],
   "source": [
    "felix_fit(model, batch_size, epochs, CPUworkers, [EarlyStop, Checkpoint], Path, \"npy\")\n",
    "#data = [i for i in gen_paths_labels(Path)]\n",
    "#val_seq = FelixSequence(data[2][0], data[2][1], batch_size, \"npy\")\n",
    "#print(data[1][0].shape)\n",
    "#train_seq = FelixSequence(data[1][0], data[1][1], batch_size, \"npy\")\n",
    "#model.fit(x = train_seq, epochs = epochs, workers = CPUworkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/ConvnetAllData2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
