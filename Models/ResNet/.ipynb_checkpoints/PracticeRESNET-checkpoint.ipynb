{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model\n",
    "from tensorflow.distribute import MirroredStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths\n",
    "\n",
    "Path = \"/home/ug-ml/felix-ML/DataGenerator2/Data\" #Path where training and validation data is\n",
    "SaveDataPath = \"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder\" #Base directory of place you store information of models\n",
    "CifFlolder = \"/home/ug-ml/felix-ML/DataGenerator2/CifFolder\"\n",
    "SaveFolderName = \"/Convnet6\" #Will create a folder and put in information about the outcome / inputs\n",
    "ModelName = \"/Convnet6.hdf5\"\n",
    "\n",
    "\n",
    "#Many variables\n",
    "\n",
    "#Model Variables\n",
    "input_shape = (36, 128, 128)\n",
    "\n",
    "#Hyper parameters\n",
    "learning_rate = 0.0005\n",
    "l2_regularizer = 0.0001\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = \"RMSprop\" #Not a variable ONLY used for a note\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "ShuffleTrainData = True\n",
    "\n",
    "#Call back variables\n",
    "TrainingPatience = 20\n",
    "CheckPointMonitor = 'val_acc'\n",
    "EarlyStopMonitor = 'val_acc'\n",
    "\n",
    "#CPU variables\n",
    "CPUworkers = 16\n",
    "\n",
    "#Limit range\n",
    "LatticeRange = [6, 11]\n",
    "\n",
    "\n",
    "#List the name of the variables you want to save in a file\n",
    "VariableListName = [\"input_shape\", \n",
    "                   \"learning_rate\", \"l2_regularizer\", \"loss\", \"optimizer\", \"batch_size\", \"epochs\", \"ShuffleTrainData\",\n",
    "                   \"TrainingPatience\", \"CheckPointMonitor\", \"EarlyStopMonitor\",\n",
    "                   \"CPUworkers\",\n",
    "                   \"LatticeRange\"]\n",
    "\n",
    "#List the variables in the same order as VariableListName\n",
    "VariableListValues = [input_shape, \n",
    "                   learning_rate, l2_regularizer, loss, optimizer, batch_size, epochs, ShuffleTrainData,\n",
    "                   TrainingPatience, CheckPointMonitor, EarlyStopMonitor,\n",
    "                    CPUworkers,\n",
    "                      LatticeRange]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder failed to be created, it may already exist\n"
     ]
    }
   ],
   "source": [
    "#Early stopping and check points\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor = EarlyStopMonitor,\n",
    "                          mode = 'auto',\n",
    "                          verbose = 1,\n",
    "                          patience = TrainingPatience)\n",
    "\n",
    "NewPath = SaveDataPath + SaveFolderName\n",
    "Checkpoint = ModelCheckpoint(NewPath + ModelName, #Save path\n",
    "                             monitor = CheckPointMonitor,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 'epoch')\n",
    "\n",
    "\n",
    "#Make folder to put model and history information\n",
    "try:\n",
    "    os.mkdir(NewPath)\n",
    "except:\n",
    "    print(\"Folder failed to be created, it may already exist\")\n",
    "    \n",
    "File1  = open(NewPath +\"/Parameters.txt\", \"w+\")\n",
    "if(len(VariableListName) == len(VariableListValues)):\n",
    "    for i in range(0, len(VariableListName)):\n",
    "        File1.write(VariableListName[i] + \" \" + str(VariableListValues[i]) + \"\\n\")\n",
    "    File1.close()\n",
    "else:\n",
    "    print(\"VariableListName and VariableListValues do not match up, so file can not be saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img1 (InputLayer)               [(None, 36, 128, 128 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 128, 128, 128 5060        img1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 64, 64)  0           separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 128, 64, 64)  17664       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 64, 64)  0           separable_conv2d_4[0][0]         \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 128, 62, 62)  17664       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 62)           0           separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 62)           0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 62)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1008        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           170         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,566\n",
      "Trainable params: 41,566\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "#strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "#with strategy.scope():\n",
    "inputs = keras.Input(shape = (36, 128, 128), name = \"img1\")\n",
    "x = layers.SeparableConv2D(128, (3, 3), activation='relu', data_format='channels_first', padding = \"same\")(inputs)\n",
    "#x = layers.SeparableConv2D(128, (3, 3), activation='relu', data_format='channels_first', padding = \"same\")(x)\n",
    "block_1_output = layers.MaxPooling2D((2, 2), data_format='channels_first')(x)\n",
    "\n",
    "x = layers.SeparableConv2D(128, (3, 3), activation='relu', data_format='channels_first', padding = \"same\")(block_1_output)\n",
    "#x = layers.SeparableConv2D(128, (3, 3), activation='relu', data_format='channels_first', padding = \"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "#x = layers.Conv2D(128, (3, 3), activation='relu', data_format='channels_first', padding = \"same\")(block_2_output)\n",
    "#x = layers.Conv2D(128, (3, 3), activation='relu', data_format='channels_first', padding = \"same\")(x)\n",
    "#block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.SeparableConv2D(128, (3, 3), activation='relu', data_format='channels_first')(block_2_output)\n",
    "#x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.MaxPooling2D((2, 2), data_format='channels_first')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Model(inputs, outputs, name = \"ResNN\")\n",
    "with open(NewPath + '/summary.txt','w') as fh:\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data done.\n",
      "training_seq done.\n",
      "val_images done.\n",
      "val_lab done.\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#Load data generators\n",
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type), to_categorical(np.array(batch_y),10)\n",
    "\n",
    "def arrs_from_paths(paths, file_type):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name) for file_name in paths]) \n",
    "    \n",
    "    \n",
    "#Define Data gemerator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "PathOfFile = CifFlolder +\"/FilePaths.txt\"\n",
    "with open(PathOfFile) as textFile:\n",
    "    lines = [line.split() for line in textFile]\n",
    "\n",
    "\n",
    "training_path = []\n",
    "training_labels = []\n",
    "validation_path = []\n",
    "validation_labels = []\n",
    "for i in lines:\n",
    "    PathSplit = i[0].split(\"/\")\n",
    "    for j in PathSplit:\n",
    "        if(j == \"training\"):\n",
    "            if(float(i[3]) > LatticeRange[0] and float(i[3]) < LatticeRange[1]):\n",
    "                training_path.append(i[0])\n",
    "                training_labels.append(int(i[2]))\n",
    "                break\n",
    "            \n",
    "        elif(j == \"validation\"):\n",
    "            if(float(i[3]) > LatticeRange[0] and float(i[3]) < LatticeRange[1]):\n",
    "                validation_path.append(i[0])\n",
    "                validation_labels.append(int(i[2]))\n",
    "                break\n",
    "\n",
    "                \n",
    "trainsize = len(training_path)\n",
    "validationsize = len(validation_path)\n",
    "\n",
    "ShuffleTraining = np.arange(trainsize, dtype = np.int)\n",
    "ShuffleValidation = np.arange(validationsize, dtype = np.int)\n",
    "\n",
    "training_path_shuffled = training_path.copy()\n",
    "training_labels_shuffled = training_labels.copy()\n",
    "validation_path_shuffled = validation_path.copy()\n",
    "validation_labels_shuffled = validation_labels.copy()\n",
    "\n",
    "rng.shuffle(ShuffleTraining)\n",
    "rng.shuffle(ShuffleValidation)\n",
    "\n",
    "for i in range(0, trainsize):\n",
    "    training_path_shuffled[i] = training_path[ShuffleTraining[i]]\n",
    "    training_labels_shuffled[i] = training_labels[ShuffleTraining[i]]\n",
    "    #print(training_path_shuffled[i], training_labels_shuffled[i])\n",
    "\n",
    "for i in range(0, validationsize):\n",
    "    validation_path_shuffled[i] = validation_path[ShuffleValidation[i]]\n",
    "    validation_labels_shuffled[i] = validation_labels[ShuffleValidation[i]]\n",
    "    #print(validation_path_shuffled[i], validation_labels_shuffled[i])\n",
    "    \n",
    "print(\"data done.\")\n",
    "training_seq = FelixSequence(training_path_shuffled, training_labels_shuffled, batch_size, \"npy\")\n",
    "print(\"training_seq done.\")\n",
    "val_images = arrs_from_paths(validation_path_shuffled, \"npy\")\n",
    "print(\"val_images done.\")\n",
    "val_lab = to_categorical(validation_labels_shuffled)\n",
    "print(\"val_lab done.\")\n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 96/370 [======>.......................] - ETA: 1:10 - loss: 7.7016 - acc: 0.0967"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4b77e3b2f03b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCPUworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleTrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     use_multiprocessing = False)\n\u001b[0m",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss,\n",
    "                  optimizer = optimizers.RMSprop(learning_rate = learning_rate),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "\n",
    "history = model.fit(training_seq, \n",
    "                    epochs=epochs, \n",
    "                    validation_data = (val_images, val_lab), \n",
    "                    callbacks=[EarlyStop, Checkpoint], \n",
    "                    workers = CPUworkers,\n",
    "                    shuffle = ShuffleTrainData,\n",
    "                    use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
