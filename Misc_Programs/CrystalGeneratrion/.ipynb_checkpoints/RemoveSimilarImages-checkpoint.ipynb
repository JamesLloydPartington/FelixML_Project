{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from keras import Input, layers, backend, Model, losses, datasets, models, metrics, optimizers, initializers\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "Path = \"/home/ug-ml/felix-ML/VAE_000/Data/Data\" #Folder containing Training Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImages(Path):\n",
    "    All_Paths = []\n",
    "    NumberTraining = 0\n",
    "    NumberValidation = 0\n",
    "    NumberTest = 0\n",
    "    Path_i = sorted(os.listdir(Path)) #Training Validation and Test\n",
    "    for i in Path_i: #i training, validation and test\n",
    "        Path_j = sorted(os.listdir(Path + \"/\" + i))\n",
    "        for j in Path_j: #j is the crystal\n",
    "            InputFile = Path + \"/\" + i + \"/\" + j +\"/\" + \"Input.npy\"\n",
    "            OutputFile = Path + \"/\" + i + \"/\" + j +\"/\" + \"Output.npy\"\n",
    "            if(i == \"Training\"):\n",
    "                All_Paths.append([InputFile, OutputFile])\n",
    "                NumberTraining+=1\n",
    "            elif(i == \"Validation\"):\n",
    "                All_Paths.append([InputFile, OutputFile])\n",
    "                NumberValidation+=1\n",
    "            else:\n",
    "                All_Paths.append([InputFile, OutputFile])\n",
    "                NumberTest+=1\n",
    "    \n",
    "    All_Images = np.zeros((NumberTraining + NumberValidation + NumberTest) * 128 * 128 * 2, dtype = np.float32).reshape((NumberTraining + NumberValidation + NumberTest), 2, 128, 128)\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(All_Paths)):\n",
    "        All_Images[i][0] = np.load(All_Paths[i][0]).astype(np.float32)\n",
    "        All_Images[i][1] = np.load(All_Paths[i][1]).astype(np.float32)\n",
    "    return(All_Images, All_Paths)\n",
    "    \n",
    "def CompareAllImages(All_Images, RMS_crit): #Comparison done by a root mean square\n",
    "    NumberImages = len(All_Images)\n",
    "    LossPairs = np.zeros(NumberImages * NumberImages, dtype = np.float32).reshape(NumberImages, NumberImages)\n",
    "    \n",
    "    for i in range(0, NumberImages):\n",
    "        for j in range(0, NumberImages):\n",
    "            if(i < j):\n",
    "                LossPairs[i][j] = RootMeanSquare(All_Images[i][0], All_Images[j][0])\n",
    "                LossPairs[j][i] = LossPairs[i][j]\n",
    "            \n",
    "    KeepCrystals = np.ones(NumberImages, dtype = np.int).reshape(NumberImages)\n",
    "    for i in range(0, NumberImages):\n",
    "        for j in range(0, NumberImages):\n",
    "            if(i < j && KeepCrystals[j] == 1 && LossPairs[i][j] < RMS_crit):\n",
    "                KeepCrystals[j] = 0\n",
    "    \n",
    "    NumberCrystalsToKeep = 0\n",
    "    for i in KeepCrystals:\n",
    "        if(i == 1):\n",
    "            NumberCrystalsToKeep+=1 \n",
    "        \n",
    "    \n",
    "    return(KeepCrystals, NumberCrystalsToKeep)\n",
    "\n",
    "\n",
    "def ShuffleIndexCreator(NumberCrystalsToUse):\n",
    "    rng = np.random.default_rng()\n",
    "    ShuffleIndex = np.arange(NumberCrystalsToUse, dtype = np.int)\n",
    "    rng.shuffle(ShuffleIndex)\n",
    "    return(ShuffleIndex)\n",
    "\n",
    "\n",
    "\n",
    "def CreateNewDataPaths(ShuffleIndex, All_Paths, KeepCrystals, RatioInSets, NumberCrystalsToKeep):\n",
    "    NewNumberTraining = int(NumberCrystalsToKeep * RatioInSets[0])\n",
    "    NewNumberValidation = int(NumberCrystalsToKeep * RatioInSets[1])\n",
    "    NewNumberTest = NumberCrystalsToKeep - NewNumberValidation - NewNumberTraining\n",
    "    \n",
    "    NewTrainingPathsInput = []\n",
    "    NewValidationPathsInput = []\n",
    "    NewTestPathsInput = []\n",
    "    \n",
    "    NewTrainingPathsOutput = []\n",
    "    NewValidationPathsOutput = []\n",
    "    NewTestPathsOutput = []\n",
    "    \n",
    "    index_i = 0\n",
    "    for i in range(0, KeepCrystals):\n",
    "        if(KeepCrystals[i] == 1):\n",
    "            if(ShuffleIndex[index_i_use] < NewNumberTraining):\n",
    "                NewTrainingPathsInput.append(All_Paths[i][0])\n",
    "                NewTrainingPathsOutput.append(All_Paths[i][1])\n",
    "                \n",
    "            elif(ShuffleIndex[index_i_use] < NewNumberTraining + NewNumberValidation):\n",
    "                NewValidationPathsInput.append(All_Paths[i][0])\n",
    "                NewValidationPathsOutput.append(All_Paths[i][1])\n",
    "                \n",
    "            else:\n",
    "                NewTestPathsInput.append(All_Paths[i][0])\n",
    "                NewTestPathsOutput.append(All_Paths[i][1])\n",
    "        index_i+=1\n",
    "    TrainingPaths = [NewTrainingPathsInput, NewTrainingPathsOutput]\n",
    "    ValidationPaths = [NewValidationPathsInput, NewValidationPathsOutput]\n",
    "    TestPaths = [NewTestPathsInput, NewTestPathsOutput]\n",
    "    \n",
    "    NumberInSet = [NewNumberTraining, NewNumberValidation, NewNumberTest]\n",
    "    \n",
    "    return(TrainingPaths, ValidationPaths, TestPaths, NumberInSet)\n",
    "\n",
    "\n",
    "\n",
    "def LoadNewImages(TrainingPaths, ValidationPaths, TestPaths, NumberInSet):\n",
    "\n",
    "    #TrainingPaths = [[All training inputs], [All training outputs]]\n",
    "    \n",
    "    NewTrainingImages = np.zeros(NumberInSet[0] * 128 * 128 * 2, dtype = np.float32).reshape(NumberInSet[0], 2, 128, 128)\n",
    "    NewValidationImages = np.zeros(NumberInSet[1] * 128 * 128 * 2, dtype = np.float32).reshape(NumberInSet[1], 2, 128, 128)\n",
    "    NewTestImages = np.zeros(NumberInSet[2] * 128 * 128 * 2, dtype = np.float32).reshape(NumberInSet[2], 2, 128, 128)\n",
    "    \n",
    "    \n",
    "    for i in range(0, NumberInSet[0]):\n",
    "        NewTrainingImages[i][0] = np.load(TrainingPaths[0][i]).astype(np.float32)\n",
    "        NewTrainingImages[i][1] = np.load(TrainingPaths[1][i]).astype(np.float32)\n",
    "        \n",
    "    for i in range(0, NumberInSet[1]):\n",
    "        NewValidationImages[i][0] = np.load(ValidationPaths[0][i]).astype(np.float32)\n",
    "        NewValidationImages[i][1] = np.load(ValidationPaths[1][i]).astype(np.float32)\n",
    "    \n",
    "    for i in range(0, NumberInSet[2]):\n",
    "        NewTestImages[i][0] = np.load(TestPaths[0][i]).astype(np.float32)\n",
    "        NewTestImages[i][1] = np.load(TestPaths[1][i]).astype(np.float32)\n",
    "    \n",
    "    AllNewImages = [NewTrainingImages, NewValidationImages, NewTestImages]\n",
    "    return(AllNewImages)\n",
    "\n",
    "\n",
    "def PairInputImages(All_Images): #Comparison done by a root mean square\n",
    "    #with All_Images = [Train_Images, Validation_Images, Test_Images]\n",
    "    DataSetSize = [len(All_Images[0]), len(All_Images[1]), len(All_Images[2])]\n",
    "    TrainValidationPairs = np.zeros(DataSetSize[0] * DataSetSize[1], dtype = np.float32).reshape(DataSetSize[0], DataSetSize[1])\n",
    "    TrainTestPairs = np.zeros(DataSetSize[0] * DataSetSize[2], dtype = np.float32).reshape(DataSetSize[0], DataSetSize[2])\n",
    "    \n",
    "    for i in range(0, DataSetSize[0]):\n",
    "        print(\"1: \", i)\n",
    "        for j in range(0, DataSetSize[1]):\n",
    "            TrainValidationPairs[i][j] = RootMeanSquare(All_Images[0][i][0], All_Images[1][j][0])\n",
    "            \n",
    "    for i in range(0, DataSetSize[0]):\n",
    "        print(\"2: \", i)\n",
    "        for j in range(0, DataSetSize[2]):\n",
    "            TrainTestPairs[i][j] = RootMeanSquare(All_Images[0][i][0], All_Images[2][j][0])\n",
    "    \n",
    "    BestPairTrainValidation = np.zeros(DataSetSize[1], dtype = np.int)\n",
    "    BestPairTrainTest = np.zeros(DataSetSize[2], dtype = np.int)\n",
    "    \n",
    "    for i in range(0, DataSetSize[1]):\n",
    "        print(\"3: \", i)\n",
    "        min_val = np.inf\n",
    "        for j in range(0, DataSetSize[0]):\n",
    "            if(TrainValidationPairs[j][i] < min_val):\n",
    "                BestPairTrainValidation[i] = j\n",
    "                min_val = TrainValidationPairs[j][i]\n",
    "                \n",
    "    for i in range(0, DataSetSize[2]):\n",
    "        print(\"4: \", i)\n",
    "        min_val = np.inf\n",
    "        for j in range(0, DataSetSize[0]):\n",
    "            if(TrainTestPairs[j][i] < min_val):\n",
    "                BestPairTrainTest[i] = j\n",
    "                min_val = TrainTestPairs[j][i]\n",
    "    return(BestPairTrainValidation, BestPairTrainTest)\n",
    "\n",
    "\n",
    "def BestPairLoss(All_Images, BestPairTrainValidation, BestPairTrainTest):\n",
    "    Val_Loss_Sum = 0\n",
    "    Test_Loss_Sum = 0\n",
    "    for i in range(0, len(BestPairTrainValidation)):\n",
    "        Val_Loss_Sum+=MeanSquareLogError(All_Images[1][i][1], All_Images[0][BestPairTrainValidation[i]][1])\n",
    "        print(\"1: \", i)\n",
    "    for i in range(0, len(BestPairTrainTest)):\n",
    "        Test_Loss_Sum+=MeanSquareLogError(All_Images[2][i][1], All_Images[0][BestPairTrainTest[i]][1])\n",
    "        print(\"2: \", i)\n",
    "    Val_Loss = Val_Loss_Sum / len(BestPairTrainValidation)\n",
    "    Test_Loss = Test_Loss_Sum / len(BestPairTrainTest)\n",
    "    return(Val_Loss, Test_Loss)\n",
    "\n",
    "\n",
    "    \n",
    "def RootMeanSquare(Image_1, Image_2): #Shape N by N\n",
    "    rms = (np.sum(np.square(Image_1 - Image_2)) / (128 * 128)) ** 0.5\n",
    "    return(rms)\n",
    "\n",
    "#MSLE = tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "def MeanSquareLogError(Image_1, Image_2):\n",
    "    msle = 0\n",
    "    for i in range(0, len(Image_1)):\n",
    "        for j in range(0, len(Image_1[i])):\n",
    "            msle+=(math.log(1+Image_1[i][j]) - math.log(1+Image_2[i][j])) ** 2\n",
    "    return(msle)\n",
    "\n",
    "\n",
    "    \n",
    "def WritePaths(Paths, File):\n",
    "    for i in Paths:\n",
    "        File.write(i + \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Original images\n",
    "All_Images, All_Paths = LoadImages(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check which input images have a value smaller loss than RMS_crit\n",
    "RMS_crit = 1\n",
    "KeepCrystals, NumberCrystalsToKeep = CompareAllImages(All_Images, RMS_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crystals have been removed from orginal data, need to organise them back randomly into training, val and testing\n",
    "ShuffleIndex = ShuffleIndexCreator(NumberCrystalsToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New paths have been put into training, val and test\n",
    "RatioInSets = [0.85, 0.1, 0.05]\n",
    "NewTrainingPaths, NewValidationPaths, NewTestPaths, NumberInSet = CreateNewDataPaths(ShuffleIndex, All_Paths, KeepCrystals, RatioInSets, NumberCrystalsToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewPath = \"/home/ug-ml/felix-ML/VAE_000/Data/FilePaths\"\n",
    "Name = \"1\"\n",
    "\n",
    "TrainingFileInput  = open(NewPath +\"/TrainingInput_\" + Name + \".txt\", \"w\")\n",
    "ValidationFileInput  = open(NewPath +\"/ValidationInput_\" + Name + \".txt\", \"w\")\n",
    "TestFileInput  = open(NewPath +\"/TestInput_\" + Name + \".txt\", \"w\")\n",
    "\n",
    "TrainingFileOutput  = open(NewPath +\"/TrainingOutput_\" + Name + \".txt\", \"w\")\n",
    "ValidationFileOutput  = open(NewPath +\"/ValidationOutput_\" + Name + \".txt\", \"w\")\n",
    "TestFileOutput  = open(NewPath +\"/TestOutput_\" + Name + \".txt\", \"w\")\n",
    "\n",
    "WritePaths(NewTrainingPaths[0], TrainingFileInput)\n",
    "WritePaths(NewValidationPaths[0], ValidationFileInput)\n",
    "WritePaths(NewTestPaths[0], TestFileInput)\n",
    "\n",
    "WritePaths(NewTrainingPaths[1], TrainingFileOutput)\n",
    "WritePaths(NewValidationPaths[1], ValidationFileOutput)\n",
    "WritePaths(NewTestPaths[1], TestFileOutput)\n",
    "\n",
    "TrainingFileInput.close()\n",
    "ValidationFileInput.close()\n",
    "TestFileInput.close()\n",
    "\n",
    "TrainingFileOutput.close()\n",
    "ValidationFileOutput.close()\n",
    "TestFileOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load new images from the new paths created\n",
    "AllNewImages = LoadNewImages(NewTrainingPaths, NewValidationPaths, NewTestPaths, NumberInSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match up the best matching pairs of crystal unit cell in training to validation and training to test data\n",
    "BestPairTrainValidation, BestPairTrainTest = PairInputImages(AllNewImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the best matching pairs, how good do the LACBED images compare with using log loss function\n",
    "Val_Loss, Test_Loss = BestPairLoss(AllNewImages, BestPairTrainValidation, BestPairTrainTest)\n",
    "print(\"Validation loss: \", Val_Loss)\n",
    "print(\"Test loss: \", Test_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average log loss\n",
    "RMS_crit = 50\n",
    "\n",
    "Ave_loss = 0\n",
    "Ave_min_loss = 0\n",
    "number = 0\n",
    "for i in range(0, All_RMS_Values.shape[0]):\n",
    "    for j in All_RMS_Values[i]:\n",
    "        if(j > RMS_crit):\n",
    "            min_loss = j\n",
    "            break\n",
    "\n",
    "    for j in range(0, All_RMS_Values.shape[1]):\n",
    "        if(All_RMS_Values[i][j] >= RMS_crit):\n",
    "            Ave_loss+=All_RMS_Values[i][j]\n",
    "            number+=1\n",
    "            if(All_RMS_Values[i][j] < min_loss):\n",
    "                min_loss = All_RMS_Values[i][j]\n",
    "    Ave_min_loss+=min_loss\n",
    "    print(i)\n",
    "print(\"Average loss: \", Ave_loss / number)\n",
    "print(\"Average min loss: \", Ave_min_loss / All_RMS_Values.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KeepCrystals = WhichCrystalsToUse(All_RMS_Values, RMS_crit)\n",
    "\n",
    "NumberCrystalsToUse = 0\n",
    "for i in KeepCrystals:\n",
    "    if(i == 1):\n",
    "        NumberCrystalsToUse+=1\n",
    "print(NumberCrystalsToUse, len(KeepCrystals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingRatio = 0.85\n",
    "ValidationRatio = 0.1\n",
    "TestRatio = 1 - TrainingRatio - ValidationRatio\n",
    "\n",
    "TrainingNumber = int(TrainingRatio * NumberCrystalsToUse)\n",
    "ValidationNumber = int(ValidationRatio * NumberCrystalsToUse)\n",
    "TestNumber = NumberCrystalsToUse - TrainingNumber - ValidationNumber\n",
    "NumberInSet = [TrainingNumber, ValidationNumber, TestNumber]\n",
    "\n",
    "ShuffleIndex = ShuffleIndexCreator(NumberCrystalsToUse)\n",
    "\n",
    "TrainingPaths, ValidationPaths, TestPaths = CreateNewDataPaths(ShuffleIndex, KeepCrystals, ReIndexCrystals, NumberInSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewPath = \"/home/ug-ml/felix-ML/VAE_000/Data/FilePaths\"\n",
    "Name = \"50\"\n",
    "\n",
    "TrainingFile  = open(NewPath +\"/Training_\" + Name + \".txt\", \"w\")\n",
    "ValidationFile  = open(NewPath +\"/Validation_\" + Name + \".txt\", \"w\")\n",
    "TestFile  = open(NewPath +\"/Test_\" + Name + \".txt\", \"w\")\n",
    "\n",
    "WritePaths(TrainingPaths, TrainingFile)\n",
    "WritePaths(ValidationPaths, ValidationFile)\n",
    "WritePaths(TestPaths, TestFile)\n",
    "\n",
    "TrainingFile.close()\n",
    "ValidationFile.close()\n",
    "TestFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check(TrainingPaths, ValidationPaths, TestPaths):\n",
    "    AllPaths = []\n",
    "    for i in TrainingPaths:\n",
    "        AllPaths.append(i)\n",
    "    for i in ValidationPaths:\n",
    "        AllPaths.append(i)\n",
    "    for i in TestPaths:\n",
    "        AllPaths.append(i)\n",
    "    for i in range(0, len(AllPaths)):\n",
    "        for j in range(0, len(AllPaths)):\n",
    "            if(j < i):\n",
    "                Image_1 = np.load(AllPaths[i])\n",
    "                Image_2 = np.load(AllPaths[j])\n",
    "                rms = RootMeanSquare(Image_1, Image_2)\n",
    "                if(rms < RMS_crit):\n",
    "                    print(AllPaths[i], AllPaths[j])\n",
    "Check(TrainingPaths, ValidationPaths, TestPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss = 0\n",
    "#data[0][0], data[0][1]\n",
    "Rms_losses = []\n",
    "reconstruction_losses = []\n",
    "\n",
    "for i in range(0, len(AllNewImages[2])):\n",
    "    x = AllNewImages[2][i][0]\n",
    "    y = AllNewImages[2][i][1]\n",
    "    #x = np.load(data[0][i])\n",
    "    #y = np.load(data[1][i])\n",
    "    a = AllNewImages[0][BestPairTrainTest[i]][1]\n",
    "    b = AllNewImages[0][BestPairTrainTest[i]][0]\n",
    "    Input_RMS = MeanSquareLogError(x, b)\n",
    "    Rms_losses.append(Input_RMS)\n",
    "    #print(i)\n",
    "    log_loss = 0\n",
    "    for j in range(0, a.shape[0]):\n",
    "        for k in range(0, a.shape[1]):\n",
    "            log_loss+=(math.log(1+a[j][k]) - math.log(1+y[j][k])) ** 2\n",
    "    reconstruction_losses.append(log_loss)\n",
    "    average_loss+=log_loss\n",
    "    if Input_RMS < 50:\n",
    "        print(i)\n",
    "        print(\"Log loss is: \", log_loss)\n",
    "        print(\"Input RMS is: \", Input_RMS)\n",
    "        w=10\n",
    "        h=10\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        columns = 4\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(x)\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(y)\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(a)\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "        plt.imshow(b)\n",
    "        plt.show()\n",
    "print(\"Average loss: \", average_loss / len(AllNewImages[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
