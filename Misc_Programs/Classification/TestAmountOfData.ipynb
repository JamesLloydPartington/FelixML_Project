{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the data and convert the data into something the NN can read\n",
    "#echo 1 | sudo tee /proc/sys/vm/overcommit_memory\n",
    "#export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "Path = \"Quarter32Bit\"\n",
    "\n",
    "AllData = np.load(Path + \"/ImageDataNorm.npy\")\n",
    "AllLabel = np.load(Path + \"/ImageLab.npy\")\n",
    "\n",
    "No_Crystals = AllData.shape[0]\n",
    "Total_ints = AllData.shape[0] * AllData.shape[1] * AllData.shape[2] * AllData.shape[3] \n",
    "\n",
    "Shuffle_Index = np.arange(No_Crystals)\n",
    "np.random.shuffle(Shuffle_Index)\n",
    "\n",
    "###########\n",
    "TrainRatio = 0.9\n",
    "ValidationRatio = 0.1 ## A fraction of the Traning data\n",
    "\n",
    "###########\n",
    "\n",
    "TrainCrystalNo = round(TrainRatio * No_Crystals)\n",
    "ValCrystalNo = round(ValidationRatio * No_Crystals)\n",
    "PixleNo = AllData.shape[2] * AllData.shape[3]\n",
    "\n",
    "train_images = np.zeros(TrainCrystalNo * PixleNo * AllData.shape[1], dtype = np.float32).reshape(TrainCrystalNo, AllData.shape[1], AllData.shape[2], AllData.shape[3])\n",
    "val_images = np.zeros(ValCrystalNo * PixleNo * AllData.shape[1], dtype = np.float32).reshape(ValCrystalNo, AllData.shape[1], AllData.shape[2], AllData.shape[3])\n",
    "\n",
    "train_lab = np.zeros(TrainCrystalNo * AllData.shape[1], dtype = np.uint8).reshape(TrainCrystalNo, AllData.shape[1])\n",
    "val_lab = np.zeros(ValCrystalNo * AllData.shape[1], dtype = np.uint8).reshape(ValCrystalNo, AllData.shape[1])\n",
    "\n",
    "for i in range(0, No_Crystals): #Put Shuffled Crystals into training and validation and test\n",
    "\tif(i < TrainCrystalNo):\n",
    "\t\ttrain_images[i] = AllData[Shuffle_Index[i]]\n",
    "\t\ttrain_lab[i] = AllLabel[Shuffle_Index[i]]\n",
    "\n",
    "\telse:\n",
    "\t\tval_images[i - TrainCrystalNo] = AllData[Shuffle_Index[i]]\n",
    "\t\tval_lab[i - TrainCrystalNo] = AllLabel[Shuffle_Index[i]]\n",
    "\n",
    "Shuffle_Index_Train = np.arange(TrainCrystalNo * AllData.shape[1])\n",
    "Shuffle_Index_Val = np.arange(ValCrystalNo * AllData.shape[1])\n",
    "\n",
    "np.random.shuffle(Shuffle_Index_Train)\n",
    "np.random.shuffle(Shuffle_Index_Val)\n",
    "\n",
    "train_images = train_images.reshape(-1, AllData.shape[2], AllData.shape[3], 1)\n",
    "val_images = val_images.reshape(-1, AllData.shape[2], AllData.shape[3], 1)\n",
    "train_lab = train_lab.reshape(-1)\n",
    "val_lab = val_lab.reshape(-1)\n",
    "\n",
    "train_images_copy = train_images\n",
    "val_images_copy = val_images\n",
    "train_lab_copy = train_lab\n",
    "val_lab_copy = val_lab\n",
    "\n",
    "\n",
    "for i in range(0,TrainCrystalNo * AllData.shape[1]):\n",
    "\ttrain_images_copy[i] = train_images[Shuffle_Index_Train[i]]\n",
    "\ttrain_lab_copy[i] = train_lab[Shuffle_Index_Train[i]]\n",
    "for i in range(0,ValCrystalNo * AllData.shape[1]):\n",
    "\tval_images_copy[i] = val_images[Shuffle_Index_Val[i]]\n",
    "\tval_lab_copy[i] = val_lab[Shuffle_Index_Val[i]]\n",
    "\n",
    "train_images = train_images_copy.astype(\"float32\")\n",
    "val_images = val_images_copy.astype(\"float32\")\n",
    "train_lab = train_lab_copy\n",
    "val_lab = val_lab_copy\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_lab = to_categorical(train_lab)\n",
    "val_lab = to_categorical(val_lab)\n",
    "\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images (58570, 64, 64, 1)\n",
      "val_images (6510, 64, 64, 1)\n",
      "train_lab (58570, 10)\n",
      "val_lab (6510, 10)\n"
     ]
    }
   ],
   "source": [
    "#Print out the shapes of the image and label arrays\n",
    "print(\"train_images\",train_images.shape)\n",
    "print(\"val_images\",val_images.shape)\n",
    "\n",
    "print(\"train_lab\",train_lab.shape)\n",
    "print(\"val_lab\",val_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a convolutional NN and show the model\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "#from keras.models import load_model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\" \n",
    "\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(512, activation='relu', kernel_regularizer = l2(0.0001)))\n",
    "    model.add(layers.Dense(10, activation='softmax', kernel_regularizer = l2(0.0001)))\n",
    "    return(model)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 292, 585, 2928, 5857, 11714, 23428, 35142, 46856, 52713, 58570]\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3968 - acc: 0.0000e+00 - val_loss: 2.3793 - val_acc: 0.1014\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3072 - acc: 0.6000 - val_loss: 2.4067 - val_acc: 0.1014\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9672 - acc: 0.6000 - val_loss: 2.7176 - val_acc: 0.1014\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4600 - acc: 0.6000 - val_loss: 3.6670 - val_acc: 0.1014\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1572 - acc: 0.6000 - val_loss: 4.0710 - val_acc: 0.1014\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0836 - acc: 0.6000 - val_loss: 4.4911 - val_acc: 0.1014\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0352 - acc: 0.6000 - val_loss: 5.0763 - val_acc: 0.1014\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0171 - acc: 0.6000 - val_loss: 5.4345 - val_acc: 0.1014\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9968 - acc: 0.6000 - val_loss: 6.0314 - val_acc: 0.1014\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9941 - acc: 0.6000 - val_loss: 6.0417 - val_acc: 0.1012\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9894 - acc: 0.6000 - val_loss: 7.2290 - val_acc: 0.1014\n",
      "Epoch 00011: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 7.2290 - acc: 0.1014\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 2.3589 - acc: 0.0993 - val_loss: 2.3423 - val_acc: 0.1108\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 2.3074 - acc: 0.1747 - val_loss: 2.2781 - val_acc: 0.1114\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 2.2180 - acc: 0.1952 - val_loss: 2.2251 - val_acc: 0.1928\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 2.1274 - acc: 0.2432 - val_loss: 2.1682 - val_acc: 0.1948\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 2.0771 - acc: 0.2466 - val_loss: 2.1494 - val_acc: 0.1966\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.0176 - acc: 0.2397 - val_loss: 2.2582 - val_acc: 0.1743\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.0123 - acc: 0.2466 - val_loss: 2.0861 - val_acc: 0.2006\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 1.9741 - acc: 0.2397 - val_loss: 2.0777 - val_acc: 0.1965\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.9664 - acc: 0.2500 - val_loss: 2.1206 - val_acc: 0.1991\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 1.9759 - acc: 0.2397 - val_loss: 2.0966 - val_acc: 0.2147\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 1.9379 - acc: 0.2500 - val_loss: 2.0812 - val_acc: 0.2012\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 1.9364 - acc: 0.2534 - val_loss: 2.1049 - val_acc: 0.2186\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 1.9124 - acc: 0.2432 - val_loss: 2.1342 - val_acc: 0.2040\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 1.9132 - acc: 0.2705 - val_loss: 2.0720 - val_acc: 0.2037\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 1.8909 - acc: 0.2568 - val_loss: 2.1008 - val_acc: 0.2089\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 1.8921 - acc: 0.2808 - val_loss: 2.0660 - val_acc: 0.2210\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 1.8561 - acc: 0.2808 - val_loss: 2.1114 - val_acc: 0.2358\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 1.8529 - acc: 0.2945 - val_loss: 2.0541 - val_acc: 0.2349\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.8046 - acc: 0.2808 - val_loss: 2.2246 - val_acc: 0.2026\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 1.8280 - acc: 0.2911 - val_loss: 2.0966 - val_acc: 0.2618\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 1.7963 - acc: 0.3048 - val_loss: 2.1883 - val_acc: 0.2429\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 1.7720 - acc: 0.2842 - val_loss: 2.2857 - val_acc: 0.2315\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 1.7804 - acc: 0.2842 - val_loss: 2.4989 - val_acc: 0.1897\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 1.8206 - acc: 0.3219 - val_loss: 2.0687 - val_acc: 0.2432\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 1.7243 - acc: 0.3527 - val_loss: 2.1514 - val_acc: 0.2453\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 1.7289 - acc: 0.3288 - val_loss: 2.2584 - val_acc: 0.2596\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 1.6819 - acc: 0.3459 - val_loss: 2.2442 - val_acc: 0.2399\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 1.7279 - acc: 0.3493 - val_loss: 2.3928 - val_acc: 0.2493\n",
      "Epoch 00028: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 2.3928 - acc: 0.2493\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 2s 91ms/step - loss: 2.3487 - acc: 0.0906 - val_loss: 2.3209 - val_acc: 0.1005\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 2.3131 - acc: 0.1248 - val_loss: 2.3106 - val_acc: 0.1005\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 2s 82ms/step - loss: 2.3038 - acc: 0.1265 - val_loss: 2.3048 - val_acc: 0.1005\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 2.2754 - acc: 0.1265 - val_loss: 2.2724 - val_acc: 0.0960\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 2.1966 - acc: 0.1983 - val_loss: 2.3048 - val_acc: 0.1942\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 2.0862 - acc: 0.2000 - val_loss: 2.0131 - val_acc: 0.2425\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.9719 - acc: 0.2427 - val_loss: 1.9695 - val_acc: 0.2550\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.9352 - acc: 0.2376 - val_loss: 1.9591 - val_acc: 0.2482\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.9234 - acc: 0.2598 - val_loss: 1.9526 - val_acc: 0.2367\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 1.9051 - acc: 0.2718 - val_loss: 1.9156 - val_acc: 0.2733\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 1.9053 - acc: 0.2564 - val_loss: 2.0623 - val_acc: 0.2112\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.9105 - acc: 0.2598 - val_loss: 1.8997 - val_acc: 0.2671\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 1.9181 - acc: 0.2444 - val_loss: 1.9273 - val_acc: 0.2381\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 1.8630 - acc: 0.2821 - val_loss: 1.9085 - val_acc: 0.2713\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.8808 - acc: 0.2615 - val_loss: 1.9362 - val_acc: 0.2347\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 1.8975 - acc: 0.2650 - val_loss: 1.8890 - val_acc: 0.2593\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.8522 - acc: 0.2889 - val_loss: 1.9690 - val_acc: 0.2421\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 1.8537 - acc: 0.2752 - val_loss: 1.8796 - val_acc: 0.2725\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 1.8242 - acc: 0.2923 - val_loss: 1.8602 - val_acc: 0.2853\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 75ms/step - loss: 1.8315 - acc: 0.3128 - val_loss: 1.9689 - val_acc: 0.2422\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 1.8138 - acc: 0.3060 - val_loss: 1.8373 - val_acc: 0.2737\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 78ms/step - loss: 1.8204 - acc: 0.3009 - val_loss: 1.8381 - val_acc: 0.2857\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 76ms/step - loss: 1.7948 - acc: 0.3077 - val_loss: 1.9554 - val_acc: 0.2628\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 1.7910 - acc: 0.3299 - val_loss: 1.8523 - val_acc: 0.2800\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.7800 - acc: 0.3094 - val_loss: 1.8605 - val_acc: 0.2879\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.8029 - acc: 0.3060 - val_loss: 1.8836 - val_acc: 0.2820\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 73ms/step - loss: 1.7624 - acc: 0.3385 - val_loss: 1.9320 - val_acc: 0.2805\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 1.7464 - acc: 0.3470 - val_loss: 1.9200 - val_acc: 0.2607\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 1.7658 - acc: 0.3026 - val_loss: 1.9152 - val_acc: 0.2773\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.7556 - acc: 0.3385 - val_loss: 1.8532 - val_acc: 0.2969\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 1.7218 - acc: 0.3368 - val_loss: 1.8235 - val_acc: 0.2983\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.7196 - acc: 0.3453 - val_loss: 2.0563 - val_acc: 0.2290\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 1.7075 - acc: 0.3487 - val_loss: 1.8729 - val_acc: 0.2962\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.7092 - acc: 0.3436 - val_loss: 1.8349 - val_acc: 0.3155\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 2s 79ms/step - loss: 1.6751 - acc: 0.3726 - val_loss: 1.9033 - val_acc: 0.2856\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 77ms/step - loss: 1.6539 - acc: 0.3932 - val_loss: 1.8909 - val_acc: 0.2968\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 79ms/step - loss: 1.6619 - acc: 0.3829 - val_loss: 1.9831 - val_acc: 0.2717\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.6635 - acc: 0.3795 - val_loss: 1.8392 - val_acc: 0.3164\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 78ms/step - loss: 1.6196 - acc: 0.4051 - val_loss: 1.9347 - val_acc: 0.2788\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 2s 80ms/step - loss: 1.6077 - acc: 0.3966 - val_loss: 1.9187 - val_acc: 0.2820\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 2s 81ms/step - loss: 1.5783 - acc: 0.4000 - val_loss: 2.0220 - val_acc: 0.3011\n",
      "Epoch 00041: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 2.0220 - acc: 0.3011\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 2.1249 - acc: 0.1844 - val_loss: 2.0247 - val_acc: 0.2280\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.9641 - acc: 0.2538 - val_loss: 1.9070 - val_acc: 0.2531\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.9069 - acc: 0.2729 - val_loss: 1.8625 - val_acc: 0.2856\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.8624 - acc: 0.2917 - val_loss: 1.8042 - val_acc: 0.3189\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.8116 - acc: 0.3152 - val_loss: 1.8152 - val_acc: 0.3098\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.7754 - acc: 0.3364 - val_loss: 1.7724 - val_acc: 0.3103\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.7442 - acc: 0.3460 - val_loss: 1.8280 - val_acc: 0.3177\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.7072 - acc: 0.3692 - val_loss: 1.7721 - val_acc: 0.3240\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.6733 - acc: 0.3832 - val_loss: 1.7652 - val_acc: 0.3267\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.6396 - acc: 0.4074 - val_loss: 1.7500 - val_acc: 0.3525\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.6064 - acc: 0.4115 - val_loss: 1.7560 - val_acc: 0.3521\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.5558 - acc: 0.4375 - val_loss: 1.8249 - val_acc: 0.3488\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.5042 - acc: 0.4648 - val_loss: 1.8615 - val_acc: 0.3425\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 1.4640 - acc: 0.4898 - val_loss: 1.8180 - val_acc: 0.3570\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.4038 - acc: 0.5215 - val_loss: 1.9675 - val_acc: 0.3610\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.3278 - acc: 0.5492 - val_loss: 2.0629 - val_acc: 0.3349\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.2758 - acc: 0.5666 - val_loss: 2.0979 - val_acc: 0.3719\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 1.2008 - acc: 0.6008 - val_loss: 2.0309 - val_acc: 0.3840\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.1292 - acc: 0.6284 - val_loss: 2.1731 - val_acc: 0.3700\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.0396 - acc: 0.6718 - val_loss: 2.5470 - val_acc: 0.3757\n",
      "Epoch 00020: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 2.5470 - acc: 0.3757\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 2.0671 - acc: 0.2158 - val_loss: 2.1642 - val_acc: 0.2083\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.9102 - acc: 0.2713 - val_loss: 1.8431 - val_acc: 0.3066\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.8268 - acc: 0.3008 - val_loss: 1.8645 - val_acc: 0.2767\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.7672 - acc: 0.3249 - val_loss: 1.8080 - val_acc: 0.3120\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.7364 - acc: 0.3415 - val_loss: 1.8032 - val_acc: 0.3181\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.7080 - acc: 0.3550 - val_loss: 1.7258 - val_acc: 0.3312\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.6875 - acc: 0.3683 - val_loss: 1.7672 - val_acc: 0.3249\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.6522 - acc: 0.3879 - val_loss: 1.7592 - val_acc: 0.3287\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.6254 - acc: 0.4070 - val_loss: 1.7246 - val_acc: 0.3396\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.5936 - acc: 0.4156 - val_loss: 1.6723 - val_acc: 0.3645\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.5444 - acc: 0.4454 - val_loss: 1.7610 - val_acc: 0.3699\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.4980 - acc: 0.4654 - val_loss: 1.6824 - val_acc: 0.3943\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.4355 - acc: 0.4938 - val_loss: 1.7620 - val_acc: 0.3889\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.3676 - acc: 0.5265 - val_loss: 1.7529 - val_acc: 0.3971\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.2996 - acc: 0.5629 - val_loss: 1.9032 - val_acc: 0.3931\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.2205 - acc: 0.5878 - val_loss: 1.8025 - val_acc: 0.4272\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.1519 - acc: 0.6211 - val_loss: 1.9693 - val_acc: 0.4190\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.0786 - acc: 0.6503 - val_loss: 1.8403 - val_acc: 0.4613\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 1.0021 - acc: 0.6783 - val_loss: 2.1225 - val_acc: 0.4292\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.9307 - acc: 0.7159 - val_loss: 2.1961 - val_acc: 0.4518\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 1s 6ms/step - loss: 2.1961 - acc: 0.4518\n",
      "Epoch 1/50\n",
      "367/367 [==============================] - 7s 19ms/step - loss: 2.0094 - acc: 0.2290 - val_loss: 1.8696 - val_acc: 0.2759\n",
      "Epoch 2/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.8528 - acc: 0.2826 - val_loss: 2.1888 - val_acc: 0.2366\n",
      "Epoch 3/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.7600 - acc: 0.3206 - val_loss: 1.7671 - val_acc: 0.3344\n",
      "Epoch 4/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.6927 - acc: 0.3477 - val_loss: 1.7324 - val_acc: 0.3487\n",
      "Epoch 5/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.6442 - acc: 0.3780 - val_loss: 1.6974 - val_acc: 0.3478\n",
      "Epoch 6/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.5908 - acc: 0.3980 - val_loss: 1.7863 - val_acc: 0.3143\n",
      "Epoch 7/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.5438 - acc: 0.4279 - val_loss: 1.6775 - val_acc: 0.3975\n",
      "Epoch 8/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.4859 - acc: 0.4573 - val_loss: 1.6186 - val_acc: 0.4147\n",
      "Epoch 9/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.4215 - acc: 0.4944 - val_loss: 1.6917 - val_acc: 0.4028\n",
      "Epoch 10/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.3587 - acc: 0.5313 - val_loss: 1.6144 - val_acc: 0.4502\n",
      "Epoch 11/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.2722 - acc: 0.5676 - val_loss: 1.6488 - val_acc: 0.4544\n",
      "Epoch 12/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.2086 - acc: 0.6000 - val_loss: 1.5841 - val_acc: 0.4816\n",
      "Epoch 13/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.1351 - acc: 0.6359 - val_loss: 1.6297 - val_acc: 0.4889\n",
      "Epoch 14/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.0588 - acc: 0.6640 - val_loss: 1.7717 - val_acc: 0.4903\n",
      "Epoch 15/50\n",
      "367/367 [==============================] - 6s 18ms/step - loss: 0.9957 - acc: 0.6998 - val_loss: 1.7607 - val_acc: 0.5063\n",
      "Epoch 16/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.9397 - acc: 0.7246 - val_loss: 1.9678 - val_acc: 0.4925\n",
      "Epoch 17/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.8933 - acc: 0.7521 - val_loss: 2.0087 - val_acc: 0.5095\n",
      "Epoch 18/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.8265 - acc: 0.7755 - val_loss: 2.0928 - val_acc: 0.5214\n",
      "Epoch 19/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.7845 - acc: 0.7883 - val_loss: 2.1714 - val_acc: 0.4974\n",
      "Epoch 20/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.7619 - acc: 0.8070 - val_loss: 2.2875 - val_acc: 0.5246\n",
      "Epoch 21/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.7331 - acc: 0.8244 - val_loss: 2.2179 - val_acc: 0.5361\n",
      "Epoch 22/50\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 0.6957 - acc: 0.8330 - val_loss: 2.2613 - val_acc: 0.5413\n",
      "Epoch 00022: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 2.2613 - acc: 0.5413\n",
      "Epoch 1/50\n",
      "733/733 [==============================] - 12s 17ms/step - loss: 1.9249 - acc: 0.2621 - val_loss: 1.9397 - val_acc: 0.2845\n",
      "Epoch 2/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.7540 - acc: 0.3254 - val_loss: 1.7205 - val_acc: 0.3336\n",
      "Epoch 3/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.6452 - acc: 0.3832 - val_loss: 1.9221 - val_acc: 0.3430\n",
      "Epoch 4/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.5630 - acc: 0.4242 - val_loss: 1.7456 - val_acc: 0.3886\n",
      "Epoch 5/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.4878 - acc: 0.4757 - val_loss: 1.6087 - val_acc: 0.4421\n",
      "Epoch 6/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.4136 - acc: 0.5134 - val_loss: 1.5713 - val_acc: 0.4601\n",
      "Epoch 7/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.3493 - acc: 0.5481 - val_loss: 1.6053 - val_acc: 0.4722\n",
      "Epoch 8/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.2873 - acc: 0.5861 - val_loss: 1.5894 - val_acc: 0.4978\n",
      "Epoch 9/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.2270 - acc: 0.6154 - val_loss: 1.6218 - val_acc: 0.5166\n",
      "Epoch 10/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.1714 - acc: 0.6453 - val_loss: 1.5920 - val_acc: 0.5267\n",
      "Epoch 11/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.1245 - acc: 0.6675 - val_loss: 1.5851 - val_acc: 0.5200\n",
      "Epoch 12/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.0869 - acc: 0.6896 - val_loss: 1.5993 - val_acc: 0.5352\n",
      "Epoch 13/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.0409 - acc: 0.7102 - val_loss: 1.6595 - val_acc: 0.5363\n",
      "Epoch 14/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 1.0118 - acc: 0.7229 - val_loss: 1.7448 - val_acc: 0.5192\n",
      "Epoch 15/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 0.9787 - acc: 0.7397 - val_loss: 1.7932 - val_acc: 0.5501\n",
      "Epoch 16/50\n",
      "733/733 [==============================] - 12s 16ms/step - loss: 0.9572 - acc: 0.7528 - val_loss: 1.8422 - val_acc: 0.5524\n",
      "Epoch 00016: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.8422 - acc: 0.5524\n",
      "Epoch 1/50\n",
      "1099/1099 [==============================] - 18s 17ms/step - loss: 1.8665 - acc: 0.2834 - val_loss: 1.7949 - val_acc: 0.3210\n",
      "Epoch 2/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.6541 - acc: 0.3706 - val_loss: 1.6337 - val_acc: 0.3896\n",
      "Epoch 3/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.5249 - acc: 0.4376 - val_loss: 1.5260 - val_acc: 0.4476\n",
      "Epoch 4/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.4116 - acc: 0.5008 - val_loss: 1.5212 - val_acc: 0.4607\n",
      "Epoch 5/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.3128 - acc: 0.5561 - val_loss: 1.4715 - val_acc: 0.5144\n",
      "Epoch 6/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.2241 - acc: 0.6078 - val_loss: 1.5694 - val_acc: 0.5126\n",
      "Epoch 7/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.1515 - acc: 0.6449 - val_loss: 1.4956 - val_acc: 0.5455\n",
      "Epoch 8/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.0832 - acc: 0.6788 - val_loss: 1.5953 - val_acc: 0.5550\n",
      "Epoch 9/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 1.0381 - acc: 0.7053 - val_loss: 1.5930 - val_acc: 0.5539\n",
      "Epoch 10/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 0.9880 - acc: 0.7312 - val_loss: 1.5491 - val_acc: 0.5783\n",
      "Epoch 11/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 0.9609 - acc: 0.7502 - val_loss: 1.6354 - val_acc: 0.5777\n",
      "Epoch 12/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 0.9207 - acc: 0.7657 - val_loss: 1.6565 - val_acc: 0.5659\n",
      "Epoch 13/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 0.9046 - acc: 0.7769 - val_loss: 1.6611 - val_acc: 0.5886\n",
      "Epoch 14/50\n",
      "1099/1099 [==============================] - 18s 16ms/step - loss: 0.8912 - acc: 0.7870 - val_loss: 1.6608 - val_acc: 0.5705\n",
      "Epoch 15/50\n",
      "1099/1099 [==============================] - 17s 16ms/step - loss: 0.8842 - acc: 0.7949 - val_loss: 1.7999 - val_acc: 0.5903\n",
      "Epoch 00015: early stopping\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 1.7999 - acc: 0.5903\n",
      "Epoch 1/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 1.7784 - acc: 0.3131 - val_loss: 1.6536 - val_acc: 0.3579\n",
      "Epoch 2/50\n",
      "1465/1465 [==============================] - 22s 15ms/step - loss: 1.5945 - acc: 0.3998 - val_loss: 1.5602 - val_acc: 0.4478\n",
      "Epoch 3/50\n",
      "1465/1465 [==============================] - 23s 15ms/step - loss: 1.4685 - acc: 0.4710 - val_loss: 1.5347 - val_acc: 0.4633\n",
      "Epoch 4/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 1.3597 - acc: 0.5322 - val_loss: 1.5026 - val_acc: 0.5054\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 23s 15ms/step - loss: 1.2701 - acc: 0.5830 - val_loss: 1.4939 - val_acc: 0.5178\n",
      "Epoch 6/50\n",
      "1465/1465 [==============================] - 23s 15ms/step - loss: 1.1978 - acc: 0.6234 - val_loss: 1.5361 - val_acc: 0.5490\n",
      "Epoch 7/50\n",
      "1465/1465 [==============================] - 22s 15ms/step - loss: 1.1375 - acc: 0.6572 - val_loss: 1.4890 - val_acc: 0.5551\n",
      "Epoch 8/50\n",
      "1465/1465 [==============================] - 23s 15ms/step - loss: 1.0924 - acc: 0.6856 - val_loss: 1.4867 - val_acc: 0.5614\n",
      "Epoch 9/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 1.0600 - acc: 0.7047 - val_loss: 1.5766 - val_acc: 0.5774\n",
      "Epoch 10/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 1.0338 - acc: 0.7198 - val_loss: 1.5871 - val_acc: 0.5705\n",
      "Epoch 11/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 1.0087 - acc: 0.7321 - val_loss: 1.5755 - val_acc: 0.5768\n",
      "Epoch 12/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 0.9884 - acc: 0.7455 - val_loss: 1.6447 - val_acc: 0.5671\n",
      "Epoch 13/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 0.9731 - acc: 0.7568 - val_loss: 1.5667 - val_acc: 0.5889\n",
      "Epoch 14/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 0.9521 - acc: 0.7662 - val_loss: 1.6396 - val_acc: 0.6089\n",
      "Epoch 15/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 0.9515 - acc: 0.7688 - val_loss: 1.7057 - val_acc: 0.5845\n",
      "Epoch 16/50\n",
      "1465/1465 [==============================] - 22s 15ms/step - loss: 0.9289 - acc: 0.7805 - val_loss: 1.7376 - val_acc: 0.5940\n",
      "Epoch 17/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 0.9209 - acc: 0.7850 - val_loss: 1.6434 - val_acc: 0.5931\n",
      "Epoch 18/50\n",
      "1465/1465 [==============================] - 23s 16ms/step - loss: 0.9134 - acc: 0.7897 - val_loss: 1.7033 - val_acc: 0.5891\n",
      "Epoch 00018: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.7033 - acc: 0.5891\n",
      "Epoch 1/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.7890 - acc: 0.3110 - val_loss: 1.6554 - val_acc: 0.3750\n",
      "Epoch 2/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.5749 - acc: 0.4157 - val_loss: 1.5334 - val_acc: 0.4455\n",
      "Epoch 3/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.4487 - acc: 0.4893 - val_loss: 1.5025 - val_acc: 0.4739\n",
      "Epoch 4/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.3465 - acc: 0.5456 - val_loss: 1.5427 - val_acc: 0.4848\n",
      "Epoch 5/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.2761 - acc: 0.5898 - val_loss: 1.4353 - val_acc: 0.5369\n",
      "Epoch 6/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.2234 - acc: 0.6215 - val_loss: 1.6391 - val_acc: 0.5089\n",
      "Epoch 7/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.1760 - acc: 0.6503 - val_loss: 1.5528 - val_acc: 0.5275\n",
      "Epoch 8/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.1397 - acc: 0.6714 - val_loss: 1.5002 - val_acc: 0.5611\n",
      "Epoch 9/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.1229 - acc: 0.6964 - val_loss: 1.4915 - val_acc: 0.5654\n",
      "Epoch 10/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.0762 - acc: 0.7109 - val_loss: 1.6270 - val_acc: 0.5739\n",
      "Epoch 11/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.0577 - acc: 0.7249 - val_loss: 1.6649 - val_acc: 0.5599\n",
      "Epoch 12/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.0299 - acc: 0.7341 - val_loss: 1.6903 - val_acc: 0.5768\n",
      "Epoch 13/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.0197 - acc: 0.7458 - val_loss: 1.7237 - val_acc: 0.5834\n",
      "Epoch 14/50\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.0026 - acc: 0.7538 - val_loss: 1.7288 - val_acc: 0.5713\n",
      "Epoch 15/50\n",
      "1648/1648 [==============================] - 27s 16ms/step - loss: 1.0038 - acc: 0.7619 - val_loss: 1.7965 - val_acc: 0.5713\n",
      "Epoch 00015: early stopping\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 1.7965 - acc: 0.5713\n",
      "Epoch 1/50\n",
      "1831/1831 [==============================] - 28s 16ms/step - loss: 1.8104 - acc: 0.3102 - val_loss: 1.6467 - val_acc: 0.3880\n",
      "Epoch 2/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 1.5202 - acc: 0.4466 - val_loss: 1.5322 - val_acc: 0.4750\n",
      "Epoch 3/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 1.3415 - acc: 0.5446 - val_loss: 1.4396 - val_acc: 0.5244\n",
      "Epoch 4/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 1.2141 - acc: 0.6173 - val_loss: 1.4461 - val_acc: 0.5602\n",
      "Epoch 5/50\n",
      "1831/1831 [==============================] - 27s 15ms/step - loss: 1.1165 - acc: 0.6669 - val_loss: 1.4647 - val_acc: 0.5575\n",
      "Epoch 6/50\n",
      "1831/1831 [==============================] - 27s 15ms/step - loss: 1.0546 - acc: 0.7020 - val_loss: 1.4411 - val_acc: 0.5648\n",
      "Epoch 7/50\n",
      "1831/1831 [==============================] - 27s 15ms/step - loss: 1.0051 - acc: 0.7292 - val_loss: 1.5340 - val_acc: 0.5808\n",
      "Epoch 8/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 0.9778 - acc: 0.7469 - val_loss: 1.6303 - val_acc: 0.5828\n",
      "Epoch 9/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 0.9534 - acc: 0.7616 - val_loss: 1.5700 - val_acc: 0.5806\n",
      "Epoch 10/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 0.9333 - acc: 0.7737 - val_loss: 1.5904 - val_acc: 0.5925\n",
      "Epoch 11/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 0.9240 - acc: 0.7845 - val_loss: 1.6951 - val_acc: 0.5868\n",
      "Epoch 12/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 0.9073 - acc: 0.7939 - val_loss: 1.6391 - val_acc: 0.6029\n",
      "Epoch 13/50\n",
      "1831/1831 [==============================] - 28s 15ms/step - loss: 0.9066 - acc: 0.7953 - val_loss: 1.6979 - val_acc: 0.6032\n",
      "Epoch 00013: early stopping\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.6979 - acc: 0.6032\n",
      "[0.10138249 0.24930875 0.30107528 0.37572965 0.45176652 0.54132104\n",
      " 0.552381   0.59032255 0.5890937  0.57127494 0.6032258 ]\n"
     ]
    }
   ],
   "source": [
    "RatioToTest = np.array([0.0001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0])\n",
    "NumberToTest = list(map(int, (RatioToTest * TrainCrystalNo * AllData.shape[1])))\n",
    "ValAccuracy = np.zeros(len(NumberToTest), dtype = np.float32)\n",
    "print(NumberToTest)\n",
    "for i in range(0, len(NumberToTest)):\n",
    "    EarlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    model = create_model()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['acc'])\n",
    "    \n",
    "    history = model.fit(train_images[0:NumberToTest[i]], train_lab[0:NumberToTest[i]], epochs=50, batch_size = 32, validation_data = (val_images, val_lab), shuffle = True, callbacks=[EarlyStop])\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(val_images, val_lab) #Warning this is validation, take care if copying this code\n",
    "\n",
    "    val_acc = history.history['val_acc']\n",
    "    ValAccuracy[i] = val_acc[-1]\n",
    "\n",
    "\n",
    "print(ValAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292, 585, 2928, 5857, 11714, 23428, 35142, 46856, 52713, 58570]\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.7084 - acc: 0.3611\n",
      "Epoch 00001: val_loss improved from 1.77758 to 1.67347, saving model to BestModCov2.hdf5\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 1.7111 - acc: 0.3630 - val_loss: 1.6735 - val_acc: 0.3668\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.6735 - acc: 0.3668\n",
      "HELLO 0.36301368474960327\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 1.5848 - acc: 0.3952\n",
      "Epoch 00001: val_loss did not improve from 1.67347\n",
      "19/19 [==============================] - 2s 93ms/step - loss: 1.5836 - acc: 0.3949 - val_loss: 1.7774 - val_acc: 0.3516\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.7774 - acc: 0.3516\n",
      "HELLO 0.3948718011379242\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.5759 - acc: 0.4184\n",
      "Epoch 00001: val_loss improved from 1.67347 to 1.61844, saving model to BestModCov2.hdf5\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.5759 - acc: 0.4184 - val_loss: 1.6184 - val_acc: 0.3935\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.6184 - acc: 0.3935\n",
      "HELLO 0.41837432980537415\n",
      "181/184 [============================>.] - ETA: 0s - loss: 1.5559 - acc: 0.4259\n",
      "Epoch 00001: val_loss improved from 1.61844 to 1.60607, saving model to BestModCov2.hdf5\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 1.5551 - acc: 0.4263 - val_loss: 1.6061 - val_acc: 0.4117\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.6061 - acc: 0.4117\n",
      "HELLO 0.4263274669647217\n",
      "365/367 [============================>.] - ETA: 0s - loss: 1.5192 - acc: 0.4484\n",
      "Epoch 00001: val_loss improved from 1.60607 to 1.60503, saving model to BestModCov2.hdf5\n",
      "367/367 [==============================] - 7s 20ms/step - loss: 1.5189 - acc: 0.4486 - val_loss: 1.6050 - val_acc: 0.4126\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.6050 - acc: 0.4126\n",
      "HELLO 0.44860848784446716\n",
      "730/733 [============================>.] - ETA: 0s - loss: 1.4611 - acc: 0.4756\n",
      "Epoch 00001: val_loss improved from 1.60503 to 1.50373, saving model to BestModCov2.hdf5\n",
      "733/733 [==============================] - 13s 17ms/step - loss: 1.4608 - acc: 0.4756 - val_loss: 1.5037 - val_acc: 0.4667\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.5037 - acc: 0.4667\n",
      "HELLO 0.4755847752094269\n",
      "1099/1099 [==============================] - ETA: 0s - loss: 1.3752 - acc: 0.5218\n",
      "Epoch 00001: val_loss did not improve from 1.50373\n",
      "1099/1099 [==============================] - 18s 17ms/step - loss: 1.3752 - acc: 0.5218 - val_loss: 1.5405 - val_acc: 0.4659\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.5405 - acc: 0.4659\n",
      "HELLO 0.5217972993850708\n",
      "1465/1465 [==============================] - ETA: 0s - loss: 1.2899 - acc: 0.5744\n",
      "Epoch 00001: val_loss improved from 1.50373 to 1.47118, saving model to BestModCov2.hdf5\n",
      "1465/1465 [==============================] - 24s 16ms/step - loss: 1.2899 - acc: 0.5744 - val_loss: 1.4712 - val_acc: 0.5163\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.4712 - acc: 0.5163\n",
      "HELLO 0.5744194984436035\n",
      "1645/1648 [============================>.] - ETA: 0s - loss: 1.1824 - acc: 0.6278\n",
      "Epoch 00001: val_loss improved from 1.47118 to 1.46137, saving model to BestModCov2.hdf5\n",
      "1648/1648 [==============================] - 26s 16ms/step - loss: 1.1823 - acc: 0.6279 - val_loss: 1.4614 - val_acc: 0.5419\n",
      "204/204 [==============================] - 1s 6ms/step - loss: 1.4614 - acc: 0.5419\n",
      "HELLO 0.6278906464576721\n",
      " 811/1831 [============>.................] - ETA: 15s - loss: 1.1156 - acc: 0.6710"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e32651c30df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNumberToTest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_lab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Warning this is validation, take care if copying this code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
